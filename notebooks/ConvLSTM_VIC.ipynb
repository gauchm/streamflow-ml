{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvLSTM trained on gridded forcings for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190723-113731'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src import load_data, evaluate, conv_lstm, datasets\n",
    "import torch.autograd as autograd\n",
    "import pickle\n",
    "\n",
    "time_stamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='../log.out', mode='a')\n",
    "chandler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('%(asctime)s - {} - %(message)s'.format(time_stamp))\n",
    "fhandler.setFormatter(formatter)\n",
    "chandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available\n",
      "2019-07-23 11:37:31,848 - 20190723-113731 - cuda devices: ['Tesla V100-SXM2-16GB', 'Tesla V100-SXM2-16GB']\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA Available')\n",
    "    USE_CUDA = True\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "num_devices = torch.cuda.device_count() if USE_CUDA else 0\n",
    "logger.warning('cuda devices: {}'.format(list(torch.cuda.get_device_name(i) for i in range(num_devices))))\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 50\n",
    "seq_steps = 1\n",
    "\n",
    "train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(hours=seq_len * seq_steps)  # first day for which to make a prediction in train set\n",
    "train_end = '2012-09-30'\n",
    "val_start = '2012-10-01'\n",
    "val_end = '2012-12-31'\n",
    "test_start = '2013-01-01'\n",
    "test_end = '2014-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/load_data.py:43: RuntimeWarning: invalid value encountered in greater\n",
      "  rdrs_data[:,i,:,:] = rdrs_nc[forcing_variables[i]][:]\n",
      "../src/load_data.py:43: RuntimeWarning: invalid value encountered in greater\n",
      "  rdrs_data[:,i,:,:] = rdrs_nc[forcing_variables[i]][:]\n",
      "../src/load_data.py:43: RuntimeWarning: invalid value encountered in greater\n",
      "  rdrs_data[:,i,:,:] = rdrs_nc[forcing_variables[i]][:]\n"
     ]
    }
   ],
   "source": [
    "rdrs_vars = [4,5]\n",
    "train_dataset = datasets.RdrsGridDataset(rdrs_vars, seq_len, seq_steps, train_start, train_end)\n",
    "val_dataset = datasets.RdrsGridDataset(rdrs_vars, seq_len, seq_steps, val_start, val_end, conv_scalers=train_dataset.conv_scalers)\n",
    "test_dataset = datasets.RdrsGridDataset(rdrs_vars, seq_len, seq_steps, test_start, test_end, conv_scalers=train_dataset.conv_scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class ConvLSTMGrid(nn.Module):\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers, dropout=0.0):\n",
    "        super(ConvLSTMGrid, self).__init__()\n",
    "        self.conv = conv_lstm.ConvLSTM((input_size[0], input_size[1]), input_dim, hidden_dim, kernel_size, num_layers, batch_first=True)\n",
    "        self.dropout = nn.Dropout2d(p=dropout)\n",
    "        self.linear = nn.Linear(input_size[0] * input_size[1], input_size[0] * input_size[1])\n",
    "        \n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        conv_out, hidden = self.conv(input_tensor, hidden_state=hidden_state)\n",
    "        conv_out = self.dropout(conv_out[-1][:,-1,0,:,:])  # last output of last layer (which has only 1 dimension anyways)\n",
    "        return self.linear(conv_out.reshape(input_tensor.shape[0], -1)).reshape((input_tensor.shape[0], conv_out.shape[1], conv_out.shape[2])), hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "num_epochs = 100\n",
    "learning_rate = 2e-3\n",
    "patience = 50\n",
    "min_improvement = 0.05\n",
    "best_loss_model = (-1, np.inf, None)\n",
    "\n",
    "# Prepare model\n",
    "stateful_lstm = False\n",
    "num_conv_layers = 3\n",
    "conv_hidden_dims = [8] * (num_conv_layers - 1) + [1]\n",
    "batch_size = 16\n",
    "kernel_size = [(3,3), (3,3), (1,1)]\n",
    "dropout = 0.2\n",
    "\n",
    "model = ConvLSTMGrid((train_dataset.conv_height, train_dataset.conv_width), train_dataset.n_conv_vars, conv_hidden_dims, kernel_size, num_conv_layers, dropout=dropout).to(device)\n",
    "model = torch.nn.DataParallel(model, device_ids=list(range(num_devices)))\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "writer = SummaryWriter()\n",
    "param_description = {'time_stamp': time_stamp, 'H_conv': conv_hidden_dims, 'batch_size': batch_size, 'num_conv_layers': num_conv_layers, 'kernel_size': kernel_size, 'loss': loss_fn, \n",
    "                     'optimizer': optimizer, 'lr': learning_rate, 'patience': patience, 'min_improvement': min_improvement, 'stateful_lstm': stateful_lstm, 'dropout': dropout,\n",
    "                     'num_epochs': num_epochs, 'seq_len': seq_len, 'seq_steps': seq_steps, 'train_start': train_start, 'train_end': train_end, 'val_start': val_start, \n",
    "                     'val_end': val_end, 'test_start': test_start, 'test_end': test_end, 'n_conv_vars': train_dataset.n_conv_vars, 'model': str(model).replace('\\n','').replace(' ', ''),\n",
    "                     'train len':len(train_dataset), 'val len': len(val_dataset), 'conv_height': train_dataset.conv_height, 'conv_width': train_dataset.conv_width, 'test len': len(test_dataset)}\n",
    "writer.add_text('Parameter Description', str(param_description))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stateful_lstm:\n",
    "    train_sampler = datasets.StatefulBatchSampler(train_dataset, batch_size)\n",
    "    val_sampler = datasets.StatefulBatchSampler(val_dataset, batch_size)\n",
    "    test_sampler = datasets.StatefulBatchSampler(test_dataset, batch_size)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler, pin_memory=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_sampler=val_sampler, pin_memory=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler, pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size, shuffle=False, pin_memory=True, drop_last=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 mean train loss:\t3534.197998046875\n",
      "Epoch 0 mean val mse:    \t686.3095703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/runoff-nn/gwf/lib/python3.6/site-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type ConvLSTMGrid. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model as ../pickle/models/ConvLSTM_VIC_allStations_20190723-113731.pkl\n",
      "Epoch 1 mean train loss:\t2919.609619140625\n",
      "Epoch 1 mean val mse:    \t1028.2008056640625\n",
      "Epoch 2 mean train loss:\t2873.742919921875\n",
      "Epoch 2 mean val mse:    \t1045.464599609375\n",
      "Epoch 3 mean train loss:\t2872.501953125\n",
      "Epoch 3 mean val mse:    \t1103.9677734375\n",
      "Epoch 4 mean train loss:\t2884.33740234375\n",
      "Epoch 4 mean val mse:    \t1117.693603515625\n",
      "Epoch 5 mean train loss:\t2882.305908203125\n",
      "Epoch 5 mean val mse:    \t1084.1075439453125\n",
      "Epoch 6 mean train loss:\t2875.266845703125\n",
      "Epoch 6 mean val mse:    \t1029.720458984375\n",
      "Epoch 7 mean train loss:\t2736.734619140625\n",
      "Epoch 7 mean val mse:    \t1189.002197265625\n",
      "Epoch 8 mean train loss:\t2651.6767578125\n",
      "Epoch 8 mean val mse:    \t1100.7298583984375\n",
      "Epoch 9 mean train loss:\t2578.5537109375\n",
      "Epoch 9 mean val mse:    \t1310.237060546875\n",
      "Epoch 10 mean train loss:\t2619.9677734375\n",
      "Epoch 10 mean val mse:    \t1147.540771484375\n",
      "Epoch 11 mean train loss:\t2478.69091796875\n",
      "Epoch 11 mean val mse:    \t1101.5457763671875\n",
      "Epoch 12 mean train loss:\t2566.687255859375\n",
      "Epoch 12 mean val mse:    \t1153.395263671875\n",
      "Epoch 13 mean train loss:\t2534.224365234375\n",
      "Epoch 13 mean val mse:    \t1192.268798828125\n",
      "Epoch 14 mean train loss:\t2445.164794921875\n",
      "Epoch 14 mean val mse:    \t1094.0716552734375\n",
      "Epoch 15 mean train loss:\t2589.136474609375\n",
      "Epoch 15 mean val mse:    \t1171.161376953125\n",
      "Epoch 16 mean train loss:\t2506.1396484375\n",
      "Epoch 16 mean val mse:    \t1155.771240234375\n",
      "Epoch 17 mean train loss:\t2573.696044921875\n",
      "Epoch 17 mean val mse:    \t1102.9771728515625\n",
      "Epoch 18 mean train loss:\t2531.205078125\n",
      "Epoch 18 mean val mse:    \t1183.780029296875\n",
      "Epoch 19 mean train loss:\t2573.860107421875\n",
      "Epoch 19 mean val mse:    \t1265.857666015625\n",
      "Epoch 20 mean train loss:\t2578.931640625\n",
      "Epoch 20 mean val mse:    \t1074.037353515625\n",
      "Epoch 21 mean train loss:\t2591.907958984375\n",
      "Epoch 21 mean val mse:    \t1170.845703125\n",
      "Epoch 22 mean train loss:\t2573.22216796875\n",
      "Epoch 22 mean val mse:    \t1217.5511474609375\n",
      "Epoch 23 mean train loss:\t2551.593505859375\n",
      "Epoch 23 mean val mse:    \t1151.3177490234375\n",
      "Epoch 24 mean train loss:\t2511.57666015625\n",
      "Epoch 24 mean val mse:    \t973.2296142578125\n",
      "Epoch 25 mean train loss:\t2528.331787109375\n",
      "Epoch 25 mean val mse:    \t954.5193481445312\n",
      "Epoch 26 mean train loss:\t2480.53564453125\n",
      "Epoch 26 mean val mse:    \t1231.913818359375\n",
      "Epoch 27 mean train loss:\t2452.220703125\n",
      "Epoch 27 mean val mse:    \t1055.3804931640625\n",
      "Epoch 28 mean train loss:\t2358.8701171875\n",
      "Epoch 28 mean val mse:    \t1179.3262939453125\n",
      "Epoch 29 mean train loss:\t2369.351806640625\n",
      "Epoch 29 mean val mse:    \t1021.2286376953125\n",
      "Epoch 30 mean train loss:\t2336.02392578125\n",
      "Epoch 30 mean val mse:    \t1095.22705078125\n",
      "Epoch 31 mean train loss:\t2287.693115234375\n",
      "Epoch 31 mean val mse:    \t1040.322021484375\n",
      "Epoch 32 mean train loss:\t2280.9423828125\n",
      "Epoch 32 mean val mse:    \t1046.569091796875\n",
      "Epoch 33 mean train loss:\t2273.41064453125\n",
      "Epoch 33 mean val mse:    \t1259.5767822265625\n",
      "Epoch 34 mean train loss:\t2256.528564453125\n",
      "Epoch 34 mean val mse:    \t1062.030029296875\n",
      "Epoch 35 mean train loss:\t2132.999755859375\n",
      "Epoch 35 mean val mse:    \t1306.4361572265625\n",
      "Epoch 36 mean train loss:\t2224.322021484375\n",
      "Epoch 36 mean val mse:    \t1141.669921875\n",
      "Epoch 37 mean train loss:\t2267.920166015625\n",
      "Epoch 37 mean val mse:    \t1123.957763671875\n",
      "Epoch 38 mean train loss:\t2249.986572265625\n",
      "Epoch 38 mean val mse:    \t1107.5689697265625\n",
      "Epoch 39 mean train loss:\t2203.127197265625\n",
      "Epoch 39 mean val mse:    \t1207.7672119140625\n",
      "Epoch 40 mean train loss:\t2197.866943359375\n",
      "Epoch 40 mean val mse:    \t1188.9281005859375\n",
      "Epoch 41 mean train loss:\t2204.47900390625\n",
      "Epoch 41 mean val mse:    \t1137.1885986328125\n",
      "Epoch 42 mean train loss:\t2146.1220703125\n",
      "Epoch 42 mean val mse:    \t1149.6099853515625\n",
      "Epoch 43 mean train loss:\t2145.6611328125\n",
      "Epoch 43 mean val mse:    \t1146.2939453125\n",
      "Epoch 44 mean train loss:\t2193.881591796875\n",
      "Epoch 44 mean val mse:    \t1355.009765625\n",
      "Epoch 45 mean train loss:\t2172.237060546875\n",
      "Epoch 45 mean val mse:    \t1217.1695556640625\n",
      "Epoch 46 mean train loss:\t2121.834716796875\n",
      "Epoch 46 mean val mse:    \t1256.989501953125\n",
      "Epoch 47 mean train loss:\t2123.4306640625\n",
      "Epoch 47 mean val mse:    \t1128.3570556640625\n",
      "Epoch 48 mean train loss:\t2097.52001953125\n",
      "Epoch 48 mean val mse:    \t1266.8863525390625\n",
      "Epoch 49 mean train loss:\t2104.232666015625\n",
      "Epoch 49 mean val mse:    \t1349.8592529296875\n",
      "Epoch 50 mean train loss:\t2241.791748046875\n",
      "Epoch 50 mean val mse:    \t1375.4183349609375\n",
      "Epoch 51 mean train loss:\t2172.29345703125\n",
      "Epoch 51 mean val mse:    \t1234.733154296875\n",
      "Patience exhausted in epoch 51. Best val-loss was 686.3095703125\n",
      "Using best model from epoch 0 which had loss 686.3095703125\n",
      "Saved model as ../pickle/models/ConvLSTM_VIC_allStations_20190723-113731.pkl\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    epoch_losses = torch.tensor(0.0)\n",
    "    conv_hidden_states = None\n",
    "    for i, train_batch in enumerate(train_dataloader):\n",
    "        y_train = train_batch['y'].reshape(-1).to(device, non_blocking=True)\n",
    "        mask = train_batch['mask'].reshape(-1).to(device, non_blocking=True)\n",
    "        if mask.sum() == 0:\n",
    "            print('Batch {} has no target values. skipping.'.format(i))\n",
    "            continue\n",
    "        if not stateful_lstm:\n",
    "            conv_hidden_states = None\n",
    "        \n",
    "        y_pred, conv_hidden_states = model(train_batch['x_conv'].to(device), hidden_state=conv_hidden_states)\n",
    "        y_pred = y_pred.reshape(-1) * mask  # ignore grid cells that have no target value\n",
    "        loss = loss_fn(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_losses += (loss * y_train.shape[0] / mask.sum()).detach()  # only average over losses where we had a target\n",
    "        \n",
    "    epoch_loss = (epoch_losses / len(train_dataloader)).item()\n",
    "    print('Epoch', epoch, 'mean train loss:\\t{}'.format(epoch_loss))\n",
    "    writer.add_scalar('loss', epoch_loss, epoch)\n",
    "    \n",
    "    # eval on validation split\n",
    "    model.eval()\n",
    "    val_losses = torch.tensor(0.0)\n",
    "    for i, val_batch in enumerate(val_dataloader):\n",
    "        y_val = val_batch['y'].reshape(-1).to(device, non_blocking=True)\n",
    "        mask = val_batch['mask'].reshape(-1).to(device, non_blocking=True)\n",
    "        if not stateful_lstm:\n",
    "            conv_hidden_states = None\n",
    "        \n",
    "        batch_pred, conv_hidden_states = model(val_batch['x_conv'], hidden_state=conv_hidden_states)\n",
    "        batch_pred = batch_pred.detach().reshape(-1)\n",
    "        val_losses += (loss_fn(batch_pred * mask, y_val).detach() * y_val.shape[0] / mask.sum())\n",
    "        \n",
    "    val_mse = (val_losses / len(val_dataloader)).item()\n",
    "    print('Epoch {} mean val mse:    \\t{}'.format(epoch, val_mse))\n",
    "    writer.add_scalar('loss_eval', val_mse, epoch)\n",
    "\n",
    "    if val_mse < best_loss_model[1] - min_improvement:\n",
    "        best_loss_model = (epoch, val_mse, model.state_dict())  # new best model\n",
    "        load_data.pickle_model('ConvLSTM_VIC', model, 'allStations', time_stamp)\n",
    "    elif epoch > best_loss_model[0] + patience:\n",
    "        print('Patience exhausted in epoch {}. Best val-loss was {}'.format(epoch, best_loss_model[1]))\n",
    "        break\n",
    "\n",
    "print('Using best model from epoch', str(best_loss_model[0]), 'which had loss', str(best_loss_model[1]))\n",
    "model.load_state_dict(best_loss_model[2])\n",
    "load_data.pickle_model('ConvLSTM_VIC', model, 'allStations', time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-23 11:51:23,120 - 20190723-113731 - predicting\n"
     ]
    }
   ],
   "source": [
    "logger.warning('predicting')\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for i, test_batch in enumerate(test_dataloader):\n",
    "    if not stateful_lstm:\n",
    "        conv_hidden_states = None\n",
    "        \n",
    "    pred, conv_hidden_states = model(test_batch['x_conv'], hidden_state=conv_hidden_states)\n",
    "    predictions.append(pred.detach())\n",
    "    \n",
    "predictions = torch.cat(predictions).cpu()\n",
    "\n",
    "if stateful_lstm:\n",
    "    # reorder time series\n",
    "    pred_indices = np.array(list(test_sampler.__iter__())).reshape(-1)\n",
    "    predictions = predictions[pred_indices.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: length of prediction 720 and actuals 730 does not match.\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GA047. Ignoring excess actuals.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/runoff-nn/gwf/lib/python3.6/site-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02GA047 \tNSE: -0.04008959879357943 \tMSE: 82.58568899524761 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04213000. Ignoring excess actuals.\n",
      "04213000 \tNSE: 0.24109884950175808 \tMSE: 137.90841198657026 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04176500. Ignoring excess actuals.\n",
      "04176500 \tNSE: -0.10568586977528005 \tMSE: 764.6464946055704 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GG003. Ignoring excess actuals.\n",
      "02GG003 \tNSE: 0.2414500851918877 \tMSE: 366.2914907626781 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04214500. Ignoring excess actuals.\n",
      "04214500 \tNSE: 0.3108797683432506 \tMSE: 84.12870655473283 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GC026. Ignoring excess actuals.\n",
      "02GC026 \tNSE: 0.13924422201855247 \tMSE: 140.23720284846632 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04174500. Ignoring excess actuals.\n",
      "04174500 \tNSE: 0.015505291637372798 \tMSE: 94.33723391132364 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GG013. Ignoring excess actuals.\n",
      "02GG013 \tNSE: 0.18519649175611452 \tMSE: 31.344181589092496 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04161820. Ignoring excess actuals.\n",
      "04161820 \tNSE: -0.34190855084251814 \tMSE: 42.80330173592912 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04159492. Ignoring excess actuals.\n",
      "04159492 \tNSE: 0.14340222808774006 \tMSE: 397.96074876705745 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04200500. Ignoring excess actuals.\n",
      "04200500 \tNSE: 0.23810018057324822 \tMSE: 772.3228974825147 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GB001. Ignoring excess actuals.\n",
      "02GB001 \tNSE: 0.0693793583908151 \tMSE: 6988.158018613837 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04208504. Ignoring excess actuals.\n",
      "04208504 \tNSE: 0.13602314329692944 \tMSE: 853.2976084531776 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04199000. Ignoring excess actuals.\n",
      "04199000 \tNSE: 0.18405372433947909 \tMSE: 844.8863496827552 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GG002. Ignoring excess actuals.\n",
      "02GG002 \tNSE: 0.20398971976855684 \tMSE: 194.1986132447879 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04193500. Ignoring excess actuals.\n",
      "04193500 \tNSE: 0.09314538518245519 \tMSE: 65002.23538248991 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04207200. Ignoring excess actuals.\n",
      "04207200 \tNSE: 0.2586305915040077 \tMSE: 17.572728842071598 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04160600. Ignoring excess actuals.\n",
      "04160600 \tNSE: 0.0947833692520571 \tMSE: 26.296321501911073 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04215000. Ignoring excess actuals.\n",
      "04215000 \tNSE: 0.23995853542405865 \tMSE: 73.9498750998731 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GB007. Ignoring excess actuals.\n",
      "02GB007 \tNSE: 0.14793048170829626 \tMSE: 26.959677887410848 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GC002. Ignoring excess actuals.\n",
      "02GC002 \tNSE: 0.22393544700490953 \tMSE: 100.96773435684295 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GA038. Ignoring excess actuals.\n",
      "02GA038 \tNSE: 0.18065937909796737 \tMSE: 134.2170851143611 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GA010. Ignoring excess actuals.\n",
      "02GA010 \tNSE: 0.12455603967421602 \tMSE: 418.87354627421286 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GG009. Ignoring excess actuals.\n",
      "02GG009 \tNSE: -0.027753813500290825 \tMSE: 161.5342108084077 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04165500. Ignoring excess actuals.\n",
      "04165500 \tNSE: 0.16970172768916603 \tMSE: 373.7395017031543 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04198000. Ignoring excess actuals.\n",
      "04198000 \tNSE: 0.14215782484649764 \tMSE: 6409.4171026439635 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04213500. Ignoring excess actuals.\n",
      "04213500 \tNSE: 0.247709296723428 \tMSE: 780.8596281283653 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GA018. Ignoring excess actuals.\n",
      "02GA018 \tNSE: 0.16018411493441786 \tMSE: 211.30705392153396 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GG006. Ignoring excess actuals.\n",
      "02GG006 \tNSE: 0.19853774997900464 \tMSE: 43.323644600130876 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GC007. Ignoring excess actuals.\n",
      "02GC007 \tNSE: -0.017026904669841247 \tMSE: 31.00240593342656 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04215500. Ignoring excess actuals.\n",
      "04215500 \tNSE: 0.24815464578243074 \tMSE: 137.34580836766287 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04195820. Ignoring excess actuals.\n",
      "04195820 \tNSE: 0.10445600841950542 \tMSE: 1064.342095475087 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04209000. Ignoring excess actuals.\n",
      "04209000 \tNSE: 0.24194917052556775 \tMSE: 240.08566805659754 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GE007. Ignoring excess actuals.\n",
      "02GE007 \tNSE: 0.22056328063005726 \tMSE: 28.516564095561765 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GC010. Ignoring excess actuals.\n",
      "02GC010 \tNSE: 0.15831889095779772 \tMSE: 50.68788239261659 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04166100. Ignoring excess actuals.\n",
      "04166100 \tNSE: -0.6593336275269661 \tMSE: 12.198807202432771 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04177000. Ignoring excess actuals.\n",
      "04177000 \tNSE: 0.10303207991177166 \tMSE: 24.4646545032225 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04164000. Ignoring excess actuals.\n",
      "04164000 \tNSE: 0.12581505623987 \tMSE: 154.66614794869096 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04159900. Ignoring excess actuals.\n",
      "04159900 \tNSE: 0.09340670038685883 \tMSE: 39.6060888762754 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GD004. Ignoring excess actuals.\n",
      "02GD004 \tNSE: 0.21821459734874815 \tMSE: 43.541233216334895 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04196800. Ignoring excess actuals.\n",
      "04196800 \tNSE: 0.11680586905551638 \tMSE: 267.3360036205113 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04199500. Ignoring excess actuals.\n",
      "04199500 \tNSE: 0.1760776183548335 \tMSE: 337.6507127739068 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04212100. Ignoring excess actuals.\n",
      "04212100 \tNSE: 0.1753415597757162 \tMSE: 1226.3021294382052 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 02GC018. Ignoring excess actuals.\n",
      "02GC018 \tNSE: 0.23606632850168696 \tMSE: 52.409817784884794 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04166500. Ignoring excess actuals.\n",
      "04166500 \tNSE: 0.10122337534949111 \tMSE: 31.28046862898938 (clipped to 0)\n",
      "Warning: length of prediction 720 and actuals 730 does not match for station 04197100. Ignoring excess actuals.\n",
      "04197100 \tNSE: 0.26115715487869984 \tMSE: 76.67210508130852 (clipped to 0)\n",
      "Median NSE (clipped to 0) 0.1592515029461078 / Min -0.6593336275269661 / Max 0.3108797683432506\n",
      "Median MSE (clipped to 0) 137.62711017711655 / Min 12.198807202432771 / Max 65002.23538248991\n"
     ]
    }
   ],
   "source": [
    "actuals = test_dataset.data_runoff.copy()\n",
    "if len(actuals['date'].unique()) != len(predictions):\n",
    "    print('Warning: length of prediction {} and actuals {} does not match.'.format(len(predictions), len(actuals['date'].unique())))\n",
    "\n",
    "nse_list = []\n",
    "mse_list = []\n",
    "predictions_df = pd.DataFrame(columns=actuals.columns)\n",
    "for station in actuals['station'].unique():\n",
    "    row, col = test_dataset.station_to_row_col[station]\n",
    "    \n",
    "    act = actuals[actuals['station'] == station].set_index('date')['runoff']\n",
    "    if predictions.shape[0] != act.shape[0]:\n",
    "        print('Warning: length of prediction {} and actuals {} does not match for station {}. Ignoring excess actuals.'.format(len(predictions), len(act), station))\n",
    "        act = act.iloc[:predictions.shape[0]]\n",
    "    pred = pd.DataFrame({'runoff': predictions[:,row,col]}, index=act.index)\n",
    "    pred['station'] = station\n",
    "    predictions_df = predictions_df.append(pred.reset_index(), sort=True)\n",
    "    \n",
    "    nse, mse = evaluate.evaluate_daily(station, pred['runoff'], act, writer=writer)\n",
    "    nse_list.append(nse)\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    print(station, '\\tNSE:', nse, '\\tMSE:', mse, '(clipped to 0)')\n",
    "\n",
    "print('Median NSE (clipped to 0)', np.median(nse_list), '/ Min', np.min(nse_list), '/ Max', np.max(nse_list))\n",
    "print('Median MSE (clipped to 0)', np.median(mse_list), '/ Min', np.min(mse_list), '/ Max', np.max(mse_list))\n",
    "writer.add_scalar('nse_median', np.median(nse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ConvLSTM_VIC_20190723-113731.pkl'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df = pd.merge(predictions_df.rename({'runoff': 'prediction'}, axis=1), actuals.rename({'runoff': 'actual'}, axis=1), \n",
    "                   on=['date', 'station'])[['date', 'station', 'prediction', 'actual']]\n",
    "load_data.pickle_results('ConvLSTM_VIC', save_df, time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190723-115135'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
