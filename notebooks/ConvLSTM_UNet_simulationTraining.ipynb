{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConvLSTM trained on simulated streamflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190817-095426'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt \n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "from torch import nn, utils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src import load_data, evaluate, conv_lstm, datasets, utils\n",
    "import torch.autograd as autograd\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "time_stamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "fhandler = logging.FileHandler(filename='../log.out', mode='a')\n",
    "chandler = logging.StreamHandler(sys.stdout)\n",
    "formatter = logging.Formatter('%(asctime)s - {} - %(message)s'.format(time_stamp))\n",
    "fhandler.setFormatter(formatter)\n",
    "chandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "logger.addHandler(chandler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available\n",
      "2019-08-17 09:54:26,864 - 20190817-095426 - cuda devices: ['Tesla V100-SXM2-16GB']\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA Available')\n",
    "    USE_CUDA = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "num_devices = torch.cuda.device_count() if USE_CUDA else 0\n",
    "logger.warning('cuda devices: {}'.format(list(torch.cuda.get_device_name(i) for i in range(num_devices))))\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "landcover_nc = nc.Dataset('../data/NA_NALCMS_LC_30m_LAEA_mmu12_urb05_n40-45w75-90_erie.nc', 'r')\n",
    "landcover_nc.set_auto_mask(False)\n",
    "erie_lats = landcover_nc['lat'][:][::-1]\n",
    "erie_lons = landcover_nc['lon'][:]\n",
    "landcover_nc.close()\n",
    "erie_lat_min, erie_lat_max, erie_lon_min, erie_lon_max = erie_lats.min(), erie_lats.max(), erie_lons.min(), erie_lons.max()\n",
    "del erie_lats, erie_lons\n",
    "\n",
    "out_lats, out_lons = load_data.load_dem_lats_lons()\n",
    "out_lats = out_lats[(erie_lat_min <= out_lats) & (out_lats <= erie_lat_max)].copy()\n",
    "out_lons = out_lons[(erie_lon_min <= out_lons) &  (out_lons <= erie_lon_max)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "seq_steps = 1\n",
    "stateful_lstm = False\n",
    "val_start, val_end = None, None\n",
    "validation_fraction = 0.1  # fraction of subbasins\n",
    "p_random_transform = 0.5\n",
    "\n",
    "if stateful_lstm:\n",
    "    val_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(days=seq_len * seq_steps)  # first day for which to make a prediction in train set\n",
    "    val_end = '2010-09-30'\n",
    "    train_start = '2010-10-01'\n",
    "    train_end = '2012-12-31'\n",
    "else:\n",
    "    train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(days=seq_len * seq_steps)  # first day for which to make a prediction in train set\n",
    "    train_end = '2012-12-31'\n",
    "test_start = '2013-01-01'\n",
    "test_end = '2014-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "rdrs_vars = [4, 5]\n",
    "agg = ['sum', 'minmax']\n",
    "include_month = False\n",
    "train_dataset = datasets.RdrsGridDataset(rdrs_vars, seq_len, seq_steps, train_start, train_end, aggregate_daily=agg, include_months=True, include_simulated_streamflow=True, resample_rdrs=True, out_lats=out_lats, out_lons=out_lons)\n",
    "if stateful_lstm:\n",
    "    val_dataset = datasets.RdrsGridDataset(rdrs_vars, seq_len, seq_steps, val_start, val_end, conv_scalers=train_dataset.conv_scalers, aggregate_daily=agg,  include_months=True, include_simulated_streamflow=True, resample_rdrs=True, out_lats=out_lats, out_lons=out_lons)\n",
    "test_dataset = datasets.RdrsGridDataset(rdrs_vars, seq_len, seq_steps, test_start, test_end, conv_scalers=train_dataset.conv_scalers, aggregate_daily=agg, include_months=True, include_simulated_streamflow=True, resample_rdrs=True, out_lats=out_lats, out_lons=out_lons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "landcover_types = []\n",
    "geophysical_dataset = datasets.GeophysicalGridDataset(dem=True, landcover=False, soil=False, groundwater=False, min_lat=erie_lat_min, max_lat=erie_lat_max, min_lon=erie_lon_min, max_lon=erie_lon_max, landcover_types=landcover_types)\n",
    "geophysical_data = next(geophysical_dataset.__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subbasins = train_dataset.simulated_streamflow['subbasin'].unique()\n",
    "np.random.seed(0)\n",
    "test_subbasins = np.random.choice(subbasins, size=int(0.2 * len(subbasins)), replace=False)\n",
    "val_subbasins = np.random.choice(list(s for s in subbasins if s not in test_subbasins), size=int(validation_fraction * len(subbasins)), replace=False)\n",
    "train_subbasins = list(s for s in subbasins if s not in test_subbasins and s not in val_subbasins)\n",
    "station_subbasins = train_dataset.simulated_streamflow[~pd.isna(train_dataset.simulated_streamflow['StationID'])]['subbasin'].unique()\n",
    "\n",
    "train_subbasin_indices = list(train_dataset.outlet_to_row_col[s] for s in train_subbasins)\n",
    "val_subbasin_indices = list(train_dataset.outlet_to_row_col[s] for s in val_subbasins)\n",
    "test_subbasin_indices = list(test_dataset.outlet_to_row_col[s] for s in test_subbasins)\n",
    "\n",
    "train_mask = torch.zeros((train_dataset.out_lats.shape[0], train_dataset.out_lats.shape[1]), dtype=torch.bool)\n",
    "val_mask = torch.zeros((train_dataset.out_lats.shape[0], train_dataset.out_lats.shape[1]), dtype=torch.bool)\n",
    "for row in range(train_mask.shape[0]):\n",
    "    for col in range(train_mask.shape[1]):\n",
    "        train_mask[row, col] = True if (row, col) in train_subbasin_indices else False\n",
    "        val_mask[row, col] = True if (row, col) in val_subbasin_indices else False\n",
    "train_mask = train_mask\n",
    "val_mask = val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/mgauch/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"{'time_stamp': '20190817-095426', 'H_convlstm': [8, 8], 'H_conv': [8, 8], 'batch_size': 4, 'num_convlstm_layers': 2, 'num_conv_layers': 2, 'convlstm_kernel_size': [(5, 5), (5, 5)], 'conv_kernel_size': [(7, 7), (7, 7)], 'loss': NSELoss(), 'optimizer': Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    eps: 1e-08\\n    lr: 0.002\\n    weight_decay: 1e-05\\n), 'lr': 0.002, 'patience': 100, 'min_improvement': 0.01, 'stateful_lstm': False, 'dropout': 0.3, 'geophys_shape': torch.Size([1, 460, 848]), 'conv_activation': <class 'torch.nn.modules.activation.LeakyReLU'>, 'num_epochs': 250, 'seq_len': 8, 'seq_steps': 1, 'train_start': datetime.datetime(2010, 1, 9, 0, 0), 'train_end': '2012-12-31', 'weight_decay': 1e-05, 'validation_fraction': 0.1, 'landcover_types': [], 'test_start': '2013-01-01', 'test_end': '2014-12-31', 'n_conv_vars': 15, 'model': 'ConvLSTMGridWithGeophysicalInput((conv_lstm):ConvLSTM((cell_list):ModuleList((0):ConvLSTMCell((conv):Conv2d(23,32,kernel_size=(5,5),stride=(1,1),padding=(2,2)))(1):Identity()(2):ConvLSTMCell((conv):Conv2d(16,32,kernel_size=(5,5),stride=(1,1),padding=(2,2)))(3):Identity()))(dropout):Dropout2d(p=0.3,inplace=False)(upsample):ConvTranspose2d(8,8,kernel_size=(31,50),stride=(13,21))(conv_out):Sequential((0):ZeroPad2d(padding=[0,0,2,2],value=0.0)(1):UNet((encoder1):Sequential((enc1conv1):Conv2d(9,32,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc1norm1):BatchNorm2d(32,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc1relu1):ReLU(inplace=True)(enc1conv2):Conv2d(32,32,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc1norm2):BatchNorm2d(32,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc1relu2):ReLU(inplace=True))(pool1):MaxPool2d(kernel_size=2,stride=2,padding=0,dilation=1,ceil_mode=False)(encoder2):Sequential((enc2conv1):Conv2d(32,64,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc2norm1):BatchNorm2d(64,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc2relu1):ReLU(inplace=True)(enc2conv2):Conv2d(64,64,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc2norm2):BatchNorm2d(64,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc2relu2):ReLU(inplace=True))(pool2):MaxPool2d(kernel_size=2,stride=2,padding=0,dilation=1,ceil_mode=False)(encoder3):Sequential((enc3conv1):Conv2d(64,128,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc3norm1):BatchNorm2d(128,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc3relu1):ReLU(inplace=True)(enc3conv2):Conv2d(128,128,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc3norm2):BatchNorm2d(128,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc3relu2):ReLU(inplace=True))(pool3):MaxPool2d(kernel_size=2,stride=2,padding=0,dilation=1,ceil_mode=False)(encoder4):Sequential((enc4conv1):Conv2d(128,256,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc4norm1):BatchNorm2d(256,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc4relu1):ReLU(inplace=True)(enc4conv2):Conv2d(256,256,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(enc4norm2):BatchNorm2d(256,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(enc4relu2):ReLU(inplace=True))(pool4):MaxPool2d(kernel_size=2,stride=2,padding=0,dilation=1,ceil_mode=False)(bottleneck):Sequential((bottleneckconv1):Conv2d(256,512,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(bottlenecknorm1):BatchNorm2d(512,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(bottleneckrelu1):ReLU(inplace=True)(bottleneckconv2):Conv2d(512,512,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(bottlenecknorm2):BatchNorm2d(512,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(bottleneckrelu2):ReLU(inplace=True))(upconv4):ConvTranspose2d(512,256,kernel_size=(2,2),stride=(2,2))(decoder4):Sequential((dec4conv1):Conv2d(512,256,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec4norm1):BatchNorm2d(256,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec4relu1):ReLU(inplace=True)(dec4conv2):Conv2d(256,256,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec4norm2):BatchNorm2d(256,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec4relu2):ReLU(inplace=True))(upconv3):ConvTranspose2d(256,128,kernel_size=(2,2),stride=(2,2))(decoder3):Sequential((dec3conv1):Conv2d(256,128,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec3norm1):BatchNorm2d(128,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec3relu1):ReLU(inplace=True)(dec3conv2):Conv2d(128,128,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec3norm2):BatchNorm2d(128,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec3relu2):ReLU(inplace=True))(upconv2):ConvTranspose2d(128,64,kernel_size=(2,2),stride=(2,2))(decoder2):Sequential((dec2conv1):Conv2d(128,64,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec2norm1):BatchNorm2d(64,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec2relu1):ReLU(inplace=True)(dec2conv2):Conv2d(64,64,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec2norm2):BatchNorm2d(64,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec2relu2):ReLU(inplace=True))(upconv1):ConvTranspose2d(64,32,kernel_size=(2,2),stride=(2,2))(decoder1):Sequential((dec1conv1):Conv2d(64,32,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec1norm1):BatchNorm2d(32,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec1relu1):ReLU(inplace=True)(dec1conv2):Conv2d(32,32,kernel_size=(3,3),stride=(1,1),padding=(1,1),bias=False)(dec1norm2):BatchNorm2d(32,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)(dec1relu2):ReLU(inplace=True))(conv):Conv2d(32,1,kernel_size=(1,1),stride=(1,1)))(2):Conv2d(1,1,kernel_size=[5,1],stride=(1,1))(3):ReLU()))', 'val_start': None, 'val_end': None, 'feed_timesteps': 1, 'train len': 1088, 'conv_height': 34, 'conv_width': 39, 'test len': 730, 'p_random_transform': 0.5}\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "num_epochs = 250\n",
    "learning_rate = 2e-3\n",
    "patience = 100\n",
    "min_improvement = 0.01\n",
    "best_loss_model = (-1, np.inf, None)\n",
    "\n",
    "# Prepare model\n",
    "batch_size = 4\n",
    "num_convlstm_layers = 2\n",
    "num_conv_layers = 2\n",
    "convlstm_hidden_dims = [8,8]\n",
    "conv_hidden_dims = [8,8]\n",
    "convlstm_kernel_size = [(5,5)] * num_convlstm_layers\n",
    "conv_kernel_size = [(7,7)] * num_conv_layers\n",
    "conv_activation = nn.LeakyReLU\n",
    "dropout = 0.3\n",
    "weight_decay = 1e-5\n",
    "feed_timesteps = 1\n",
    "\n",
    "model = conv_lstm.ConvLSTMGridWithGeophysicalInput((train_dataset.conv_height, train_dataset.conv_width), train_dataset.n_conv_vars, \n",
    "                                                   geophysical_dataset.shape[0], convlstm_hidden_dims, conv_hidden_dims, convlstm_kernel_size, \n",
    "                                                   conv_kernel_size, num_convlstm_layers, num_conv_layers, conv_activation, dropout=dropout, \n",
    "                                                   geophysical_size=geophysical_dataset.shape[1:], feed_timesteps=feed_timesteps, conv_model='unet').to(device)\n",
    "if num_devices > 1:\n",
    "    model = torch.nn.DataParallel(model, device_ids=list(range(num_devices)))\n",
    "loss_fn = evaluate.NSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "writer = SummaryWriter(comment='ConvLSTM_simulationTraining')\n",
    "param_description = {'time_stamp': time_stamp, 'H_convlstm': convlstm_hidden_dims, 'H_conv': conv_hidden_dims, 'batch_size': batch_size, 'num_convlstm_layers': num_convlstm_layers, 'num_conv_layers': num_conv_layers, 'convlstm_kernel_size': convlstm_kernel_size, 'conv_kernel_size': conv_kernel_size, 'loss': loss_fn, \n",
    "                     'optimizer': optimizer, 'lr': learning_rate, 'patience': patience, 'min_improvement': min_improvement, 'stateful_lstm': stateful_lstm, 'dropout': dropout, 'geophys_shape': geophysical_dataset.shape, 'conv_activation': conv_activation,\n",
    "                     'num_epochs': num_epochs, 'seq_len': seq_len, 'seq_steps': seq_steps, 'train_start': train_start, 'train_end': train_end, 'weight_decay': weight_decay, 'validation_fraction': validation_fraction, 'landcover_types': landcover_types,\n",
    "                     'test_start': test_start, 'test_end': test_end, 'n_conv_vars': train_dataset.n_conv_vars, 'model': str(model).replace('\\n','').replace(' ', ''), 'val_start': val_start, 'val_end': val_end, 'feed_timesteps': feed_timesteps,\n",
    "                     'train len': len(train_dataset), 'conv_height': train_dataset.conv_height, 'conv_width': train_dataset.conv_width, 'test len': len(test_dataset), 'p_random_transform': p_random_transform}\n",
    "writer.add_text('Parameter Description', str(param_description))\n",
    "str(param_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if stateful_lstm:\n",
    "    train_sampler = datasets.StatefulBatchSampler(train_dataset, batch_size)\n",
    "    val_sampler = datasets.StatefulBatchSampler(val_dataset, batch_size)\n",
    "    test_sampler = datasets.StatefulBatchSampler(test_dataset, batch_size)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler, pin_memory=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_sampler=val_sampler, pin_memory=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler, pin_memory=True)\n",
    "else:\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, shuffle=True, pin_memory=True, drop_last=False)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True, drop_last=False)\n",
    "    \n",
    "geophysical_batch = geophysical_data.repeat(batch_size,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 mean train loss:\t2.122314453125\n",
      "Epoch 0 mean val loss:\t1.8716998100280762\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 1 mean train loss:\t1.5723170042037964\n",
      "Epoch 1 mean val loss:\t1.5734895467758179\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 2 mean train loss:\t1.4508445262908936\n",
      "Epoch 2 mean val loss:\t1.5656012296676636\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 3 mean train loss:\t1.4435787200927734\n",
      "Epoch 3 mean val loss:\t1.5623987913131714\n",
      "Epoch 4 mean train loss:\t1.378777265548706\n",
      "Epoch 4 mean val loss:\t1.747795820236206\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 5 mean train loss:\t1.3697559833526611\n",
      "Epoch 5 mean val loss:\t1.9428454637527466\n",
      "Epoch 6 mean train loss:\t1.3450442552566528\n",
      "Epoch 6 mean val loss:\t1.909047245979309\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 7 mean train loss:\t1.351323127746582\n",
      "Epoch 7 mean val loss:\t2.186293601989746\n",
      "Epoch 8 mean train loss:\t1.3611360788345337\n",
      "Epoch 8 mean val loss:\t1.789842128753662\n",
      "Epoch 9 mean train loss:\t1.3287290334701538\n",
      "Epoch 9 mean val loss:\t2.1220624446868896\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 10 mean train loss:\t1.309870719909668\n",
      "Epoch 10 mean val loss:\t2.3305952548980713\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 11 mean train loss:\t1.2745404243469238\n",
      "Epoch 11 mean val loss:\t2.4015145301818848\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 12 mean train loss:\t1.3457142114639282\n",
      "Epoch 12 mean val loss:\t2.144373655319214\n",
      "Epoch 13 mean train loss:\t1.2804900407791138\n",
      "Epoch 13 mean val loss:\t1.8405245542526245\n",
      "Epoch 14 mean train loss:\t1.3688323497772217\n",
      "Epoch 14 mean val loss:\t2.0290162563323975\n",
      "Epoch 15 mean train loss:\t1.3708970546722412\n",
      "Epoch 15 mean val loss:\t1.7514530420303345\n",
      "Epoch 16 mean train loss:\t1.357127070426941\n",
      "Epoch 16 mean val loss:\t2.0550222396850586\n",
      "Epoch 17 mean train loss:\t1.3137731552124023\n",
      "Epoch 17 mean val loss:\t2.1676645278930664\n",
      "Epoch 18 mean train loss:\t1.4160634279251099\n",
      "Epoch 18 mean val loss:\t2.1196959018707275\n",
      "Epoch 19 mean train loss:\t1.2973686456680298\n",
      "Epoch 19 mean val loss:\t2.117663621902466\n",
      "Epoch 20 mean train loss:\t1.3008426427841187\n",
      "Epoch 20 mean val loss:\t2.5926504135131836\n",
      "Epoch 21 mean train loss:\t1.3174221515655518\n",
      "Epoch 21 mean val loss:\t2.878200054168701\n",
      "Epoch 22 mean train loss:\t1.296935796737671\n",
      "Epoch 22 mean val loss:\t3.8389103412628174\n",
      "Epoch 23 mean train loss:\t1.2823573350906372\n",
      "Epoch 23 mean val loss:\t3.536377429962158\n",
      "Epoch 24 mean train loss:\t1.2740557193756104\n",
      "Epoch 24 mean val loss:\t4.148344039916992\n",
      "Epoch 25 mean train loss:\t1.2711063623428345\n",
      "Epoch 25 mean val loss:\t4.536963939666748\n",
      "Epoch 26 mean train loss:\t1.2739040851593018\n",
      "Epoch 26 mean val loss:\t3.7165908813476562\n",
      "Epoch 27 mean train loss:\t1.252028465270996\n",
      "Epoch 27 mean val loss:\t4.662269592285156\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 28 mean train loss:\t1.4228906631469727\n",
      "Epoch 28 mean val loss:\t2.3389365673065186\n",
      "Epoch 29 mean train loss:\t1.3003995418548584\n",
      "Epoch 29 mean val loss:\t2.6204493045806885\n",
      "Epoch 30 mean train loss:\t1.287385106086731\n",
      "Epoch 30 mean val loss:\t3.290897846221924\n",
      "Epoch 31 mean train loss:\t1.2173099517822266\n",
      "Epoch 31 mean val loss:\t4.33681583404541\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 32 mean train loss:\t1.294954538345337\n",
      "Epoch 32 mean val loss:\t4.198722839355469\n",
      "Epoch 33 mean train loss:\t1.2955830097198486\n",
      "Epoch 33 mean val loss:\t4.993603229522705\n",
      "Epoch 34 mean train loss:\t1.2366015911102295\n",
      "Epoch 34 mean val loss:\t5.519583225250244\n",
      "Epoch 35 mean train loss:\t1.230672836303711\n",
      "Epoch 35 mean val loss:\t4.125247955322266\n",
      "Epoch 36 mean train loss:\t1.2079211473464966\n",
      "Epoch 36 mean val loss:\t4.3849897384643555\n",
      "Epoch 37 mean train loss:\t1.2108275890350342\n",
      "Epoch 37 mean val loss:\t5.462498664855957\n",
      "Epoch 38 mean train loss:\t1.2427209615707397\n",
      "Epoch 38 mean val loss:\t6.281038284301758\n",
      "Epoch 39 mean train loss:\t1.2171030044555664\n",
      "Epoch 39 mean val loss:\t5.783504962921143\n",
      "Epoch 40 mean train loss:\t1.2187330722808838\n",
      "Epoch 40 mean val loss:\t6.0780229568481445\n",
      "Epoch 41 mean train loss:\t1.2237491607666016\n",
      "Epoch 41 mean val loss:\t6.3426103591918945\n",
      "Epoch 42 mean train loss:\t1.1828773021697998\n",
      "Epoch 42 mean val loss:\t6.343776226043701\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 43 mean train loss:\t1.1639420986175537\n",
      "Epoch 43 mean val loss:\t6.956138610839844\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 44 mean train loss:\t1.1926984786987305\n",
      "Epoch 44 mean val loss:\t7.057071208953857\n",
      "Epoch 45 mean train loss:\t1.163421630859375\n",
      "Epoch 45 mean val loss:\t6.8996901512146\n",
      "Epoch 46 mean train loss:\t1.22162926197052\n",
      "Epoch 46 mean val loss:\t7.450735569000244\n",
      "Epoch 47 mean train loss:\t1.200364589691162\n",
      "Epoch 47 mean val loss:\t5.731862545013428\n",
      "Epoch 48 mean train loss:\t1.1605541706085205\n",
      "Epoch 48 mean val loss:\t7.761838912963867\n",
      "Epoch 49 mean train loss:\t1.1773262023925781\n",
      "Epoch 49 mean val loss:\t7.273421287536621\n",
      "Epoch 50 mean train loss:\t1.0977277755737305\n",
      "Epoch 50 mean val loss:\t7.564471244812012\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 51 mean train loss:\t1.1200385093688965\n",
      "Epoch 51 mean val loss:\t7.046708583831787\n",
      "Epoch 52 mean train loss:\t1.0876379013061523\n",
      "Epoch 52 mean val loss:\t7.981858253479004\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 53 mean train loss:\t1.2789885997772217\n",
      "Epoch 53 mean val loss:\t5.466893196105957\n",
      "Epoch 54 mean train loss:\t1.2920879125595093\n",
      "Epoch 54 mean val loss:\t5.9788994789123535\n",
      "Epoch 55 mean train loss:\t1.2651007175445557\n",
      "Epoch 55 mean val loss:\t4.530411243438721\n",
      "Epoch 56 mean train loss:\t1.1093553304672241\n",
      "Epoch 56 mean val loss:\t5.845056056976318\n",
      "Epoch 57 mean train loss:\t1.1628276109695435\n",
      "Epoch 57 mean val loss:\t7.974947929382324\n",
      "Epoch 58 mean train loss:\t1.1173789501190186\n",
      "Epoch 58 mean val loss:\t6.814347267150879\n",
      "Epoch 59 mean train loss:\t1.057780146598816\n",
      "Epoch 59 mean val loss:\t6.947775840759277\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 60 mean train loss:\t1.064724326133728\n",
      "Epoch 60 mean val loss:\t7.596867084503174\n",
      "Epoch 61 mean train loss:\t1.0287683010101318\n",
      "Epoch 61 mean val loss:\t8.332785606384277\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 62 mean train loss:\t1.0572586059570312\n",
      "Epoch 62 mean val loss:\t7.785590648651123\n",
      "Epoch 63 mean train loss:\t1.0593420267105103\n",
      "Epoch 63 mean val loss:\t8.408906936645508\n",
      "Epoch 64 mean train loss:\t1.0559003353118896\n",
      "Epoch 64 mean val loss:\t7.775860786437988\n",
      "Epoch 65 mean train loss:\t1.0705989599227905\n",
      "Epoch 65 mean val loss:\t8.134028434753418\n",
      "Epoch 66 mean train loss:\t1.055936574935913\n",
      "Epoch 66 mean val loss:\t7.490667819976807\n",
      "Epoch 67 mean train loss:\t0.9910942316055298\n",
      "Epoch 67 mean val loss:\t7.764342308044434\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 68 mean train loss:\t0.9922129511833191\n",
      "Epoch 68 mean val loss:\t9.24146556854248\n",
      "Epoch 69 mean train loss:\t1.0179907083511353\n",
      "Epoch 69 mean val loss:\t9.502635955810547\n",
      "Epoch 70 mean train loss:\t1.0219308137893677\n",
      "Epoch 70 mean val loss:\t10.431567192077637\n",
      "Epoch 71 mean train loss:\t0.9928961396217346\n",
      "Epoch 71 mean val loss:\t8.395830154418945\n",
      "Epoch 72 mean train loss:\t0.9807049036026001\n",
      "Epoch 72 mean val loss:\t11.411874771118164\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 73 mean train loss:\t0.9947176575660706\n",
      "Epoch 73 mean val loss:\t10.022611618041992\n",
      "Epoch 74 mean train loss:\t0.976664125919342\n",
      "Epoch 74 mean val loss:\t11.464068412780762\n",
      "Epoch 75 mean train loss:\t1.0195627212524414\n",
      "Epoch 75 mean val loss:\t13.686805725097656\n",
      "Epoch 76 mean train loss:\t0.9811791777610779\n",
      "Epoch 76 mean val loss:\t13.522053718566895\n",
      "Epoch 77 mean train loss:\t0.9510936737060547\n",
      "Epoch 77 mean val loss:\t16.157621383666992\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 78 mean train loss:\t0.9847744107246399\n",
      "Epoch 78 mean val loss:\t13.761590003967285\n",
      "Epoch 79 mean train loss:\t1.021475076675415\n",
      "Epoch 79 mean val loss:\t10.984756469726562\n",
      "Epoch 80 mean train loss:\t0.960742712020874\n",
      "Epoch 80 mean val loss:\t11.810258865356445\n",
      "Epoch 81 mean train loss:\t0.9407254457473755\n",
      "Epoch 81 mean val loss:\t15.496980667114258\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 82 mean train loss:\t0.9057744145393372\n",
      "Epoch 82 mean val loss:\t22.165302276611328\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 83 mean train loss:\t0.9305827617645264\n",
      "Epoch 83 mean val loss:\t14.953794479370117\n",
      "Epoch 84 mean train loss:\t0.9406787753105164\n",
      "Epoch 84 mean val loss:\t9.301942825317383\n",
      "Epoch 85 mean train loss:\t0.9435972571372986\n",
      "Epoch 85 mean val loss:\t11.832823753356934\n",
      "Epoch 86 mean train loss:\t1.0696995258331299\n",
      "Epoch 86 mean val loss:\t9.84911823272705\n",
      "Epoch 87 mean train loss:\t1.0492767095565796\n",
      "Epoch 87 mean val loss:\t8.913147926330566\n",
      "Epoch 88 mean train loss:\t0.988463819026947\n",
      "Epoch 88 mean val loss:\t13.65921688079834\n",
      "Epoch 89 mean train loss:\t0.9316675066947937\n",
      "Epoch 89 mean val loss:\t13.208542823791504\n",
      "Epoch 90 mean train loss:\t0.9263057112693787\n",
      "Epoch 90 mean val loss:\t12.982627868652344\n",
      "Epoch 91 mean train loss:\t0.9195218682289124\n",
      "Epoch 91 mean val loss:\t13.513893127441406\n",
      "Epoch 92 mean train loss:\t0.9600411653518677\n",
      "Epoch 92 mean val loss:\t14.8401460647583\n",
      "Epoch 93 mean train loss:\t0.9393641352653503\n",
      "Epoch 93 mean val loss:\t17.77471351623535\n",
      "Epoch 94 mean train loss:\t0.930375874042511\n",
      "Epoch 94 mean val loss:\t16.11333656311035\n",
      "Epoch 95 mean train loss:\t0.8941763043403625\n",
      "Epoch 95 mean val loss:\t14.706642150878906\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 96 mean train loss:\t0.913963794708252\n",
      "Epoch 96 mean val loss:\t14.891672134399414\n",
      "Epoch 97 mean train loss:\t0.8954423069953918\n",
      "Epoch 97 mean val loss:\t14.711845397949219\n",
      "Epoch 98 mean train loss:\t0.9006811380386353\n",
      "Epoch 98 mean val loss:\t17.622974395751953\n",
      "Epoch 99 mean train loss:\t0.88250333070755\n",
      "Epoch 99 mean val loss:\t20.899478912353516\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 100 mean train loss:\t0.93134605884552\n",
      "Epoch 100 mean val loss:\t18.477798461914062\n",
      "Epoch 101 mean train loss:\t0.9136384129524231\n",
      "Epoch 101 mean val loss:\t17.2593994140625\n",
      "Epoch 102 mean train loss:\t0.8722248673439026\n",
      "Epoch 102 mean val loss:\t18.505664825439453\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 103 mean train loss:\t0.8655602931976318\n",
      "Epoch 103 mean val loss:\t20.906089782714844\n",
      "Epoch 104 mean train loss:\t0.8785855174064636\n",
      "Epoch 104 mean val loss:\t15.174548149108887\n",
      "Epoch 105 mean train loss:\t0.8911164999008179\n",
      "Epoch 105 mean val loss:\t16.11545753479004\n",
      "Epoch 106 mean train loss:\t0.8575112223625183\n",
      "Epoch 106 mean val loss:\t18.956344604492188\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 107 mean train loss:\t0.8500686287879944\n",
      "Epoch 107 mean val loss:\t19.287199020385742\n",
      "Epoch 108 mean train loss:\t0.8492159247398376\n",
      "Epoch 108 mean val loss:\t18.86548614501953\n",
      "Epoch 109 mean train loss:\t0.8227640390396118\n",
      "Epoch 109 mean val loss:\t19.506084442138672\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 110 mean train loss:\t0.894207775592804\n",
      "Epoch 110 mean val loss:\t14.545977592468262\n",
      "Epoch 111 mean train loss:\t0.8580933809280396\n",
      "Epoch 111 mean val loss:\t14.863917350769043\n",
      "Epoch 112 mean train loss:\t0.8739833235740662\n",
      "Epoch 112 mean val loss:\t18.42086410522461\n",
      "Epoch 113 mean train loss:\t0.8661782145500183\n",
      "Epoch 113 mean val loss:\t17.048233032226562\n",
      "Epoch 114 mean train loss:\t0.843519389629364\n",
      "Epoch 114 mean val loss:\t23.18368911743164\n",
      "Epoch 115 mean train loss:\t0.8101498484611511\n",
      "Epoch 115 mean val loss:\t19.19688606262207\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 116 mean train loss:\t0.8401722311973572\n",
      "Epoch 116 mean val loss:\t16.95500373840332\n",
      "Epoch 117 mean train loss:\t0.8321900367736816\n",
      "Epoch 117 mean val loss:\t19.191211700439453\n",
      "Epoch 118 mean train loss:\t0.8161084055900574\n",
      "Epoch 118 mean val loss:\t16.46595001220703\n",
      "Epoch 119 mean train loss:\t0.8029593825340271\n",
      "Epoch 119 mean val loss:\t25.41771697998047\n",
      "Epoch 120 mean train loss:\t0.7955527305603027\n",
      "Epoch 120 mean val loss:\t17.625022888183594\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 121 mean train loss:\t0.7990994453430176\n",
      "Epoch 121 mean val loss:\t21.931699752807617\n",
      "Epoch 122 mean train loss:\t0.7844817042350769\n",
      "Epoch 122 mean val loss:\t19.159927368164062\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 123 mean train loss:\t0.7820504307746887\n",
      "Epoch 123 mean val loss:\t17.963258743286133\n",
      "Epoch 124 mean train loss:\t0.8650949001312256\n",
      "Epoch 124 mean val loss:\t16.96315574645996\n",
      "Epoch 125 mean train loss:\t0.8366020917892456\n",
      "Epoch 125 mean val loss:\t11.517539024353027\n",
      "Epoch 126 mean train loss:\t0.7877162098884583\n",
      "Epoch 126 mean val loss:\t18.007516860961914\n",
      "Epoch 127 mean train loss:\t0.7901728749275208\n",
      "Epoch 127 mean val loss:\t17.685903549194336\n",
      "Epoch 128 mean train loss:\t0.789339542388916\n",
      "Epoch 128 mean val loss:\t18.843812942504883\n",
      "Epoch 129 mean train loss:\t0.8032993674278259\n",
      "Epoch 129 mean val loss:\t18.51675033569336\n",
      "Epoch 130 mean train loss:\t0.7704569101333618\n",
      "Epoch 130 mean val loss:\t22.695510864257812\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 131 mean train loss:\t0.799393892288208\n",
      "Epoch 131 mean val loss:\t21.07512664794922\n",
      "Epoch 132 mean train loss:\t0.7759038209915161\n",
      "Epoch 132 mean val loss:\t18.008403778076172\n",
      "Epoch 133 mean train loss:\t0.7920523881912231\n",
      "Epoch 133 mean val loss:\t18.428686141967773\n",
      "Epoch 134 mean train loss:\t0.7982756495475769\n",
      "Epoch 134 mean val loss:\t21.361352920532227\n",
      "Epoch 135 mean train loss:\t0.7858763933181763\n",
      "Epoch 135 mean val loss:\t21.204635620117188\n",
      "Epoch 136 mean train loss:\t0.7757197618484497\n",
      "Epoch 136 mean val loss:\t20.373720169067383\n",
      "Epoch 137 mean train loss:\t0.7140068411827087\n",
      "Epoch 137 mean val loss:\t25.974214553833008\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 138 mean train loss:\t0.7673212289810181\n",
      "Epoch 138 mean val loss:\t24.357589721679688\n",
      "Epoch 139 mean train loss:\t0.7592982649803162\n",
      "Epoch 139 mean val loss:\t22.383495330810547\n",
      "Epoch 140 mean train loss:\t0.7367475032806396\n",
      "Epoch 140 mean val loss:\t21.71226692199707\n",
      "Epoch 141 mean train loss:\t0.7838351130485535\n",
      "Epoch 141 mean val loss:\t19.235519409179688\n",
      "Epoch 142 mean train loss:\t0.743166983127594\n",
      "Epoch 142 mean val loss:\t25.83281898498535\n",
      "Epoch 143 mean train loss:\t0.7672944068908691\n",
      "Epoch 143 mean val loss:\t17.739627838134766\n",
      "Epoch 144 mean train loss:\t0.8400686383247375\n",
      "Epoch 144 mean val loss:\t16.698537826538086\n",
      "Epoch 145 mean train loss:\t0.7253755331039429\n",
      "Epoch 145 mean val loss:\t25.057723999023438\n",
      "Epoch 146 mean train loss:\t0.7117246389389038\n",
      "Epoch 146 mean val loss:\t19.562145233154297\n",
      "Epoch 147 mean train loss:\t0.7812708616256714\n",
      "Epoch 147 mean val loss:\t19.19379997253418\n",
      "Epoch 148 mean train loss:\t0.754521369934082\n",
      "Epoch 148 mean val loss:\t22.04454231262207\n",
      "Epoch 149 mean train loss:\t0.7805613279342651\n",
      "Epoch 149 mean val loss:\t21.02672004699707\n",
      "Epoch 150 mean train loss:\t0.7480648159980774\n",
      "Epoch 150 mean val loss:\t18.575668334960938\n",
      "Epoch 151 mean train loss:\t0.7232840657234192\n",
      "Epoch 151 mean val loss:\t19.686416625976562\n",
      "Epoch 152 mean train loss:\t0.72064608335495\n",
      "Epoch 152 mean val loss:\t17.11836051940918\n",
      "Epoch 153 mean train loss:\t1.0411200523376465\n",
      "Epoch 153 mean val loss:\t14.075194358825684\n",
      "Epoch 154 mean train loss:\t1.2457982301712036\n",
      "Epoch 154 mean val loss:\t4.837113857269287\n",
      "Epoch 155 mean train loss:\t0.9292445182800293\n",
      "Epoch 155 mean val loss:\t11.178592681884766\n",
      "Epoch 156 mean train loss:\t0.836986780166626\n",
      "Epoch 156 mean val loss:\t15.751456260681152\n",
      "Epoch 157 mean train loss:\t0.8001260757446289\n",
      "Epoch 157 mean val loss:\t24.54601287841797\n",
      "Epoch 158 mean train loss:\t0.7452252507209778\n",
      "Epoch 158 mean val loss:\t17.036848068237305\n",
      "Epoch 159 mean train loss:\t0.762195885181427\n",
      "Epoch 159 mean val loss:\t19.573013305664062\n",
      "Epoch 160 mean train loss:\t0.8171001672744751\n",
      "Epoch 160 mean val loss:\t24.30609130859375\n",
      "Epoch 161 mean train loss:\t0.7336046099662781\n",
      "Epoch 161 mean val loss:\t29.238948822021484\n",
      "Epoch 162 mean train loss:\t0.7381434440612793\n",
      "Epoch 162 mean val loss:\t26.034326553344727\n",
      "Epoch 163 mean train loss:\t0.7365832924842834\n",
      "Epoch 163 mean val loss:\t21.354137420654297\n",
      "Epoch 164 mean train loss:\t0.9684060215950012\n",
      "Epoch 164 mean val loss:\t19.195030212402344\n",
      "Epoch 165 mean train loss:\t1.14126718044281\n",
      "Epoch 165 mean val loss:\t6.59358549118042\n",
      "Epoch 166 mean train loss:\t0.9475180506706238\n",
      "Epoch 166 mean val loss:\t20.298229217529297\n",
      "Epoch 167 mean train loss:\t0.8857361674308777\n",
      "Epoch 167 mean val loss:\t25.8822078704834\n",
      "Epoch 168 mean train loss:\t0.8552460670471191\n",
      "Epoch 168 mean val loss:\t32.150352478027344\n",
      "Epoch 169 mean train loss:\t0.7937082648277283\n",
      "Epoch 169 mean val loss:\t39.759437561035156\n",
      "Epoch 170 mean train loss:\t0.7502428889274597\n",
      "Epoch 170 mean val loss:\t36.5909423828125\n",
      "Epoch 171 mean train loss:\t0.7625900506973267\n",
      "Epoch 171 mean val loss:\t25.50240135192871\n",
      "Epoch 172 mean train loss:\t0.7553300261497498\n",
      "Epoch 172 mean val loss:\t31.56752586364746\n",
      "Epoch 173 mean train loss:\t0.7420068979263306\n",
      "Epoch 173 mean val loss:\t26.79633331298828\n",
      "Epoch 174 mean train loss:\t0.7594968676567078\n",
      "Epoch 174 mean val loss:\t21.72641944885254\n",
      "Epoch 175 mean train loss:\t0.7296334505081177\n",
      "Epoch 175 mean val loss:\t27.69112777709961\n",
      "Epoch 176 mean train loss:\t0.7515533566474915\n",
      "Epoch 176 mean val loss:\t25.999374389648438\n",
      "Epoch 177 mean train loss:\t0.7533355355262756\n",
      "Epoch 177 mean val loss:\t20.541519165039062\n",
      "Epoch 178 mean train loss:\t0.7549812197685242\n",
      "Epoch 178 mean val loss:\t19.948862075805664\n",
      "Epoch 179 mean train loss:\t0.7574124336242676\n",
      "Epoch 179 mean val loss:\t19.647117614746094\n",
      "Epoch 180 mean train loss:\t0.7436336874961853\n",
      "Epoch 180 mean val loss:\t19.016658782958984\n",
      "Epoch 181 mean train loss:\t0.7523297667503357\n",
      "Epoch 181 mean val loss:\t17.877954483032227\n",
      "Epoch 182 mean train loss:\t0.7367837429046631\n",
      "Epoch 182 mean val loss:\t23.85980796813965\n",
      "Epoch 183 mean train loss:\t0.7146681547164917\n",
      "Epoch 183 mean val loss:\t24.323509216308594\n",
      "Epoch 184 mean train loss:\t0.7265965342521667\n",
      "Epoch 184 mean val loss:\t22.69273567199707\n",
      "Epoch 185 mean train loss:\t0.7342653274536133\n",
      "Epoch 185 mean val loss:\t21.30401039123535\n",
      "Epoch 186 mean train loss:\t0.7021061778068542\n",
      "Epoch 186 mean val loss:\t24.070043563842773\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 187 mean train loss:\t0.7208698987960815\n",
      "Epoch 187 mean val loss:\t20.60248374938965\n",
      "Epoch 188 mean train loss:\t0.7318999171257019\n",
      "Epoch 188 mean val loss:\t18.49932098388672\n",
      "Epoch 189 mean train loss:\t0.7678413391113281\n",
      "Epoch 189 mean val loss:\t18.66840362548828\n",
      "Epoch 190 mean train loss:\t0.7124890089035034\n",
      "Epoch 190 mean val loss:\t18.927490234375\n",
      "Epoch 191 mean train loss:\t0.709861695766449\n",
      "Epoch 191 mean val loss:\t15.860076904296875\n",
      "Epoch 192 mean train loss:\t0.6937710642814636\n",
      "Epoch 192 mean val loss:\t18.358802795410156\n",
      "Epoch 193 mean train loss:\t0.720583975315094\n",
      "Epoch 193 mean val loss:\t14.388172149658203\n",
      "Epoch 194 mean train loss:\t0.6816844940185547\n",
      "Epoch 194 mean val loss:\t13.956865310668945\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 195 mean train loss:\t0.8023352026939392\n",
      "Epoch 195 mean val loss:\t17.507476806640625\n",
      "Epoch 196 mean train loss:\t0.7026158571243286\n",
      "Epoch 196 mean val loss:\t19.353761672973633\n",
      "Epoch 197 mean train loss:\t0.6960718631744385\n",
      "Epoch 197 mean val loss:\t20.227712631225586\n",
      "Epoch 198 mean train loss:\t0.7882372140884399\n",
      "Epoch 198 mean val loss:\t11.288606643676758\n",
      "Epoch 199 mean train loss:\t0.6990985870361328\n",
      "Epoch 199 mean val loss:\t16.92937660217285\n",
      "Epoch 200 mean train loss:\t0.7387484908103943\n",
      "Epoch 200 mean val loss:\t13.943702697753906\n",
      "Epoch 201 mean train loss:\t0.6892406344413757\n",
      "Epoch 201 mean val loss:\t16.810314178466797\n",
      "Epoch 202 mean train loss:\t0.6773536205291748\n",
      "Epoch 202 mean val loss:\t17.077741622924805\n",
      "Epoch 203 mean train loss:\t0.7016015648841858\n",
      "Epoch 203 mean val loss:\t16.423810958862305\n",
      "Epoch 204 mean train loss:\t0.6919611096382141\n",
      "Epoch 204 mean val loss:\t15.498315811157227\n",
      "Epoch 205 mean train loss:\t0.7149284482002258\n",
      "Epoch 205 mean val loss:\t12.389713287353516\n",
      "Epoch 206 mean train loss:\t0.7275326251983643\n",
      "Epoch 206 mean val loss:\t13.627241134643555\n",
      "Epoch 207 mean train loss:\t0.6966615915298462\n",
      "Epoch 207 mean val loss:\t16.14564323425293\n",
      "Epoch 208 mean train loss:\t0.8078434467315674\n",
      "Epoch 208 mean val loss:\t14.700139045715332\n",
      "Epoch 209 mean train loss:\t0.7503532767295837\n",
      "Epoch 209 mean val loss:\t12.813092231750488\n",
      "Epoch 210 mean train loss:\t0.7209186553955078\n",
      "Epoch 210 mean val loss:\t17.075395584106445\n",
      "Epoch 211 mean train loss:\t0.7066308856010437\n",
      "Epoch 211 mean val loss:\t16.203996658325195\n",
      "Epoch 212 mean train loss:\t0.7106888294219971\n",
      "Epoch 212 mean val loss:\t16.713171005249023\n",
      "Epoch 213 mean train loss:\t0.6975748538970947\n",
      "Epoch 213 mean val loss:\t13.515739440917969\n",
      "Epoch 214 mean train loss:\t0.6901884078979492\n",
      "Epoch 214 mean val loss:\t14.590840339660645\n",
      "Epoch 215 mean train loss:\t0.6917960047721863\n",
      "Epoch 215 mean val loss:\t15.026787757873535\n",
      "Epoch 216 mean train loss:\t0.6683877110481262\n",
      "Epoch 216 mean val loss:\t15.540963172912598\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 217 mean train loss:\t0.6960201859474182\n",
      "Epoch 217 mean val loss:\t14.502305030822754\n",
      "Epoch 218 mean train loss:\t0.714655339717865\n",
      "Epoch 218 mean val loss:\t13.817150115966797\n",
      "Epoch 219 mean train loss:\t0.6914581656455994\n",
      "Epoch 219 mean val loss:\t16.32248306274414\n",
      "Epoch 220 mean train loss:\t0.6884588003158569\n",
      "Epoch 220 mean val loss:\t13.926923751831055\n",
      "Epoch 221 mean train loss:\t0.6797478199005127\n",
      "Epoch 221 mean val loss:\t16.065168380737305\n",
      "Epoch 222 mean train loss:\t0.6932867169380188\n",
      "Epoch 222 mean val loss:\t13.69963264465332\n",
      "Epoch 223 mean train loss:\t0.6913227438926697\n",
      "Epoch 223 mean val loss:\t14.925119400024414\n",
      "Epoch 224 mean train loss:\t0.6722408533096313\n",
      "Epoch 224 mean val loss:\t17.136924743652344\n",
      "Epoch 225 mean train loss:\t0.6862136721611023\n",
      "Epoch 225 mean val loss:\t14.928628921508789\n",
      "Epoch 226 mean train loss:\t0.658815860748291\n",
      "Epoch 226 mean val loss:\t17.332361221313477\n",
      "Epoch 227 mean train loss:\t0.8423227667808533\n",
      "Epoch 227 mean val loss:\t15.14464282989502\n",
      "Epoch 228 mean train loss:\t0.7850289940834045\n",
      "Epoch 228 mean val loss:\t15.673345565795898\n",
      "Epoch 229 mean train loss:\t0.7088201642036438\n",
      "Epoch 229 mean val loss:\t14.853811264038086\n",
      "Epoch 230 mean train loss:\t0.6716644763946533\n",
      "Epoch 230 mean val loss:\t13.955781936645508\n",
      "Epoch 231 mean train loss:\t0.7138094902038574\n",
      "Epoch 231 mean val loss:\t14.377516746520996\n",
      "Epoch 232 mean train loss:\t0.7316722273826599\n",
      "Epoch 232 mean val loss:\t13.845982551574707\n",
      "Epoch 233 mean train loss:\t0.6536311507225037\n",
      "Epoch 233 mean val loss:\t12.118515014648438\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n",
      "Epoch 234 mean train loss:\t0.6690913438796997\n",
      "Epoch 234 mean val loss:\t11.388773918151855\n",
      "Epoch 235 mean train loss:\t0.7359643578529358\n",
      "Epoch 235 mean val loss:\t14.54350471496582\n",
      "Epoch 236 mean train loss:\t0.7168107628822327\n",
      "Epoch 236 mean val loss:\t13.28355884552002\n",
      "Epoch 237 mean train loss:\t0.6870843768119812\n",
      "Epoch 237 mean val loss:\t10.776283264160156\n",
      "Epoch 238 mean train loss:\t0.6652207374572754\n",
      "Epoch 238 mean val loss:\t12.700505256652832\n",
      "Epoch 239 mean train loss:\t0.6771507859230042\n",
      "Epoch 239 mean val loss:\t11.103169441223145\n",
      "Epoch 240 mean train loss:\t0.7482846975326538\n",
      "Epoch 240 mean val loss:\t12.55496597290039\n",
      "Epoch 241 mean train loss:\t0.674405574798584\n",
      "Epoch 241 mean val loss:\t13.453435897827148\n",
      "Epoch 242 mean train loss:\t0.6472139358520508\n",
      "Epoch 242 mean val loss:\t12.65585708618164\n",
      "Epoch 243 mean train loss:\t0.654871940612793\n",
      "Epoch 243 mean val loss:\t12.834604263305664\n",
      "Epoch 244 mean train loss:\t0.6556161642074585\n",
      "Epoch 244 mean val loss:\t13.270147323608398\n",
      "Epoch 245 mean train loss:\t0.6733737587928772\n",
      "Epoch 245 mean val loss:\t11.748688697814941\n",
      "Epoch 246 mean train loss:\t0.656323254108429\n",
      "Epoch 246 mean val loss:\t11.627009391784668\n",
      "Epoch 247 mean train loss:\t0.713534414768219\n",
      "Epoch 247 mean val loss:\t13.04383659362793\n",
      "Epoch 248 mean train loss:\t0.6647617220878601\n",
      "Epoch 248 mean val loss:\t12.459999084472656\n",
      "Epoch 249 mean train loss:\t0.6641168594360352\n",
      "Epoch 249 mean val loss:\t11.639379501342773\n",
      "Using best model from epoch 233 which had loss 0.6536311507225037\n",
      "Saved model as /home/mgauch/runoff-nn/src/../pickle/models/ConvLSTM_simulationTraining_allStations_20190817-095426.pkl\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_losses = torch.tensor(0.0)\n",
    "    val_losses = torch.tensor(0.0)\n",
    "    conv_hidden_states = None\n",
    "    for i, train_batch in enumerate(train_dataloader):\n",
    "        geophysical_input = geophysical_batch[:train_batch['y_sim'].shape[0]]\n",
    "        x_conv, geophysical_input, y_train, y_sim_means, train_mask_transformed, val_mask_transformed = \\\n",
    "            utils.random_transform(train_batch['x_conv'], geophysical_input, train_batch['y_sim'], train_dataset.y_sim_means, \n",
    "                                   train_mask, val_mask, rdrs_contains_month=include_month, border_masking=20, p=p_random_transform)\n",
    "        y_train = y_train.reshape((y_train.shape[0],-1)).to(device, non_blocking=True)\n",
    "        y_sim_means = y_sim_means.reshape(-1).to(device, non_blocking=True)\n",
    "        train_mask_transformed = train_mask_transformed.reshape(-1).to(device, non_blocking=True)\n",
    "        val_mask_transformed = val_mask_transformed.reshape(-1).to(device, non_blocking=True)\n",
    "        \n",
    "        if not train_mask_transformed.any():\n",
    "            print('Batch {} has no target values. skipping.'.format(i))\n",
    "            continue\n",
    "        if not stateful_lstm:\n",
    "            conv_hidden_states = None\n",
    "        \n",
    "        y_pred, conv_hidden_states = model(x_conv.to(device), geophysical_input.to(device), hidden_state=conv_hidden_states)\n",
    "        y_pred = y_pred.reshape((y_train.shape[0], -1))\n",
    "        train_loss = loss_fn(y_pred[:,train_mask_transformed], y_train[:,train_mask_transformed], \n",
    "                             means=y_sim_means[train_mask_transformed])\n",
    "        val_losses += loss_fn(y_pred[:,val_mask_transformed], y_train[:,val_mask_transformed], \n",
    "                              means=y_sim_means[val_mask_transformed]).detach()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses += train_loss.detach()\n",
    "        \n",
    "    train_loss = (train_losses / len(train_dataloader)).item()\n",
    "    val_loss = (val_losses / len(train_dataloader)).item()\n",
    "    print('Epoch', epoch, 'mean train loss:\\t{}'.format(train_loss))\n",
    "    print('Epoch', epoch, 'mean val loss:\\t{}'.format(val_loss))\n",
    "    writer.add_scalar('loss_nse', train_loss, epoch)\n",
    "    writer.add_scalar('loss_nse_val', val_loss, epoch)\n",
    "    \n",
    "    if train_loss < best_loss_model[1] - min_improvement:\n",
    "        best_loss_model = (epoch, train_loss, model.state_dict())  # new best model\n",
    "        load_data.pickle_model('ConvLSTM_simulationTraining', model, 'allStations', time_stamp)\n",
    "    elif epoch > best_loss_model[0] + patience:\n",
    "        print('Patience exhausted in epoch {}. Best train-loss was {}'.format(epoch, best_loss_model[1]))\n",
    "        break\n",
    "    \n",
    "print('Using best model from epoch', str(best_loss_model[0]), 'which had loss', str(best_loss_model[1]))\n",
    "model.load_state_dict(best_loss_model[2])\n",
    "load_data.save_model_with_state('ConvLSTM_simulationTraining', best_loss_model[0], model, optimizer, time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del train_mask_transformed, val_mask_transformed, y_train, y_pred, y_sim_means\n",
    "if USE_CUDA:\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-17 16:48:42,580 - 20190817-095426 - predicting\n"
     ]
    }
   ],
   "source": [
    "logger.warning('predicting')\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "conv_hidden_states = None\n",
    "for i, test_batch in enumerate(test_dataloader):\n",
    "    if not stateful_lstm:\n",
    "        conv_hidden_states = None\n",
    "        \n",
    "    geophysical_input = geophysical_batch[:test_batch['y_sim'].shape[0]]\n",
    "    pred, conv_hidden_states = model(test_batch['x_conv'].to(device), geophysical_input.to(device), hidden_state=conv_hidden_states)\n",
    "    predictions.append(pred.detach().cpu())\n",
    "    \n",
    "predictions = torch.cat(predictions).cpu()\n",
    "\n",
    "if stateful_lstm:\n",
    "    # reorder time series\n",
    "    pred_indices = np.array(list(test_sampler.__iter__())).reshape(-1)\n",
    "    predictions = predictions[pred_indices.argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \tNSE sim: -1.1557462124772169 \tMSE sim: 2494043.0073844944\n",
      "2 \tNSE sim: -0.6297592901758091 \tMSE sim: 138.32987309406877\n",
      "3 \tNSE sim: -0.18459778018629236 \tMSE sim: 37.696220614391805\n",
      "4 \tNSE sim: -0.034309712131826764 \tMSE sim: 17.624136160275437\n",
      "5 \tNSE sim: -0.012707673259664709 \tMSE sim: 24.5626714537254\n",
      "6 \tNSE sim: 0.12329275786464644 \tMSE sim: 5.087395158802028\n",
      "7 \tNSE sim: 0.37819912205174266 \tMSE sim: 1.7240176683092614\n",
      "8 \tNSE sim: 0.2426458630264856 \tMSE sim: 5.765352521647773\n",
      "9 \tNSE sim: 0.35344014416157643 \tMSE sim: 2.6244652662358563\n",
      "10 \tNSE sim: 0.28454311859109704 \tMSE sim: 4.077986351120026\n",
      "11 \tNSE sim: -0.08358677037670481 \tMSE sim: 13.223163364420579\n",
      "12 \tNSE sim: 0.2189121481689329 \tMSE sim: 2.2985816416629263\n",
      "13 \tNSE sim: 0.03243501050915776 \tMSE sim: 3.713331318198565\n",
      "14 \tNSE sim: -0.7428994775209901 \tMSE sim: 467.6320946825756\n",
      "15 \tNSE sim: -0.7788833102551747 \tMSE sim: 214.40280591280293\n",
      "16 \tNSE sim: -0.029453616986924835 \tMSE sim: 15.06194438887841\n",
      "17 \tNSE sim: 0.002749117362624731 \tMSE sim: 93.63506327693622\n",
      "18 \tNSE sim: -0.9150854196490803 \tMSE sim: 13766.538889100706\n",
      "19 \tNSE sim: -0.15541130487288246 \tMSE sim: 6.810259342729072\n",
      "20 \tNSE sim: 0.14291773529451512 \tMSE sim: 50.69156367982033\n",
      "21 \tNSE sim: -0.9059639676343412 \tMSE sim: 13426.500000493274\n",
      "22 \tNSE sim: 0.14145672084386518 \tMSE sim: 3.9503860870344143\n",
      "23 \tNSE sim: -0.0447684743596215 \tMSE sim: 9.717799421353103\n",
      "24 \tNSE sim: 0.19674115194861963 \tMSE sim: 4.016090063277843\n",
      "25 \tNSE sim: -0.8860720765691061 \tMSE sim: 11505.769642701829\n",
      "26 \tNSE sim: 0.17142819676927568 \tMSE sim: 24.186872059009737\n",
      "27 \tNSE sim: 0.3320375097680951 \tMSE sim: 4.16847253504255\n",
      "28 \tNSE sim: 0.35078055145162723 \tMSE sim: 4.97138772591638\n",
      "29 \tNSE sim: 0.05858131640982489 \tMSE sim: 4.178255583460223\n",
      "30 \tNSE sim: -0.8897271160567448 \tMSE sim: 10741.457314535784\n",
      "31 \tNSE sim: -0.10330636376457836 \tMSE sim: 34.31086361177485\n",
      "32 \tNSE sim: -0.8627168969048873 \tMSE sim: 9263.643614288478\n",
      "33 \tNSE sim: 0.22128345018547357 \tMSE sim: 5.006094235659069\n",
      "34 \tNSE sim: 0.3102119419224877 \tMSE sim: 2.165012469074468\n",
      "35 \tNSE sim: 0.25360636661189595 \tMSE sim: 3.0702865932738765\n",
      "36 \tNSE sim: 0.1931041417873457 \tMSE sim: 2.4627424835171765\n",
      "37 \tNSE sim: -0.3870514017304303 \tMSE sim: 166.27736644292958\n",
      "38 \tNSE sim: -0.30379893659557755 \tMSE sim: 108.25240342532526\n",
      "39 \tNSE sim: 0.18860983754514105 \tMSE sim: 26.266387027682732\n",
      "40 \tNSE sim: -0.780280708403154 \tMSE sim: 7409.953481773669\n",
      "41 \tNSE sim: 0.35663022395821864 \tMSE sim: 3.073972307175745\n",
      "42 \tNSE sim: 0.19609385710208094 \tMSE sim: 223.99279937795487\n",
      "43 \tNSE sim: -0.02734494245089869 \tMSE sim: 44.01283518909402\n",
      "44 \tNSE sim: -0.43069577631653666 \tMSE sim: 3361.747755282378\n",
      "45 \tNSE sim: -0.5116486740997988 \tMSE sim: 69.0930469020837\n",
      "46 \tNSE sim: -0.018306341110193136 \tMSE sim: 20.765981148227645\n",
      "47 \tNSE sim: -0.15208038988400197 \tMSE sim: 264.39146449033234\n",
      "48 \tNSE sim: 0.17742167949169774 \tMSE sim: 8.89005881116056\n",
      "49 \tNSE sim: -11.751836769347742 \tMSE sim: 31.228546623815014\n",
      "50 \tNSE sim: -0.5390843355602544 \tMSE sim: 3361.0084326427736\n",
      "51 \tNSE sim: -0.6428312777409884 \tMSE sim: 37.8888135326746\n",
      "52 \tNSE sim: 0.22257988270333973 \tMSE sim: 6.15528435433103\n",
      "53 \tNSE sim: -0.3504214983797558 \tMSE sim: 97.96324009015305\n",
      "54 \tNSE sim: 0.1365374506689182 \tMSE sim: 4.593218639171045\n",
      "55 \tNSE sim: 0.232564152773438 \tMSE sim: 74.24567172655833\n",
      "56 \tNSE sim: -0.35520152552898443 \tMSE sim: 1889.8299830238323\n",
      "57 \tNSE sim: 0.051080707268972514 \tMSE sim: 26.874272027933827\n",
      "58 \tNSE sim: 0.1356937847530063 \tMSE sim: 158.8994613626478\n",
      "59 \tNSE sim: 0.17000493015881424 \tMSE sim: 114.98157727790426\n",
      "60 \tNSE sim: -0.08626914465274194 \tMSE sim: 17.982615764289093\n",
      "61 \tNSE sim: -0.4446427851053203 \tMSE sim: 1832.4817836410753\n",
      "62 \tNSE sim: -0.007818419061024429 \tMSE sim: 19.072904489500285\n",
      "63 \tNSE sim: 0.04457694946316981 \tMSE sim: 41.3625138796398\n",
      "64 \tNSE sim: 0.06978374656705988 \tMSE sim: 8.3629807058462\n",
      "65 \tNSE sim: 0.24749905216051948 \tMSE sim: 8.628289658309749\n",
      "66 \tNSE sim: 0.02480678610060827 \tMSE sim: 10.638997557847514\n",
      "67 \tNSE sim: 0.12562534561699734 \tMSE sim: 12.784002470734816\n",
      "68 \tNSE sim: -0.20915100763502337 \tMSE sim: 117.88367623136688\n",
      "69 \tNSE sim: 0.23832599756387773 \tMSE sim: 2.8854535000073755\n",
      "70 \tNSE sim: 0.265654065686186 \tMSE sim: 2.276231202020549\n",
      "71 \tNSE sim: -0.14989503665788972 \tMSE sim: 22.181309918813266\n",
      "72 \tNSE sim: -0.010958248584288066 \tMSE sim: 192.19060602909582\n",
      "73 \tNSE sim: -0.2224518417242678 \tMSE sim: 480.8437736330108\n",
      "74 \tNSE sim: 0.2427391660752971 \tMSE sim: 2.1093777112805627\n",
      "75 \tNSE sim: 0.24534297564934637 \tMSE sim: 7.989296141050258\n",
      "76 \tNSE sim: -0.40108276929352393 \tMSE sim: 332.9581930256375\n",
      "77 \tNSE sim: 0.3472777655657381 \tMSE sim: 2.890871774568846\n",
      "78 \tNSE sim: -0.22848394403189975 \tMSE sim: 78.47335184126378\n",
      "79 \tNSE sim: 0.06586141544481194 \tMSE sim: 3.291579861011127\n",
      "80 \tNSE sim: -0.1596387322795616 \tMSE sim: 14.614446350675603\n",
      "81 \tNSE sim: -0.2131208252594572 \tMSE sim: 155.43277180025626\n",
      "82 \tNSE sim: 0.16614487381482212 \tMSE sim: 3.698532908995537\n",
      "83 \tNSE sim: -0.3317898207367691 \tMSE sim: 165.5210272006099\n",
      "84 \tNSE sim: 0.1862307045009145 \tMSE sim: 7.1268245190658766\n",
      "85 \tNSE sim: -0.463519978677325 \tMSE sim: 488.4332583532128\n",
      "86 \tNSE sim: 0.09299934277016109 \tMSE sim: 8.526563298050922\n",
      "87 \tNSE sim: 0.1198794907511983 \tMSE sim: 7.212486997271101\n",
      "88 \tNSE sim: -0.10991678954822115 \tMSE sim: 319.56035313162056\n",
      "89 \tNSE sim: 0.1423464591234972 \tMSE sim: 2.3500326462064605\n",
      "90 \tNSE sim: -0.5572702465413037 \tMSE sim: 54.74103899434\n",
      "91 \tNSE sim: -0.5060627808236231 \tMSE sim: 372.2137867727239\n",
      "92 \tNSE sim: 0.027559020170399462 \tMSE sim: 4.5423807329001535\n",
      "93 \tNSE sim: 0.03736299023184497 \tMSE sim: 4.779178592422386\n",
      "94 \tNSE sim: 0.15977256321754474 \tMSE sim: 3.669276223547478\n",
      "95 \tNSE sim: -0.2368730586923098 \tMSE sim: 56.670439740603236\n",
      "96 \tNSE sim: -0.022176349540825147 \tMSE sim: 3.6244371752431506\n",
      "97 \tNSE sim: -0.14072661301776623 \tMSE sim: 3.4184979804287905\n",
      "98 \tNSE sim: 0.30591845912908233 \tMSE sim: 6.653843627776583\n",
      "99 \tNSE sim: -0.48608375784085944 \tMSE sim: 190.72262868440095\n",
      "100 \tNSE sim: -0.18351020204554147 \tMSE sim: 34.95174754243673\n",
      "101 \tNSE sim: -0.08719893059416406 \tMSE sim: 2.7967701266481706\n",
      "102 \tNSE sim: -1.212815718031909 \tMSE sim: 1073.455337516584\n",
      "103 \tNSE sim: 0.28737856330780354 \tMSE sim: 3.8900183618171007\n",
      "104 \tNSE sim: -0.476848064646451 \tMSE sim: 90.22427948492337\n",
      "105 \tNSE sim: 0.12981328396079195 \tMSE sim: 6.070569806440314\n",
      "106 \tNSE sim: 0.3575827920699646 \tMSE sim: 28.96353377083731\n",
      "107 \tNSE sim: -0.4279203553532376 \tMSE sim: 3.63363363261293\n",
      "108 \tNSE sim: -4.9293738245070875 \tMSE sim: 50.52063757123927\n",
      "109 \tNSE sim: -0.14296351386688433 \tMSE sim: 355.1000726135704\n",
      "110 \tNSE sim: -0.4172938985223624 \tMSE sim: 41.43460728969862\n",
      "111 \tNSE sim: 0.16634001149655242 \tMSE sim: 3.959214864685094\n",
      "112 \tNSE sim: 0.16537717721065526 \tMSE sim: 2.3325738555296485\n",
      "113 \tNSE sim: 0.09461940659309231 \tMSE sim: 28.297808465321847\n",
      "114 \tNSE sim: -0.29870770285748627 \tMSE sim: 26.258923554841942\n",
      "115 \tNSE sim: -0.1605021564766247 \tMSE sim: 17.5293100243093\n",
      "116 \tNSE sim: -17.75275960314488 \tMSE sim: 29.567045219416936\n",
      "117 \tNSE sim: -0.3795187044751147 \tMSE sim: 318.4047427094855\n",
      "118 \tNSE sim: 0.2522837357331458 \tMSE sim: 6.83151281573181\n",
      "119 \tNSE sim: -0.7641637928484928 \tMSE sim: 3.4786642769988547\n",
      "120 \tNSE sim: 0.297223478775977 \tMSE sim: 1.4659792352656889\n",
      "121 \tNSE sim: 0.038459509462419716 \tMSE sim: 9.532632303253234\n",
      "122 \tNSE sim: -0.511786862075793 \tMSE sim: 288.66804955801575\n",
      "123 \tNSE sim: -0.16389724021095198 \tMSE sim: 33.82128668147667\n",
      "124 \tNSE sim: -0.1571497407543596 \tMSE sim: 35.54891000508419\n",
      "125 \tNSE sim: -0.18264451279491456 \tMSE sim: 18.506462784280743\n",
      "126 \tNSE sim: -0.5407866776946426 \tMSE sim: 121.19015520868246\n",
      "127 \tNSE sim: -0.17841635347838403 \tMSE sim: 3.985419586696923\n",
      "128 \tNSE sim: -0.022934234171616552 \tMSE sim: 2.8622530522758414\n",
      "129 \tNSE sim: -0.5019103963362299 \tMSE sim: 7.376004439556246\n",
      "130 \tNSE sim: 0.1396177418694985 \tMSE sim: 13.09027378902454\n",
      "131 \tNSE sim: 0.09465831552181847 \tMSE sim: 12.780447616158826\n",
      "132 \tNSE sim: 0.1882950898655361 \tMSE sim: 3.746511936997793\n",
      "133 \tNSE sim: -1.0009245239433673 \tMSE sim: 9.299839249687773\n",
      "134 \tNSE sim: 0.284095461910567 \tMSE sim: 23.471811587022728\n",
      "135 \tNSE sim: 0.2192380385626731 \tMSE sim: 1.4499394288355871\n",
      "136 \tNSE sim: -0.17030215718093644 \tMSE sim: 34.99844166101104\n",
      "137 \tNSE sim: -0.14840941009099562 \tMSE sim: 67.3638125962592\n",
      "138 \tNSE sim: 0.22083295077564613 \tMSE sim: 7.72619284833916\n",
      "139 \tNSE sim: 0.2637932100566195 \tMSE sim: 3.0511133787618054\n",
      "140 \tNSE sim: 0.1339680094267447 \tMSE sim: 3.1768775600911208\n",
      "141 \tNSE sim: -0.005513309022252999 \tMSE sim: 21.860556809844933\n",
      "142 \tNSE sim: 0.2166221352692067 \tMSE sim: 1.8705010416760737\n",
      "143 \tNSE sim: -0.2553776087029933 \tMSE sim: 8.727775413503469\n",
      "144 \tNSE sim: 0.08936177302899584 \tMSE sim: 13.850053097978575\n",
      "145 \tNSE sim: 0.189764850326823 \tMSE sim: 4.623612934898308\n",
      "146 \tNSE sim: -0.5478105561677786 \tMSE sim: 333.20710397425523\n",
      "147 \tNSE sim: 0.010378942992847029 \tMSE sim: 7.824800035256835\n",
      "148 \tNSE sim: 0.22426796931798443 \tMSE sim: 3.710274346781507\n",
      "149 \tNSE sim: 0.3737125083899444 \tMSE sim: 1.6826686008262766\n",
      "150 \tNSE sim: 0.19620253807824528 \tMSE sim: 4.786548117875391\n",
      "151 \tNSE sim: 0.21005549059487838 \tMSE sim: 1.616208797820092\n",
      "152 \tNSE sim: -0.44982176193114976 \tMSE sim: 793.8068745458565\n",
      "153 \tNSE sim: -0.5897477282973174 \tMSE sim: 1959.6551701580945\n",
      "154 \tNSE sim: 0.2268925187463573 \tMSE sim: 3.0790299478451493\n",
      "155 \tNSE sim: 0.21303055825006567 \tMSE sim: 5.43012754274361\n",
      "156 \tNSE sim: 0.2005613225496965 \tMSE sim: 8.14308956937192\n",
      "157 \tNSE sim: -0.9299495605537362 \tMSE sim: 91034.08671059473\n",
      "158 \tNSE sim: 0.2538055080135586 \tMSE sim: 4.519240453562268\n",
      "159 \tNSE sim: -0.32891658701280346 \tMSE sim: 188.47409827894626\n",
      "160 \tNSE sim: 0.24595340520205222 \tMSE sim: 2.302340891459293\n",
      "161 \tNSE sim: -0.5649427652960402 \tMSE sim: 1667.030115913451\n",
      "162 \tNSE sim: 0.20369941813518733 \tMSE sim: 3.2922689159675405\n",
      "163 \tNSE sim: -0.5331841245679059 \tMSE sim: 1.6481102043087672\n",
      "164 \tNSE sim: 0.2640944522998514 \tMSE sim: 2.212873136424608\n",
      "165 \tNSE sim: 0.20478455149713048 \tMSE sim: 1.5486289799361568\n",
      "166 \tNSE sim: 0.21902029074016272 \tMSE sim: 1.880780322406997\n",
      "167 \tNSE sim: -0.928533772886234 \tMSE sim: 90306.94467315586\n",
      "168 \tNSE sim: -0.14882493805143104 \tMSE sim: 5.539034611918479\n",
      "169 \tNSE sim: 0.2349198792613969 \tMSE sim: 2.9379342473756207\n",
      "170 \tNSE sim: -0.35806435614522103 \tMSE sim: 47.7342885624661\n",
      "171 \tNSE sim: -0.6311497819353145 \tMSE sim: 52316.18863599849\n",
      "172 \tNSE sim: -0.0061784002938543026 \tMSE sim: 6.586447385320252\n",
      "173 \tNSE sim: -0.32104316196267746 \tMSE sim: 265.15102699157967\n",
      "174 \tNSE sim: 0.2489446800152446 \tMSE sim: 1.479346375107091\n",
      "175 \tNSE sim: -0.6023537009706601 \tMSE sim: 1491.6725269232293\n",
      "176 \tNSE sim: -0.8547153869794819 \tMSE sim: 75460.36765697232\n",
      "177 \tNSE sim: -1.1997731680527144 \tMSE sim: 681.4717308015198\n",
      "178 \tNSE sim: 0.2404424633475939 \tMSE sim: 4.1688904281786465\n",
      "179 \tNSE sim: -0.11872396386397521 \tMSE sim: 40.91035720093485\n",
      "180 \tNSE sim: -0.2647401964550955 \tMSE sim: 90.62695349216666\n",
      "181 \tNSE sim: 0.1055827791699483 \tMSE sim: 8.4382575878221\n",
      "182 \tNSE sim: 0.14219298908687117 \tMSE sim: 1.471656464875839\n",
      "183 \tNSE sim: -0.4957201582807429 \tMSE sim: 352.61182096732017\n",
      "184 \tNSE sim: -0.2660569689077188 \tMSE sim: 33.62100822711525\n",
      "185 \tNSE sim: -0.6252903316154295 \tMSE sim: 1044.9067794121997\n",
      "186 \tNSE sim: 0.27872617789937737 \tMSE sim: 2.7413516104601063\n",
      "187 \tNSE sim: -0.22849781445643913 \tMSE sim: 183.0627275446925\n",
      "188 \tNSE sim: 0.0426129486543374 \tMSE sim: 15.734362617920146\n",
      "189 \tNSE sim: 0.03197235677952981 \tMSE sim: 16.58390457696351\n",
      "190 \tNSE sim: -0.8135463854456733 \tMSE sim: 73477.93642243707\n",
      "191 \tNSE sim: 0.26881335522744154 \tMSE sim: 1.270158312552235\n",
      "192 \tNSE sim: -0.914620135842954 \tMSE sim: 314.5474477820084\n",
      "193 \tNSE sim: 0.005597008766108691 \tMSE sim: 10.522187945281969\n",
      "194 \tNSE sim: 0.292128840578632 \tMSE sim: 2.1562913037566345\n",
      "195 \tNSE sim: -0.04312661497847303 \tMSE sim: 23.87724162147431\n",
      "196 \tNSE sim: 0.07722168933453177 \tMSE sim: 5.033009416383008\n",
      "197 \tNSE sim: -0.8943205893872705 \tMSE sim: 209.7517270949935\n",
      "198 \tNSE sim: -0.5908236914241081 \tMSE sim: 51027.79345907094\n",
      "199 \tNSE sim: 0.2102241306978626 \tMSE sim: 2.2077640533135416\n",
      "200 \tNSE sim: 0.19702730489954412 \tMSE sim: 1.6456086665666303\n",
      "201 \tNSE sim: 0.020993908328732602 \tMSE sim: 4.837526365405921\n",
      "202 \tNSE sim: -0.5564647550001185 \tMSE sim: 813.9028725174682\n",
      "203 \tNSE sim: -0.6692342477976341 \tMSE sim: 111.98643078477619\n",
      "204 \tNSE sim: 0.1585062631657136 \tMSE sim: 3.064126096323503\n",
      "205 \tNSE sim: 0.2136726465191554 \tMSE sim: 4.800746225269976\n",
      "206 \tNSE sim: -0.06199240286226115 \tMSE sim: 15.207643627806869\n",
      "207 \tNSE sim: -0.6095838288627378 \tMSE sim: 51377.98594916705\n",
      "208 \tNSE sim: -0.4378493669419896 \tMSE sim: 209.2177474998523\n",
      "209 \tNSE sim: -0.283599138574018 \tMSE sim: 121.71334466635926\n",
      "210 \tNSE sim: -0.35675594992005566 \tMSE sim: 33.78004974885489\n",
      "211 \tNSE sim: -0.0029627409724062304 \tMSE sim: 6.091794517816687\n",
      "212 \tNSE sim: 0.15871239079594457 \tMSE sim: 2.7617406747332147\n",
      "213 \tNSE sim: 0.25143785045858735 \tMSE sim: 2.5077736682971916\n",
      "214 \tNSE sim: 0.27579050585786835 \tMSE sim: 0.6794997482940527\n",
      "215 \tNSE sim: -0.9296470663954097 \tMSE sim: 1.5476495465912885\n",
      "216 \tNSE sim: -0.47944374812039814 \tMSE sim: 252.83308119271007\n",
      "217 \tNSE sim: -0.06627211088093632 \tMSE sim: 58.95558757898928\n",
      "218 \tNSE sim: 0.2685675627538402 \tMSE sim: 7.4057480724337434\n",
      "219 \tNSE sim: -0.2108917905825678 \tMSE sim: 79.038334539494\n",
      "220 \tNSE sim: -0.044641001796964064 \tMSE sim: 1.7791510954202245\n",
      "221 \tNSE sim: 0.032473163462602095 \tMSE sim: 13.205284533479858\n",
      "222 \tNSE sim: 0.22618813308669217 \tMSE sim: 2.562016081780503\n",
      "223 \tNSE sim: -0.05511345967116066 \tMSE sim: 33.033269083565564\n",
      "224 \tNSE sim: -0.6040118403507737 \tMSE sim: 47807.877603257744\n",
      "225 \tNSE sim: 0.27534570514708356 \tMSE sim: 3.0174808570799274\n",
      "226 \tNSE sim: -0.235839987376683 \tMSE sim: 1.2221843200324232\n",
      "227 \tNSE sim: -0.38589871473516135 \tMSE sim: 148.54670300753497\n",
      "228 \tNSE sim: 0.20077474001084084 \tMSE sim: 8.181870483331858\n",
      "229 \tNSE sim: 0.2368728792816832 \tMSE sim: 3.814624059260293\n",
      "230 \tNSE sim: -0.12605330484196697 \tMSE sim: 24.263837694216097\n",
      "231 \tNSE sim: 0.17944176829080682 \tMSE sim: 4.7064350356633895\n",
      "232 \tNSE sim: 0.26449770598032996 \tMSE sim: 1.296106741962492\n",
      "233 \tNSE sim: -0.6010276298558603 \tMSE sim: 46943.806203241125\n",
      "234 \tNSE sim: 0.17596442046952765 \tMSE sim: 9.962991414747528\n",
      "235 \tNSE sim: -0.5892822437677645 \tMSE sim: 44911.32741491296\n",
      "236 \tNSE sim: -0.31103952537937274 \tMSE sim: 50.95480711781522\n",
      "237 \tNSE sim: 0.13981214229977823 \tMSE sim: 4.578937322987766\n",
      "238 \tNSE sim: 0.07015762790499769 \tMSE sim: 3.4702442071939235\n",
      "239 \tNSE sim: -0.5986384829618079 \tMSE sim: 44315.02767178896\n",
      "240 \tNSE sim: 0.2663100271351847 \tMSE sim: 2.7760657046177184\n",
      "241 \tNSE sim: 0.2331956572543561 \tMSE sim: 1.1887516720360118\n",
      "242 \tNSE sim: 0.23965184577517273 \tMSE sim: 0.7600882794421016\n",
      "243 \tNSE sim: -0.5277570707068462 \tMSE sim: 134.28577282590408\n",
      "244 \tNSE sim: -0.13026013281341342 \tMSE sim: 5.264688233943848\n",
      "245 \tNSE sim: -0.36622642072110634 \tMSE sim: 8.941651851190198\n",
      "246 \tNSE sim: -0.1824953362257784 \tMSE sim: 26.31673903386885\n",
      "247 \tNSE sim: 0.027342610429734626 \tMSE sim: 14.291933824292666\n",
      "248 \tNSE sim: -1.0191092423846082 \tMSE sim: 329.62599708220245\n",
      "249 \tNSE sim: -0.262476254700275 \tMSE sim: 73.7372818592444\n",
      "250 \tNSE sim: -0.5507170113784445 \tMSE sim: 13.929355223704965\n",
      "251 \tNSE sim: -0.034767223962320015 \tMSE sim: 4.509241914188181\n",
      "252 \tNSE sim: -0.06778601835095754 \tMSE sim: 34.199092391628675\n",
      "253 \tNSE sim: 0.29508491215124333 \tMSE sim: 0.8817109902649334\n",
      "254 \tNSE sim: -0.5190193779592724 \tMSE sim: 102.91635158170367\n",
      "255 \tNSE sim: 0.21523759466644377 \tMSE sim: 4.214003048764429\n",
      "256 \tNSE sim: -0.6012930854482934 \tMSE sim: 43998.15420871179\n",
      "257 \tNSE sim: 0.24383581783095554 \tMSE sim: 2.183062432315505\n",
      "258 \tNSE sim: -0.5433454609226724 \tMSE sim: 106.58129482531922\n",
      "259 \tNSE sim: -0.4306618269302056 \tMSE sim: 26.91879800545778\n",
      "260 \tNSE sim: -0.892243907422148 \tMSE sim: 11850.428056594803\n",
      "261 \tNSE sim: -0.3474457332207699 \tMSE sim: 2296.8337660205443\n",
      "262 \tNSE sim: -0.11741626022451168 \tMSE sim: 8.462612668207377\n",
      "263 \tNSE sim: 0.07817112374214652 \tMSE sim: 2.9679652468692264\n",
      "264 \tNSE sim: 0.19542139900059452 \tMSE sim: 6.852487074922208\n",
      "265 \tNSE sim: 0.2457377106917279 \tMSE sim: 4.180696768957506\n",
      "266 \tNSE sim: 0.23040385901663119 \tMSE sim: 1.1050635821465271\n",
      "267 \tNSE sim: -0.5949684922567513 \tMSE sim: 42518.863573283765\n",
      "268 \tNSE sim: -0.8543661743843032 \tMSE sim: 11283.298996320122\n",
      "269 \tNSE sim: -0.5341149676804371 \tMSE sim: 2255.7815277229492\n",
      "270 \tNSE sim: -0.05440282953904685 \tMSE sim: 16.1641635672912\n",
      "271 \tNSE sim: 0.109363914651194 \tMSE sim: 4.6920577851169805\n",
      "272 \tNSE sim: -0.48356799706957565 \tMSE sim: 24.567825446190596\n",
      "273 \tNSE sim: -0.06494820952402258 \tMSE sim: 0.91792796628159\n",
      "274 \tNSE sim: -0.17797014638499076 \tMSE sim: 2.5055214100560566\n",
      "275 \tNSE sim: -0.853365018388661 \tMSE sim: 10333.05212726437\n",
      "276 \tNSE sim: 0.22183103659457915 \tMSE sim: 4.476238359691995\n",
      "277 \tNSE sim: -0.1296748393308449 \tMSE sim: 45.04918730467971\n",
      "278 \tNSE sim: -0.2897110136551262 \tMSE sim: 1453.6199735183504\n",
      "279 \tNSE sim: -0.4533121421842776 \tMSE sim: 10.323313371357857\n",
      "280 \tNSE sim: -0.06623530679793443 \tMSE sim: 1.7371250908040765\n",
      "281 \tNSE sim: -0.45743419749726577 \tMSE sim: 827.6565296677882\n",
      "282 \tNSE sim: -0.2767838114032375 \tMSE sim: 272.06722523404466\n",
      "283 \tNSE sim: 0.23865293492366868 \tMSE sim: 3.3846471339479685\n",
      "284 \tNSE sim: -0.18532430835563174 \tMSE sim: 1.8909304223466068\n",
      "285 \tNSE sim: -0.2574762268131334 \tMSE sim: 30.930771248253258\n",
      "286 \tNSE sim: 0.24111128758601752 \tMSE sim: 3.042097748700275\n",
      "287 \tNSE sim: 0.1790886704974014 \tMSE sim: 4.351047437946166\n",
      "288 \tNSE sim: 0.25171201018297074 \tMSE sim: 5.661527747773318\n",
      "289 \tNSE sim: -0.08661818548787514 \tMSE sim: 4.476108163071799\n",
      "290 \tNSE sim: -0.4549458642296249 \tMSE sim: 781.3780092291438\n",
      "291 \tNSE sim: -0.858931569793393 \tMSE sim: 9446.511074921827\n",
      "292 \tNSE sim: 0.05477958877415989 \tMSE sim: 26.500156371508208\n",
      "293 \tNSE sim: 0.06921382606120052 \tMSE sim: 14.604894812519207\n",
      "294 \tNSE sim: -0.2548674711804504 \tMSE sim: 920.2523287523204\n",
      "295 \tNSE sim: 0.20036091255417343 \tMSE sim: 5.021304702250517\n",
      "296 \tNSE sim: -0.5562394074803869 \tMSE sim: 12506.617511135993\n",
      "297 \tNSE sim: -0.5671428467716748 \tMSE sim: 8943.60605284676\n",
      "298 \tNSE sim: -0.5526222485056447 \tMSE sim: 8066.130763424249\n",
      "299 \tNSE sim: -0.37031107275412034 \tMSE sim: 452.2361433678715\n",
      "300 \tNSE sim: -0.5391953706298414 \tMSE sim: 8016.364268454869\n",
      "301 \tNSE sim: 0.1581315046489986 \tMSE sim: 10.5546508227148\n",
      "302 \tNSE sim: -0.4404989350499391 \tMSE sim: 610.9292624155122\n",
      "303 \tNSE sim: 0.0762091946861918 \tMSE sim: 25.003397258778588\n",
      "304 \tNSE sim: -0.12636930907559596 \tMSE sim: 81.9617276313916\n",
      "305 \tNSE sim: 0.08907532227223036 \tMSE sim: 19.90138924317394\n",
      "306 \tNSE sim: -0.3206092163606329 \tMSE sim: 317.4989339534062\n",
      "307 \tNSE sim: 0.2089161915416463 \tMSE sim: 3.242612688772299\n",
      "308 \tNSE sim: 0.20385529951133974 \tMSE sim: 4.119859877401361\n",
      "309 \tNSE sim: -0.43718309399319644 \tMSE sim: 507.83406658176324\n",
      "310 \tNSE sim: -0.28440975909541044 \tMSE sim: 210.44535284982285\n",
      "311 \tNSE sim: 0.1645856887099184 \tMSE sim: 6.382057722654474\n",
      "312 \tNSE sim: -0.8304325451283534 \tMSE sim: 9049.105928992929\n",
      "313 \tNSE sim: 0.1609692547185645 \tMSE sim: 4.725514509617091\n",
      "314 \tNSE sim: -0.23076861249808878 \tMSE sim: 764.7995878137239\n",
      "315 \tNSE sim: 0.06417641266747975 \tMSE sim: 23.191909303337138\n",
      "316 \tNSE sim: -0.5495160474585776 \tMSE sim: 7880.379522300636\n",
      "317 \tNSE sim: -0.5407160409823828 \tMSE sim: 5887.663943637349\n",
      "318 \tNSE sim: 0.11913712933157539 \tMSE sim: 11.302258045726902\n",
      "319 \tNSE sim: -0.21994199180737128 \tMSE sim: 136.89957674570962\n",
      "320 \tNSE sim: 0.2906190242536275 \tMSE sim: 1.9737794415159697\n",
      "321 \tNSE sim: -0.5491741928400538 \tMSE sim: 3391.921590379633\n",
      "322 \tNSE sim: -0.3331143878572178 \tMSE sim: 327.8366260581984\n",
      "323 \tNSE sim: 0.15928962447441375 \tMSE sim: 3.135829694515573\n",
      "324 \tNSE sim: -0.7656946028107574 \tMSE sim: 8436.079647971748\n",
      "325 \tNSE sim: 0.22567799667773747 \tMSE sim: 3.494309589531653\n",
      "326 \tNSE sim: -0.2721426763667447 \tMSE sim: 291.3984702562263\n",
      "327 \tNSE sim: -0.12692186141104855 \tMSE sim: 89.23911196957083\n",
      "328 \tNSE sim: 0.15673231081544592 \tMSE sim: 2.0137825335869186\n",
      "329 \tNSE sim: -0.5008590531637032 \tMSE sim: 7394.646449963031\n",
      "330 \tNSE sim: 0.08836106632070118 \tMSE sim: 12.579295015642485\n",
      "331 \tNSE sim: -0.2708251990844217 \tMSE sim: 85.48497556951571\n",
      "332 \tNSE sim: -0.020503339584329927 \tMSE sim: 13.944553652835609\n",
      "333 \tNSE sim: 0.1860744344880284 \tMSE sim: 6.5730485670922105\n",
      "334 \tNSE sim: -0.527818106285838 \tMSE sim: 7226.954560283137\n",
      "335 \tNSE sim: -0.07212918178539196 \tMSE sim: 14.513972878858532\n",
      "336 \tNSE sim: -0.1524074347676303 \tMSE sim: 30.384140100515467\n",
      "337 \tNSE sim: 0.10373934853944233 \tMSE sim: 14.635064813715239\n",
      "338 \tNSE sim: 0.05957081424330246 \tMSE sim: 3.0754246512996124\n",
      "339 \tNSE sim: 0.223839715190837 \tMSE sim: 3.8245829075586\n",
      "340 \tNSE sim: -0.10945436640881834 \tMSE sim: 38.033674882436856\n",
      "341 \tNSE sim: -0.5162071150800132 \tMSE sim: 859.4709952862701\n",
      "342 \tNSE sim: -0.511703823290862 \tMSE sim: 6889.6904018437135\n",
      "343 \tNSE sim: -0.46828128505219246 \tMSE sim: 738.7370997495726\n",
      "344 \tNSE sim: -0.020402156111049452 \tMSE sim: 64.87871038896517\n",
      "345 \tNSE sim: -0.06753302566943087 \tMSE sim: 46.5792031348084\n",
      "346 \tNSE sim: -0.16198348454335698 \tMSE sim: 369.8594378861428\n",
      "347 \tNSE sim: 0.12330851569616408 \tMSE sim: 3.2587427789952677\n",
      "348 \tNSE sim: -0.25720439467302403 \tMSE sim: 202.53606460738197\n",
      "349 \tNSE sim: -0.28890849873821045 \tMSE sim: 117.11686529563401\n",
      "350 \tNSE sim: -0.7712130541683078 \tMSE sim: 7905.049385397239\n",
      "351 \tNSE sim: -1.3812787019371005 \tMSE sim: 6.13365915076989\n",
      "352 \tNSE sim: 0.03544269975317471 \tMSE sim: 42.45452166885387\n",
      "353 \tNSE sim: -0.5098036507794599 \tMSE sim: 6540.251662667784\n",
      "354 \tNSE sim: -0.2769494555528633 \tMSE sim: 225.25364071719395\n",
      "355 \tNSE sim: 0.13632487987340147 \tMSE sim: 10.258263757532943\n",
      "356 \tNSE sim: 0.2384142725477144 \tMSE sim: 2.04604806578009\n",
      "357 \tNSE sim: 0.058165754511740886 \tMSE sim: 10.63077994210907\n",
      "358 \tNSE sim: -0.3431553730294208 \tMSE sim: 101.10701153963191\n",
      "359 \tNSE sim: 0.12810257436371209 \tMSE sim: 3.3554018727644905\n",
      "360 \tNSE sim: 0.10240168737857269 \tMSE sim: 2.5853734730585596\n",
      "361 \tNSE sim: 0.15746234111106328 \tMSE sim: 26.028252773825976\n",
      "362 \tNSE sim: -0.30760858725868245 \tMSE sim: 5424.011098191373\n",
      "363 \tNSE sim: 0.05179930376766695 \tMSE sim: 3.6822288014947184\n",
      "364 \tNSE sim: 0.012477429421174357 \tMSE sim: 6.319792479968969\n",
      "365 \tNSE sim: -0.5099619112330807 \tMSE sim: 620.9032812788403\n",
      "366 \tNSE sim: -0.12029524597493713 \tMSE sim: 14.300096178249127\n",
      "367 \tNSE sim: -0.7893808266032991 \tMSE sim: 7782.620938822107\n",
      "368 \tNSE sim: -0.20198983417041005 \tMSE sim: 244.45872602704318\n",
      "369 \tNSE sim: 0.10722250705283831 \tMSE sim: 2.8429771221059243\n",
      "370 \tNSE sim: -0.33421459503960893 \tMSE sim: 168.691325003179\n",
      "371 \tNSE sim: 0.13802154077728368 \tMSE sim: 17.520208599497337\n",
      "372 \tNSE sim: -0.028937522606406585 \tMSE sim: 4.383767512693405\n",
      "373 \tNSE sim: -0.47502206015823556 \tMSE sim: 5827.351437962022\n",
      "374 \tNSE sim: -0.15417494123746134 \tMSE sim: 76.0687103889115\n",
      "375 \tNSE sim: -0.344020890992383 \tMSE sim: 71.6446442517827\n",
      "376 \tNSE sim: -0.4954002209591686 \tMSE sim: 399.91871968488505\n",
      "377 \tNSE sim: -0.021892473808152735 \tMSE sim: 12.144688220027216\n",
      "378 \tNSE sim: -0.24946075500937526 \tMSE sim: 114.7009431341693\n",
      "379 \tNSE sim: -0.7353230384697225 \tMSE sim: 7227.4042147961245\n",
      "380 \tNSE sim: 0.1854936181544663 \tMSE sim: 12.206587559023424\n",
      "381 \tNSE sim: 0.1832713898472027 \tMSE sim: 2.6401387389545174\n",
      "382 \tNSE sim: -0.397904702121173 \tMSE sim: 265.2494527470763\n",
      "383 \tNSE sim: 0.2373031884979887 \tMSE sim: 2.1344299063386707\n",
      "384 \tNSE sim: 0.2409118461716222 \tMSE sim: 5.682785195440449\n",
      "385 \tNSE sim: -0.7264363903114273 \tMSE sim: 6928.944100045234\n",
      "386 \tNSE sim: -0.5514437074678387 \tMSE sim: 1252.2635698850709\n",
      "387 \tNSE sim: -0.39750451304570245 \tMSE sim: 1690.4117870522332\n",
      "388 \tNSE sim: 0.2657444493101667 \tMSE sim: 2.5425091553013286\n",
      "389 \tNSE sim: -0.09344196573375707 \tMSE sim: 21.61072526243752\n",
      "390 \tNSE sim: -0.15778479114711508 \tMSE sim: 37.79069900413538\n",
      "391 \tNSE sim: -0.08538237506654878 \tMSE sim: 46.960911104621324\n",
      "392 \tNSE sim: -0.0320663119471023 \tMSE sim: 32.023211597604195\n",
      "393 \tNSE sim: -0.11545125978790183 \tMSE sim: 48.831947038635775\n",
      "394 \tNSE sim: -0.5162768455239193 \tMSE sim: 1125.1732076423216\n",
      "395 \tNSE sim: -0.1959594726991174 \tMSE sim: 184.46660227162897\n",
      "396 \tNSE sim: -0.7749487701488866 \tMSE sim: 6716.617239113179\n",
      "397 \tNSE sim: 0.08387788863918022 \tMSE sim: 3.016642962966459\n",
      "398 \tNSE sim: -0.06037791153725869 \tMSE sim: 21.261344308924016\n",
      "399 \tNSE sim: 0.025336555109185976 \tMSE sim: 5.822036706659987\n",
      "400 \tNSE sim: 0.04280783696642754 \tMSE sim: 11.336330936148146\n",
      "401 \tNSE sim: 0.13192030697328094 \tMSE sim: 2.2523086606131484\n",
      "402 \tNSE sim: -0.25174176379757496 \tMSE sim: 111.49921688512171\n",
      "403 \tNSE sim: -0.35898473483146787 \tMSE sim: 775.8574282492291\n",
      "404 \tNSE sim: 0.06154769780783387 \tMSE sim: 2.9226467563832945\n",
      "405 \tNSE sim: -0.4848933494519665 \tMSE sim: 846.7220762278481\n",
      "406 \tNSE sim: 0.2521164268292646 \tMSE sim: 4.055977979636923\n",
      "407 \tNSE sim: 0.10362331682711434 \tMSE sim: 3.6040164231187277\n",
      "408 \tNSE sim: -0.08993200275252566 \tMSE sim: 15.635983525137\n",
      "409 \tNSE sim: 0.01646991515559104 \tMSE sim: 16.631837519137573\n",
      "410 \tNSE sim: 0.09673177423624357 \tMSE sim: 8.813716058860138\n",
      "411 \tNSE sim: 0.12442197441347758 \tMSE sim: 1.1183627445537527\n",
      "412 \tNSE sim: -0.6438732218535104 \tMSE sim: 5431.443979959866\n",
      "413 \tNSE sim: 0.20569937804440241 \tMSE sim: 6.468250094822919\n",
      "414 \tNSE sim: -0.3273549775730873 \tMSE sim: 686.9829384148046\n",
      "415 \tNSE sim: 0.061825794638654785 \tMSE sim: 7.961128832092282\n",
      "416 \tNSE sim: -0.11682450926108046 \tMSE sim: 36.557248636750025\n",
      "417 \tNSE sim: 0.17852583254848597 \tMSE sim: 2.7640791545688677\n",
      "418 \tNSE sim: -0.25217611936529405 \tMSE sim: 59.368052006868545\n",
      "419 \tNSE sim: -0.2814006590422653 \tMSE sim: 600.4891973526354\n",
      "420 \tNSE sim: -0.14429380578976803 \tMSE sim: 36.0484881318863\n",
      "421 \tNSE sim: -0.47549154829814344 \tMSE sim: 559.6689093636173\n",
      "422 \tNSE sim: -0.013455974618878708 \tMSE sim: 3.527771919027552\n",
      "423 \tNSE sim: 0.12896394841336944 \tMSE sim: 2.023670454122111\n",
      "424 \tNSE sim: -0.09813394667032349 \tMSE sim: 14.108226852006675\n",
      "425 \tNSE sim: -0.060619688936631944 \tMSE sim: 5.178201857966328\n",
      "426 \tNSE sim: 0.181480276411351 \tMSE sim: 3.6295115259965054\n",
      "427 \tNSE sim: -0.003303511845728746 \tMSE sim: 19.13246090416141\n",
      "428 \tNSE sim: -0.22203455993375987 \tMSE sim: 458.07827044817003\n",
      "429 \tNSE sim: -0.46077734933302916 \tMSE sim: 316.507125255336\n",
      "430 \tNSE sim: -0.02683758126382174 \tMSE sim: 4.285158490864849\n",
      "431 \tNSE sim: -0.07465076499831258 \tMSE sim: 588.052439639518\n",
      "432 \tNSE sim: -0.24259871255051735 \tMSE sim: 1272.3863827956645\n",
      "433 \tNSE sim: -0.44175320321169087 \tMSE sim: 1134.7119515426457\n",
      "434 \tNSE sim: 0.14166108803381539 \tMSE sim: 14.614667276095506\n",
      "435 \tNSE sim: -0.18138330175818185 \tMSE sim: 220.3373137528961\n",
      "436 \tNSE sim: 0.14238104479950864 \tMSE sim: 14.629159754024512\n",
      "437 \tNSE sim: -0.40626861919065393 \tMSE sim: 239.91660119444424\n",
      "438 \tNSE sim: 0.13833001977107517 \tMSE sim: 3.2254530422327115\n",
      "439 \tNSE sim: -0.33794673965204214 \tMSE sim: 172.58825208627178\n",
      "440 \tNSE sim: 0.026131550322548103 \tMSE sim: 2.119770020865285\n",
      "441 \tNSE sim: 0.1442328779746731 \tMSE sim: 1.9185287281388206\n",
      "442 \tNSE sim: -0.0952407528330732 \tMSE sim: 3.2611152755225565\n",
      "443 \tNSE sim: 0.057704490364982486 \tMSE sim: 84.99553730117651\n",
      "444 \tNSE sim: -0.5444897968578823 \tMSE sim: 534.846027452088\n",
      "445 \tNSE sim: 0.3348200660147248 \tMSE sim: 2.6990644790910725\n",
      "446 \tNSE sim: -0.2692867546056228 \tMSE sim: 120.68090177163704\n",
      "447 \tNSE sim: 0.2810529245341552 \tMSE sim: 24.980313605060037\n",
      "448 \tNSE sim: -0.5516568706707794 \tMSE sim: 13.800980151941024\n",
      "449 \tNSE sim: 0.0512832981592638 \tMSE sim: 87.70814205629303\n",
      "450 \tNSE sim: 0.21103668535106102 \tMSE sim: 19.34898255602782\n",
      "451 \tNSE sim: 0.25650148685896434 \tMSE sim: 11.911488366780928\n",
      "452 \tNSE sim: -0.24787589930897957 \tMSE sim: 82.49960247659884\n",
      "453 \tNSE sim: 0.1146249633253954 \tMSE sim: 8.547585401517875\n",
      "454 \tNSE sim: -0.27324837271948077 \tMSE sim: 573.3652534153273\n",
      "455 \tNSE sim: 0.15172396067405158 \tMSE sim: 9.891249479093638\n",
      "456 \tNSE sim: 0.21712920082074139 \tMSE sim: 42.957763456966624\n",
      "457 \tNSE sim: 0.09905007119159981 \tMSE sim: 14.250623152269212\n",
      "458 \tNSE sim: -0.46325821077957907 \tMSE sim: 413.95185033785793\n",
      "459 \tNSE sim: -0.1659236872413823 \tMSE sim: 44.87906328320739\n",
      "460 \tNSE sim: 0.24877441420294977 \tMSE sim: 2.2395536320110945\n",
      "461 \tNSE sim: 0.22076776461272374 \tMSE sim: 2.8489332245221397\n",
      "462 \tNSE sim: 0.08991607888419373 \tMSE sim: 36.92541319821275\n",
      "463 \tNSE sim: -0.37205497437902935 \tMSE sim: 167.91427270989047\n",
      "464 \tNSE sim: 0.09450286470490232 \tMSE sim: 8.505644072129817\n",
      "465 \tNSE sim: 0.2558688157030272 \tMSE sim: 6.975016471186782\n",
      "466 \tNSE sim: 0.11124822355828334 \tMSE sim: 2.3917767632949456\n",
      "467 \tNSE sim: 0.12513211894784815 \tMSE sim: 4.498338230250122\n",
      "468 \tNSE sim: 0.18114366223603218 \tMSE sim: 2.6028094566015576\n",
      "469 \tNSE sim: -0.24813274135610852 \tMSE sim: 71.6292075818426\n",
      "470 \tNSE sim: 0.17015130307357895 \tMSE sim: 6.840651871175012\n",
      "471 \tNSE sim: 0.21643635811828055 \tMSE sim: 5.357722096196595\n",
      "472 \tNSE sim: 0.17756231995166305 \tMSE sim: 6.902989013446495\n",
      "473 \tNSE sim: 0.016218611565038454 \tMSE sim: 18.192784542510225\n",
      "474 \tNSE sim: -1.1518397289519609 \tMSE sim: 2518214.5633527376\n",
      "475 \tNSE sim: -0.8042155733263181 \tMSE sim: 72598.18118850546\n",
      "476 \tNSE sim: 0.1666413116792952 \tMSE sim: 0.3655122226926027\n",
      "477 \tNSE sim: -0.18781754538461648 \tMSE sim: 133.46000500383568\n",
      "478 \tNSE sim: -0.14911319427339098 \tMSE sim: 117.54322731563512\n",
      "479 \tNSE sim: -1.990945646318106 \tMSE sim: 0.27378290683908585\n",
      "480 \tNSE sim: 0.2192909857356179 \tMSE sim: 7.832374385064836\n",
      "481 \tNSE sim: -1705.340180530474 \tMSE sim: 10.016403135959663\n",
      "482 \tNSE sim: 0.08736493059516648 \tMSE sim: 11.564755753852877\n",
      "483 \tNSE sim: 0.16725623188712335 \tMSE sim: 15.393904188135103\n",
      "484 \tNSE sim: -0.44423784933302946 \tMSE sim: 1083.5526641316249\n",
      "485 \tNSE sim: 0.09294966943142569 \tMSE sim: 0.10974337253482798\n",
      "486 \tNSE sim: -0.02808830726631517 \tMSE sim: 3.2555391859433302\n",
      "487 \tNSE sim: -0.005079468390916775 \tMSE sim: 1.30493866041987\n",
      "488 \tNSE sim: 0.062186212028601084 \tMSE sim: 0.11033608106718422\n",
      "489 \tNSE sim: -0.10293449681578037 \tMSE sim: 0.31889558267976614\n",
      "490 \tNSE sim: -0.11716853425749196 \tMSE sim: 0.9038976442364804\n",
      "491 \tNSE sim: -2.2735926049703767 \tMSE sim: 0.0133057732285389\n",
      "492 \tNSE sim: -0.041994003551271586 \tMSE sim: 1.4389027157550223\n",
      "493 \tNSE sim: -0.1454299128358143 \tMSE sim: 0.0399005317911495\n",
      "494 \tNSE sim: 0.07957598248455955 \tMSE sim: 0.0037579069764124757\n",
      "495 \tNSE sim: -0.4746026442282263 \tMSE sim: 0.12996516240988906\n",
      "496 \tNSE sim: -0.798316643987329 \tMSE sim: 0.4550906335120326\n",
      "497 \tNSE sim: -0.8750418447371242 \tMSE sim: 20.533718368892995\n",
      "498 \tNSE sim: -0.7480301481075149 \tMSE sim: 0.7128789409972603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/hydroeval/objective_functions.py:31: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.sum((evaluation - np.mean(evaluation)) ** 2, dtype=np.float64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 \tNSE sim: -inf \tMSE sim: 0.0013961594795827913\n",
      "500 \tNSE sim: -0.8072211265036668 \tMSE sim: 21.20286431732403\n",
      "501 \tNSE sim: -0.3344429322075355 \tMSE sim: 0.05314875204368285\n",
      "502 \tNSE sim: -0.11464664838095029 \tMSE sim: 0.11620475261289565\n",
      "503 \tNSE sim: 0.040895951510749984 \tMSE sim: 0.02588337292798732\n",
      "504 \tNSE sim: -0.17316241425224166 \tMSE sim: 0.007895569760262502\n",
      "505 \tNSE sim: -0.0701308633290636 \tMSE sim: 3.0430953103399343\n",
      "506 \tNSE sim: -0.16380920864376503 \tMSE sim: 40.924394127899625\n",
      "507 \tNSE sim: -21.39267833002606 \tMSE sim: 0.31190101930437475\n",
      "508 \tNSE sim: 0.0707209934380445 \tMSE sim: 2.421730834835997\n",
      "509 \tNSE sim: -0.47792555942865644 \tMSE sim: 85.0451750262998\n",
      "510 \tNSE sim: 0.20884694177969665 \tMSE sim: 0.7652389867011958\n",
      "511 \tNSE sim: -0.18401100390573766 \tMSE sim: 0.8624351878104435\n",
      "512 \tNSE sim: -0.6199847508673666 \tMSE sim: 379.71953341763253\n",
      "513 \tNSE sim: -0.2697985474245501 \tMSE sim: 278.97182174918163\n",
      "514 \tNSE sim: -0.08056760132379392 \tMSE sim: 1.0248368238890784\n",
      "515 \tNSE sim: -0.03899266500912901 \tMSE sim: 0.20392253470604732\n",
      "516 \tNSE sim: -0.09822876596045194 \tMSE sim: 0.42311711900457083\n",
      "517 \tNSE sim: 0.029988392820763043 \tMSE sim: 0.03115426453872804\n",
      "518 \tNSE sim: 0.06385075690293573 \tMSE sim: 0.008537863222388297\n",
      "519 \tNSE sim: 0.07025397435753444 \tMSE sim: 2.01593555630896\n",
      "520 \tNSE sim: 0.18936321805133072 \tMSE sim: 0.1985974866359915\n",
      "521 \tNSE sim: -0.19566684601655626 \tMSE sim: 5.227413976466515\n",
      "522 \tNSE sim: 0.1299334910310801 \tMSE sim: 1.4302068416138858\n",
      "523 \tNSE sim: 0.23222019678202854 \tMSE sim: 0.0444407997337675\n",
      "524 \tNSE sim: 0.15449226246109216 \tMSE sim: 0.005710042794453678\n",
      "525 \tNSE sim: -inf \tMSE sim: 0.17305543402436757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/hydroeval/objective_functions.py:31: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.sum((evaluation - np.mean(evaluation)) ** 2, dtype=np.float64))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526 \tNSE sim: -4.87991628363764 \tMSE sim: 0.0022841912149631043\n",
      "527 \tNSE sim: -72.94834146582429 \tMSE sim: 1.2125042363413827\n",
      "528 \tNSE sim: 0.19064340809992253 \tMSE sim: 0.05466607995017496\n",
      "529 \tNSE sim: -97.90919223360365 \tMSE sim: 1.0195229048394603\n",
      "530 \tNSE sim: 0.3238544672645649 \tMSE sim: 3.5684489240031314\n",
      "531 \tNSE sim: 0.214714740171566 \tMSE sim: 0.9386162933590932\n",
      "532 \tNSE sim: 0.18091595816094275 \tMSE sim: 0.2692225789774661\n",
      "533 \tNSE sim: -184.96606807339882 \tMSE sim: 0.36533333775545923\n",
      "534 \tNSE sim: 0.1508470074497208 \tMSE sim: 0.5191481825024082\n",
      "535 \tNSE sim: 0.344041711869962 \tMSE sim: 0.20388065525364868\n",
      "536 \tNSE sim: 0.21467274027514605 \tMSE sim: 2.1038679654367143\n",
      "537 \tNSE sim: 0.3937167838425769 \tMSE sim: 0.9791320798471186\n",
      "538 \tNSE sim: -0.43867608191982543 \tMSE sim: 246.27872479710953\n",
      "539 \tNSE sim: 0.26309194207104347 \tMSE sim: 0.014321806760507047\n",
      "540 \tNSE sim: -0.5040643314879059 \tMSE sim: 7842.826983802013\n",
      "541 \tNSE sim: -0.3233227846570763 \tMSE sim: 714.6558477972569\n",
      "542 \tNSE sim: -0.3501996506709424 \tMSE sim: 770.3530388897301\n",
      "543 \tNSE sim: 0.0251966696512671 \tMSE sim: 31.4374783556832\n",
      "544 \tNSE sim: 0.023054429774097662 \tMSE sim: 0.24507886139593213\n",
      "545 \tNSE sim: 0.008793473915844174 \tMSE sim: 0.005776793789592003\n",
      "546 \tNSE sim: 0.06475772850031158 \tMSE sim: 0.9411981537216138\n",
      "547 \tNSE sim: 0.1699631676501363 \tMSE sim: 0.010046785368914771\n",
      "548 \tNSE sim: 0.20861969776846234 \tMSE sim: 0.047019190430054696\n",
      "549 \tNSE sim: 0.19216490278630727 \tMSE sim: 0.10574876415096295\n",
      "550 \tNSE sim: -138.31283191975987 \tMSE sim: 1.0809582493228145\n",
      "551 \tNSE sim: 0.05699126874907545 \tMSE sim: 0.01678686771560104\n",
      "552 \tNSE sim: 0.11043750321370716 \tMSE sim: 10.498792987467123\n",
      "553 \tNSE sim: -0.9333339275850592 \tMSE sim: 13958.718714066528\n",
      "554 \tNSE sim: 0.2086394252396272 \tMSE sim: 1.141345144057132\n",
      "555 \tNSE sim: 0.20218616394357847 \tMSE sim: 0.1581407492908729\n",
      "556 \tNSE sim: -0.8288105182259091 \tMSE sim: 424.42488623023456\n",
      "557 \tNSE sim: -0.24111697598127435 \tMSE sim: 4.842419341978564\n",
      "558 \tNSE sim: -0.03954314321507946 \tMSE sim: 3.267452192022511\n",
      "559 \tNSE sim: -0.15230808935394013 \tMSE sim: 6.113166718859015\n",
      "560 \tNSE sim: -0.4578764044950765 \tMSE sim: 71.31077410562811\n",
      "561 \tNSE sim: 0.1520587827170642 \tMSE sim: 1.62820826807909\n",
      "562 \tNSE sim: -0.02292383345472193 \tMSE sim: 5.043911153288883\n",
      "563 \tNSE sim: -0.6030119582348197 \tMSE sim: 226.8842683428985\n",
      "564 \tNSE sim: 0.07817400913927264 \tMSE sim: 0.667383982070249\n",
      "565 \tNSE sim: -0.15850481424904928 \tMSE sim: 4.062046665910117\n",
      "566 \tNSE sim: -0.32683999753693316 \tMSE sim: 28.36730950487488\n",
      "567 \tNSE sim: 0.2683354144556266 \tMSE sim: 0.08120011098874623\n",
      "568 \tNSE sim: 0.17161200774732832 \tMSE sim: 0.3913345558379531\n",
      "569 \tNSE sim: 0.23987872097840268 \tMSE sim: 3.0996701910611946\n",
      "570 \tNSE sim: 0.2714466717198618 \tMSE sim: 0.15676551809418277\n",
      "571 \tNSE sim: -0.5236737839970484 \tMSE sim: 257.75383209791005\n",
      "572 \tNSE sim: 0.263646610309064 \tMSE sim: 0.6775811360286067\n",
      "573 \tNSE sim: 0.04046916089120023 \tMSE sim: 1.8015976041238844\n",
      "574 \tNSE sim: -0.11853666610663693 \tMSE sim: 3.370386851348351\n",
      "575 \tNSE sim: -0.6330644353343886 \tMSE sim: 663.1974006761361\n",
      "576 \tNSE sim: 0.23417853806181754 \tMSE sim: 0.3242844096875206\n",
      "577 \tNSE sim: 0.2809813454835409 \tMSE sim: 0.20994795756214218\n",
      "578 \tNSE sim: 0.18912156367526656 \tMSE sim: 0.28251577028672414\n",
      "579 \tNSE sim: 0.21133796436102792 \tMSE sim: 0.1813122636071165\n",
      "580 \tNSE sim: -0.008607561576347011 \tMSE sim: 2.3090363547054285\n",
      "581 \tNSE sim: 0.24573075117860543 \tMSE sim: 0.04599458785928139\n",
      "582 \tNSE sim: -2.9877598348405425 \tMSE sim: 1.3200507198541458\n",
      "583 \tNSE sim: -0.6239424046773097 \tMSE sim: 420.35070028936485\n",
      "584 \tNSE sim: 0.17070300116413384 \tMSE sim: 1.8163485247074458\n",
      "585 \tNSE sim: 0.2641308314694232 \tMSE sim: 0.3976362224640097\n",
      "586 \tNSE sim: -0.31819041293851025 \tMSE sim: 0.08125342357784172\n",
      "587 \tNSE sim: -0.2256528727610274 \tMSE sim: 5.496048337307487\n",
      "588 \tNSE sim: 0.19078699001032673 \tMSE sim: 2.0120648530096847\n",
      "589 \tNSE sim: -0.5962961090257388 \tMSE sim: 0.07338200530784257\n",
      "590 \tNSE sim: 0.09639514623760859 \tMSE sim: 0.07232958612374957\n",
      "591 \tNSE sim: 0.10458604125958704 \tMSE sim: 2.0724948150832834\n",
      "592 \tNSE sim: 0.1540373065072812 \tMSE sim: 0.4767649153449286\n",
      "593 \tNSE sim: -0.28713423873347876 \tMSE sim: 12.64091083692539\n",
      "594 \tNSE sim: -0.6770527085109199 \tMSE sim: 101.6418340071492\n",
      "595 \tNSE sim: -0.10605885464960485 \tMSE sim: 15.698018768235235\n",
      "596 \tNSE sim: -0.48396309792869774 \tMSE sim: 811.9041490660396\n",
      "597 \tNSE sim: -0.9281286962085427 \tMSE sim: 1094.7243153232355\n",
      "598 \tNSE sim: -0.5086825229681124 \tMSE sim: 69.76930326287489\n",
      "599 \tNSE sim: -0.36732809956895207 \tMSE sim: 6.002904403745025\n",
      "600 \tNSE sim: 0.03605545640635499 \tMSE sim: 0.07186612049445042\n",
      "601 \tNSE sim: 0.14863941962406202 \tMSE sim: 0.2724007665003449\n",
      "602 \tNSE sim: -0.051117086792290545 \tMSE sim: 3.7753372784997374\n",
      "603 \tNSE sim: -0.1336976620269259 \tMSE sim: 9.77533441908819\n",
      "604 \tNSE sim: -1.092159387737095 \tMSE sim: 752.227755075474\n",
      "605 \tNSE sim: -0.02662736938205401 \tMSE sim: 10.985900256462337\n",
      "606 \tNSE sim: -0.6555800569971895 \tMSE sim: 386.58711640266415\n",
      "607 \tNSE sim: -0.6487046556933997 \tMSE sim: 55994.494699010276\n",
      "608 \tNSE sim: -0.3683305168849851 \tMSE sim: 104.15927378876948\n",
      "609 \tNSE sim: -0.044711931523486736 \tMSE sim: 4.172903999320512\n",
      "610 \tNSE sim: -0.07119599286194123 \tMSE sim: 0.14003431838935657\n",
      "611 \tNSE sim: -0.06048455739942682 \tMSE sim: 0.19088802870536928\n",
      "612 \tNSE sim: 0.19842820832915686 \tMSE sim: 0.30011906980244135\n",
      "613 \tNSE sim: -0.9634137380663621 \tMSE sim: 130.4620322131785\n",
      "614 \tNSE sim: 0.08198027131190633 \tMSE sim: 7.747408832390682\n",
      "615 \tNSE sim: -0.20147349169518503 \tMSE sim: 16.825148294862153\n",
      "616 \tNSE sim: 0.1224026654759931 \tMSE sim: 1.80332690645644\n",
      "617 \tNSE sim: -0.5527609233772779 \tMSE sim: 220.886663359184\n",
      "618 \tNSE sim: 0.2269476235386687 \tMSE sim: 0.7005315896405918\n",
      "619 \tNSE sim: 0.2132521869101981 \tMSE sim: 0.9528440590214968\n",
      "620 \tNSE sim: 0.15223245668065832 \tMSE sim: 13.013252261906429\n",
      "621 \tNSE sim: -0.6347333265016537 \tMSE sim: 2421.0014349638727\n",
      "622 \tNSE sim: 0.21616999731518516 \tMSE sim: 0.4648011733791261\n",
      "623 \tNSE sim: 0.15481773353154327 \tMSE sim: 0.352855356435601\n",
      "624 \tNSE sim: 0.0862475205638552 \tMSE sim: 0.2255267645621119\n",
      "625 \tNSE sim: -0.3718078077706859 \tMSE sim: 2357.322398042892\n",
      "626 \tNSE sim: -0.9996535288440338 \tMSE sim: 817.2525572803294\n",
      "627 \tNSE sim: 0.23423318898140177 \tMSE sim: 0.6049471194996988\n",
      "628 \tNSE sim: -0.5873304084841351 \tMSE sim: 2780.4967518228905\n",
      "629 \tNSE sim: -0.9098784727381566 \tMSE sim: 12065.423391318664\n",
      "630 \tNSE sim: 0.21854932754353196 \tMSE sim: 0.336625077601261\n",
      "631 \tNSE sim: 0.06089293068761292 \tMSE sim: 2.245493531015373\n",
      "632 \tNSE sim: -0.08573825194014328 \tMSE sim: 2.635607883808625\n",
      "633 \tNSE sim: 0.09698096136842682 \tMSE sim: 1.2532491065596993\n",
      "634 \tNSE sim: -0.0027378892809690747 \tMSE sim: 3.36825885086773\n",
      "635 \tNSE sim: -0.043464769299708994 \tMSE sim: 106.56753095663738\n",
      "636 \tNSE sim: 0.0036005374792122957 \tMSE sim: 5.488524357851066\n",
      "637 \tNSE sim: -0.3131413387951354 \tMSE sim: 49.52407871991234\n",
      "638 \tNSE sim: 0.18258681352739514 \tMSE sim: 6.190132526273764\n",
      "639 \tNSE sim: 0.22584514360696828 \tMSE sim: 2.821468976777494\n",
      "640 \tNSE sim: 0.14443161682112637 \tMSE sim: 8.895435051840966\n",
      "641 \tNSE sim: -0.2385757893776792 \tMSE sim: 903.1826672562802\n",
      "642 \tNSE sim: 0.32331900408716197 \tMSE sim: 0.01770244277548068\n",
      "643 \tNSE sim: 0.14377182901960794 \tMSE sim: 0.5191767562807605\n",
      "644 \tNSE sim: -1.00327265610442 \tMSE sim: 1.4848377584334311\n",
      "645 \tNSE sim: 0.18971731581419682 \tMSE sim: 0.023518310230249594\n",
      "646 \tNSE sim: -0.24343368044877067 \tMSE sim: 1.346856474712855\n",
      "647 \tNSE sim: 0.06309394859809403 \tMSE sim: 0.03274719147036169\n",
      "648 \tNSE sim: 0.027160372047195902 \tMSE sim: 0.7063112418488147\n",
      "649 \tNSE sim: -0.2633689418790668 \tMSE sim: 32.19547909336804\n",
      "650 \tNSE sim: 0.029422486729970165 \tMSE sim: 1.2689439650458454\n",
      "651 \tNSE sim: -0.34455535533640624 \tMSE sim: 47.82894002477901\n",
      "652 \tNSE sim: 0.17179611809732964 \tMSE sim: 0.5825719827740061\n",
      "653 \tNSE sim: -0.35094669422414104 \tMSE sim: 297.6285528388307\n",
      "654 \tNSE sim: -0.44015138731076964 \tMSE sim: 286.3047710597307\n",
      "655 \tNSE sim: 0.015837551867879163 \tMSE sim: 0.6585861820051874\n",
      "656 \tNSE sim: -0.00902999401480642 \tMSE sim: 1.2451513288239928\n",
      "657 \tNSE sim: -23.390409138293325 \tMSE sim: 0.9686391303574201\n",
      "658 \tNSE sim: 0.11857966220272398 \tMSE sim: 2.6657482695407446\n",
      "659 \tNSE sim: -0.06426836015291015 \tMSE sim: 1.4354659787743482\n",
      "660 \tNSE sim: -0.12672532464288877 \tMSE sim: 1.1877760225308103\n",
      "661 \tNSE sim: 0.20207040838969115 \tMSE sim: 0.18010802915219262\n",
      "662 \tNSE sim: 0.35505599512643415 \tMSE sim: 0.055498566862099794\n",
      "663 \tNSE sim: 0.31194892498068794 \tMSE sim: 0.2097109649109399\n",
      "664 \tNSE sim: -0.3899850169414072 \tMSE sim: 202.69754333999646\n",
      "665 \tNSE sim: -0.12403566983213765 \tMSE sim: 46.657205989425364\n",
      "666 \tNSE sim: -0.5489768960461743 \tMSE sim: 6592.071841697735\n",
      "667 \tNSE sim: 0.12445843296675241 \tMSE sim: 24.555629014621235\n",
      "668 \tNSE sim: -0.21632307708291276 \tMSE sim: 84.57699891568458\n",
      "669 \tNSE sim: -0.17445721861000418 \tMSE sim: 28.030758264956493\n",
      "670 \tNSE sim: -0.9065341865297356 \tMSE sim: 36.59796227409459\n",
      "671 \tNSE sim: 0.21687509941403715 \tMSE sim: 0.24316369525232007\n",
      "672 \tNSE sim: -0.5002027861491629 \tMSE sim: 4.038826462917449\n",
      "673 \tNSE sim: -0.27876078145518446 \tMSE sim: 181.11838101394267\n",
      "674 \tNSE sim: -0.3087673345687958 \tMSE sim: 105.83068863165458\n",
      "675 \tNSE sim: 0.008430726695413782 \tMSE sim: 156.01036605645808\n",
      "02GA038 676 \tNSE: -0.061246406722009095 \tMSE: 174.61584618343562 (clipped to 0)\n",
      "676 \tNSE sim: -0.10530374505745854 \tMSE sim: 42.03528258487726\n",
      "02GA047 677 \tNSE: -0.10061360528002394 \tMSE: 86.2771276641578 (clipped to 0)\n",
      "677 \tNSE sim: 0.2341947683109432 \tMSE sim: 71.29820963804674\n",
      "04159492 678 \tNSE: -0.0866518152304383 \tMSE: 504.52570355655365 (clipped to 0)\n",
      "678 \tNSE sim: -0.1474746181097426 \tMSE sim: 340.61678023509927\n",
      "679 \tNSE sim: -0.17571190862198272 \tMSE sim: 370.17029030184943\n",
      "04159900 680 \tNSE: 0.05872054488844303 \tMSE: 40.895735204251594 (clipped to 0)\n",
      "680 \tNSE sim: 0.03835305889821028 \tMSE sim: 36.28142977099873\n",
      "04160600 681 \tNSE: 0.06250363359827704 \tMSE: 27.122628108954764 (clipped to 0)\n",
      "681 \tNSE sim: 0.1014332805167043 \tMSE sim: 17.325309848273882\n",
      "02GG006 682 \tNSE: 0.02865520461831439 \tMSE: 52.07112274259033 (clipped to 0)\n",
      "682 \tNSE sim: 0.11178713883972302 \tMSE sim: 13.871756747265094\n",
      "02GD004 683 \tNSE: 0.13534444507300802 \tMSE: 47.610592297877396 (clipped to 0)\n",
      "683 \tNSE sim: 0.27057288356623777 \tMSE sim: 21.490954198895764\n",
      "02GA018 684 \tNSE: -0.14307014565594023 \tMSE: 287.0857026184171 (clipped to 0)\n",
      "684 \tNSE sim: -0.2976225624275146 \tMSE sim: 120.45629886056959\n",
      "02GA010 685 \tNSE: -0.22104870754966321 \tMSE: 582.1637249076666 (clipped to 0)\n",
      "685 \tNSE sim: -0.23932517960952304 \tMSE sim: 297.83290073299577\n",
      "02GB007 686 \tNSE: -0.02524938799045917 \tMSE: 32.0616137568012 (clipped to 0)\n",
      "686 \tNSE sim: -0.05553395945154782 \tMSE sim: 31.07889347360541\n",
      "02GB001 687 \tNSE: -0.8968004589152361 \tMSE: 14244.734723105363 (clipped to 0)\n",
      "687 \tNSE sim: -0.7861733631066881 \tMSE sim: 8702.182391010596\n",
      "04215000 688 \tNSE: -0.032256523934621306 \tMSE: 99.15114267552136 (clipped to 0)\n",
      "688 \tNSE sim: 0.23138534294495694 \tMSE sim: 6.187617238839625\n",
      "04166100 689 \tNSE: -0.15326663500366977 \tMSE: 8.457259078620913 (clipped to 0)\n",
      "689 \tNSE sim: -0.08546523783818927 \tMSE sim: 48.24360256599205\n",
      "04166500 690 \tNSE: -0.20617371080566027 \tMSE: 41.690540774436535 (clipped to 0)\n",
      "690 \tNSE sim: -0.869318602533723 \tMSE sim: 193.94679240485792\n",
      "04161820 691 \tNSE: -1.21926779261001 \tMSE: 70.08014734581185 (clipped to 0)\n",
      "691 \tNSE sim: -0.3091712541021088 \tMSE sim: 58.02660821233117\n",
      "04165500 692 \tNSE: -0.7424262038811422 \tMSE: 780.0126290778378 (clipped to 0)\n",
      "692 \tNSE sim: -0.8098617107144788 \tMSE sim: 725.5660462087094\n",
      "04164000 693 \tNSE: -0.6960485489318344 \tMSE: 297.1941056779683 (clipped to 0)\n",
      "693 \tNSE sim: -0.8196401351975402 \tMSE sim: 289.3047284795571\n",
      "02GG009 694 \tNSE: -0.050045183159548534 \tMSE: 163.33812646854952 (clipped to 0)\n",
      "694 \tNSE sim: -0.07716297056065335 \tMSE sim: 67.3292669487634\n",
      "02GG013 695 \tNSE: 0.06470700124065765 \tMSE: 35.71171280705231 (clipped to 0)\n",
      "695 \tNSE sim: 0.09648051174100969 \tMSE sim: 15.787157091104522\n",
      "02GG003 696 \tNSE: -0.23577665408857396 \tMSE: 589.9568963366529 (clipped to 0)\n",
      "696 \tNSE sim: -0.30713768875564074 \tMSE sim: 385.6139339251\n",
      "02GE007 697 \tNSE: 0.07532686344523731 \tMSE: 33.45010478941006 (clipped to 0)\n",
      "697 \tNSE sim: 0.16193221728017104 \tMSE sim: 9.419889373122004\n",
      "02GG002 698 \tNSE: -0.19705804894409074 \tMSE: 288.70984364223955 (clipped to 0)\n",
      "698 \tNSE sim: -0.3127160153896409 \tMSE sim: 176.08631850091913\n",
      "02GC002 699 \tNSE: -0.08090580334405773 \tMSE: 138.8996758686135 (clipped to 0)\n",
      "699 \tNSE sim: -0.2924484616693577 \tMSE sim: 38.311727671648576\n",
      "02GC018 700 \tNSE: -0.009311148275122472 \tMSE: 68.35741601715553 (clipped to 0)\n",
      "700 \tNSE sim: -0.19300291823871873 \tMSE sim: 49.87828751906498\n",
      "02GC010 701 \tNSE: 0.09676807437588453 \tMSE: 53.697065538130744 (clipped to 0)\n",
      "701 \tNSE sim: 0.18711288678578974 \tMSE sim: 33.07642424732915\n",
      "02GC026 702 \tNSE: -0.43116910707964107 \tMSE: 230.17886798905798 (clipped to 0)\n",
      "702 \tNSE sim: -0.3412791777938673 \tMSE sim: 161.6278253468407\n",
      "02GC007 703 \tNSE: -1.536506252450327 \tMSE: 76.40297859003185 (clipped to 0)\n",
      "703 \tNSE sim: -0.4014636362447219 \tMSE sim: 161.54783646537584\n",
      "04213500 704 \tNSE: -0.1771893503967399 \tMSE: 1205.9325984370616 (clipped to 0)\n",
      "704 \tNSE sim: -0.169516817316258 \tMSE sim: 278.8626485688946\n",
      "04214500 705 \tNSE: -0.05810055921999324 \tMSE: 127.5403592196614 (clipped to 0)\n",
      "705 \tNSE sim: -0.00273224392058391 \tMSE sim: 24.00576932438179\n",
      "04215500 706 \tNSE: -0.1573534639589247 \tMSE: 209.00057291734655 (clipped to 0)\n",
      "706 \tNSE sim: -0.4617685005801182 \tMSE sim: 43.98509357001663\n",
      "04174500 707 \tNSE: -1.6037485882466687 \tMSE: 246.2475349947887 (clipped to 0)\n",
      "707 \tNSE sim: -0.24052243361579606 \tMSE sim: 198.4454197573391\n",
      "708 \tNSE sim: -0.10804985592719518 \tMSE sim: 10.320587673307775\n",
      "04176500 709 \tNSE: -0.47193850277169513 \tMSE: 1005.4432393302523 (clipped to 0)\n",
      "709 \tNSE sim: -0.3901243613096719 \tMSE sim: 717.6347726522055\n",
      "04213000 710 \tNSE: -0.2514131248781566 \tMSE: 224.59015792170746 (clipped to 0)\n",
      "710 \tNSE sim: -0.2763518889596315 \tMSE sim: 53.071327769584805\n",
      "711 \tNSE sim: -0.02081773501689632 \tMSE sim: 19.629680887030613\n",
      "04177000 712 \tNSE: -0.04553919998123934 \tMSE: 28.177103500272842 (clipped to 0)\n",
      "712 \tNSE sim: 0.11149757685228634 \tMSE sim: 3.74262562994789\n",
      "04193500 713 \tNSE: -0.40144929397930573 \tMSE: 99223.66007461607 (clipped to 0)\n",
      "713 \tNSE sim: -0.5955995835290506 \tMSE sim: 50982.13343133626\n",
      "04195820 714 \tNSE: -0.1702093238454745 \tMSE: 1373.585075407185 (clipped to 0)\n",
      "714 \tNSE sim: -0.552672479395294 \tMSE sim: 322.13158750578657\n",
      "04198000 715 \tNSE: -0.2146626691506317 \tMSE: 8973.39262166286 (clipped to 0)\n",
      "715 \tNSE sim: -0.5860269433620964 \tMSE sim: 2236.0035229865853\n",
      "04199000 716 \tNSE: -0.09150130016944402 \tMSE: 1116.1728312738032 (clipped to 0)\n",
      "716 \tNSE sim: -0.35245648123816187 \tMSE sim: 181.98019075000775\n",
      "04199500 717 \tNSE: -0.12468376488811206 \tMSE: 455.10117326101545 (clipped to 0)\n",
      "717 \tNSE sim: -0.43134474090908315 \tMSE sim: 101.74565644352005\n",
      "04200500 718 \tNSE: -0.11759663463062942 \tMSE: 1118.3844909806726 (clipped to 0)\n",
      "718 \tNSE sim: -0.39639208314186347 \tMSE sim: 168.85721692820832\n",
      "04208504 719 \tNSE: -1.4164620377114678 \tMSE: 2359.7444263798416 (clipped to 0)\n",
      "719 \tNSE sim: -1.2605092294996658 \tMSE sim: 1236.982850080077\n",
      "04207200 720 \tNSE: -0.5040353955863086 \tMSE: 35.20389058667751 (clipped to 0)\n",
      "720 \tNSE sim: -0.7784173911086534 \tMSE sim: 11.466612852493274\n",
      "04212100 721 \tNSE: -0.49396447273708466 \tMSE: 2193.625440194002 (clipped to 0)\n",
      "721 \tNSE sim: -0.6532631706030376 \tMSE sim: 577.3722180575796\n",
      "04209000 722 \tNSE: -0.379271097096898 \tMSE: 431.2374062008637 (clipped to 0)\n",
      "722 \tNSE sim: -0.6171149883862426 \tMSE sim: 92.98570959145424\n",
      "04197100 723 \tNSE: 0.07146228081033368 \tMSE: 95.23492309312545 (clipped to 0)\n",
      "723 \tNSE sim: 0.1912256853024512 \tMSE sim: 14.550756114288209\n",
      "04196800 724 \tNSE: -0.0326696792220873 \tMSE: 309.02483905529436 (clipped to 0)\n",
      "724 \tNSE sim: -0.15648867918667753 \tMSE sim: 76.28805766336501\n"
     ]
    }
   ],
   "source": [
    "actuals = test_dataset.data_runoff.copy()\n",
    "if len(actuals['date'].unique()) != len(predictions):\n",
    "    print('Warning: length of prediction {} and actuals {} does not match.'.format(len(predictions), len(actuals['date'].unique())))\n",
    "\n",
    "nse_dict, nse_sim_dict = {}, {}\n",
    "mse_dict, mse_sim_dict = {}, {}\n",
    "predictions_df = pd.DataFrame(columns=actuals.columns)\n",
    "predictions_df['is_test_subbasin'] = False\n",
    "predictions_df['is_val_subbasin'] = False\n",
    "for subbasin in test_dataset.simulated_streamflow['subbasin'].unique():\n",
    "    row, col = test_dataset.outlet_to_row_col[subbasin]\n",
    "    \n",
    "    station = None\n",
    "    subbasin_sim = test_dataset.simulated_streamflow[test_dataset.simulated_streamflow['subbasin'] == subbasin].set_index('date')\n",
    "    if subbasin in station_subbasins:\n",
    "        station = subbasin_sim['StationID'].values[0]\n",
    "        act = actuals[actuals['station'] == station].set_index('date')['runoff']\n",
    "    if predictions.shape[0] != subbasin_sim.shape[0]:\n",
    "        print('Warning: length of prediction {} and actuals {} does not match for subbasin {}. Ignoring excess actuals.'.format(len(predictions), len(subbasin_sim), subbasin))\n",
    "        subbasin_sim = subbasin_sim.iloc[:predictions.shape[0]]\n",
    "        if station is not None:\n",
    "            act = act.iloc[:predictions.shape[0]]\n",
    "    pred = pd.DataFrame({'runoff': predictions[:,row,col]}, index=subbasin_sim.index)\n",
    "    pred['subbasin'] = subbasin\n",
    "    pred['station'] = station\n",
    "    pred['is_test_subbasin'] = subbasin in test_subbasins\n",
    "    pred['is_val_subbasin'] = subbasin in val_subbasins\n",
    "    predictions_df = predictions_df.append(pred.reset_index(), sort=True)\n",
    "    subbasin_type = 'test' if subbasin in test_subbasins else ('val' if subbasin in val_subbasins else 'train')\n",
    "    nse_sim, mse_sim = evaluate.evaluate_daily('Sub{}'.format(subbasin), pred['runoff'], subbasin_sim['simulated_streamflow'], writer=writer, group=subbasin_type)\n",
    "    nse_sim_dict[subbasin] = nse_sim\n",
    "    mse_sim_dict[subbasin] = mse_sim\n",
    "\n",
    "    if station is not None:\n",
    "        nse, mse = evaluate.evaluate_daily(station, pred['runoff'], act, writer=writer)\n",
    "        nse_dict[subbasin] = nse\n",
    "        mse_dict[subbasin] = mse\n",
    "        print(station, subbasin, '\\tNSE:', nse, '\\tMSE:', mse, '(clipped to 0)')\n",
    "    print(subbasin, '\\tNSE sim:', nse_sim, '\\tMSE sim:', mse_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sim Median NSE (clipped to 0) -0.015881157864535922 / Min -17.75275960314488 / Max 0.3737125083899444\n",
      "Train sim Median MSE (clipped to 0) 13.90055598548503 / Min 0.0022841912149631043 / Max 2518214.5633527376\n",
      "Val sim Median NSE (clipped to 0) -0.25636021752719673 / Min -138.31283191975987 / Max 0.3937167838425769\n",
      "Val sim Median MSE (clipped to 0) 23.374567682501933 / Min 0.2097109649109399 / Max 51377.98594916705\n",
      "Test sim Median NSE (clipped to 0) -0.015881157864535922 / Min -17.75275960314488 / Max 0.3737125083899444\n",
      "Test sim Median MSE (clipped to 0) 13.90055598548503 / Min 0.0022841912149631043 / Max 2518214.5633527376\n",
      "Stations (Train/Val) Median NSE (clipped to 0) -0.1637813939021996 / Min -1.6037485882466687 / Max 0.09676807437588453\n",
      "Stations (Train/Val) Median MSE (clipped to 0) 216.795365419527 / Min 8.457259078620913 / Max 99223.66007461607\n",
      "Stations (Test) Median NSE (clipped to 0) -0.10454896740003672 / Min -0.5040353955863086 / Max 0.13534444507300802\n",
      "Stations (Test) Median MSE (clipped to 0) 193.93049315888044 / Min 33.45010478941006 / Max 1118.3844909806726\n",
      "Stations (Train/Val/Test) Median NSE (clipped to 0) -0.148168390329805 / Min -1.6037485882466687 / Max 0.13534444507300802\n",
      "Stations (Train/Val/Test) Median MSE (clipped to 0) 216.795365419527 / Min 8.457259078620913 / Max 99223.66007461607\n"
     ]
    }
   ],
   "source": [
    "def print_nse_mse(name, nse_dict, mse_dict, subbasins):\n",
    "    nses = list(nse_dict[s] for s in subbasins)\n",
    "    mses = list(mse_dict[s] for s in subbasins)\n",
    "    print(name, 'Median NSE (clipped to 0)', np.median(nses), '/ Min', np.min(nses), '/ Max', np.max(nses))\n",
    "    print(name, 'Median MSE (clipped to 0)', np.median(mses), '/ Min', np.min(mses), '/ Max', np.max(mses))\n",
    "    \n",
    "    return np.median(nses)\n",
    "\n",
    "print_nse_mse('Train sim', nse_sim_dict, mse_sim_dict, train_subbasins)\n",
    "print_nse_mse('Val sim', nse_sim_dict, mse_sim_dict, val_subbasins)\n",
    "nse_median_sim_test = print_nse_mse('Test sim', nse_sim_dict, mse_sim_dict, train_subbasins)\n",
    "nse_median_stations_train_val = print_nse_mse('Stations (Train/Val)', nse_dict, mse_dict, list(s for s in station_subbasins if s not in test_subbasins))\n",
    "nse_median_stations_test = print_nse_mse('Stations (Test)', nse_dict, mse_dict, list(s for s in station_subbasins if s in test_subbasins))\n",
    "nse_median_stations = print_nse_mse('Stations (Train/Val/Test)', nse_dict, mse_dict, station_subbasins)\n",
    "\n",
    "writer.add_scalar('nse_median_sim', nse_median_sim_test)\n",
    "writer.add_scalar('nse_median_stations_test', nse_median_stations_test)\n",
    "writer.add_scalar('nse_median_stations_all', nse_median_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{676: -0.061246406722009095,\n",
       " 677: -0.10061360528002394,\n",
       " 678: -0.0866518152304383,\n",
       " 680: 0.05872054488844303,\n",
       " 681: 0.06250363359827704,\n",
       " 682: 0.02865520461831439,\n",
       " 683: 0.13534444507300802,\n",
       " 684: -0.14307014565594023,\n",
       " 685: -0.22104870754966321,\n",
       " 686: -0.02524938799045917,\n",
       " 687: -0.8968004589152361,\n",
       " 688: -0.032256523934621306,\n",
       " 689: -0.15326663500366977,\n",
       " 690: -0.20617371080566027,\n",
       " 691: -1.21926779261001,\n",
       " 692: -0.7424262038811422,\n",
       " 693: -0.6960485489318344,\n",
       " 694: -0.050045183159548534,\n",
       " 695: 0.06470700124065765,\n",
       " 696: -0.23577665408857396,\n",
       " 697: 0.07532686344523731,\n",
       " 698: -0.19705804894409074,\n",
       " 699: -0.08090580334405773,\n",
       " 700: -0.009311148275122472,\n",
       " 701: 0.09676807437588453,\n",
       " 702: -0.43116910707964107,\n",
       " 703: -1.536506252450327,\n",
       " 704: -0.1771893503967399,\n",
       " 705: -0.05810055921999324,\n",
       " 706: -0.1573534639589247,\n",
       " 707: -1.6037485882466687,\n",
       " 709: -0.47193850277169513,\n",
       " 710: -0.2514131248781566,\n",
       " 712: -0.04553919998123934,\n",
       " 713: -0.40144929397930573,\n",
       " 714: -0.1702093238454745,\n",
       " 715: -0.2146626691506317,\n",
       " 716: -0.09150130016944402,\n",
       " 717: -0.12468376488811206,\n",
       " 718: -0.11759663463062942,\n",
       " 719: -1.4164620377114678,\n",
       " 720: -0.5040353955863086,\n",
       " 721: -0.49396447273708466,\n",
       " 722: -0.379271097096898,\n",
       " 723: 0.07146228081033368,\n",
       " 724: -0.0326696792220873}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nse_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ConvLSTM_simulationTraining_20190817-095426.pkl'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_df = pd.merge(predictions_df.rename({'runoff': 'prediction'}, axis=1), \n",
    "                   test_dataset.simulated_streamflow, on=['date', 'subbasin'])\n",
    "save_df = pd.merge(save_df, actuals.rename({'runoff': 'actual'}, axis=1), how='left', on=['date', 'station'])\\\n",
    "            [['date', 'subbasin', 'station', 'prediction', 'actual', 'simulated_streamflow', 'is_test_subbasin', 'is_val_subbasin']]\n",
    "load_data.pickle_results('ConvLSTM_simulationTraining', save_df, time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 5, 6, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 39, 42, 43, 45, 46, 47, 48, 52, 54, 55, 57, 58, 59, 62, 63, 64, 66, 67, 70, 73, 74, 75, 78, 79, 81, 82, 84, 85, 87, 88, 89, 91, 92, 94, 95, 96, 98, 99, 100, 101, 102, 103, 105, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 120, 121, 122, 124, 125, 126, 127, 128, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 144, 145, 147, 148, 149, 150, 152, 153, 154, 155, 156, 159, 160, 161, 162, 164, 165, 166, 167, 168, 169, 174, 175, 177, 178, 179, 180, 181, 183, 184, 185, 187, 189, 190, 191, 192, 193, 194, 195, 196, 198, 199, 200, 201, 202, 203, 204, 206, 208, 209, 211, 212, 213, 214, 217, 218, 219, 220, 221, 223, 224, 225, 226, 227, 228, 229, 231, 233, 234, 235, 237, 238, 239, 241, 242, 243, 246, 249, 250, 251, 254, 255, 257, 260, 261, 262, 263, 265, 266, 270, 271, 273, 274, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 288, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299, 301, 302, 303, 304, 305, 306, 308, 309, 310, 312, 313, 314, 315, 319, 320, 321, 322, 323, 324, 325, 327, 330, 332, 333, 334, 335, 336, 337, 340, 341, 342, 343, 344, 346, 347, 348, 349, 350, 354, 358, 360, 361, 362, 363, 366, 367, 369, 371, 372, 373, 374, 378, 379, 380, 382, 384, 385, 389, 390, 391, 392, 393, 395, 396, 397, 398, 399, 400, 402, 404, 405, 406, 409, 411, 412, 413, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 427, 428, 429, 430, 431, 432, 433, 434, 436, 438, 439, 441, 443, 444, 445, 447, 448, 449, 451, 452, 453, 454, 455, 456, 457, 459, 460, 462, 465, 466, 467, 468, 470, 471, 472, 473, 474, 476, 478, 480, 482, 485, 486, 487, 488, 489, 490, 492, 494, 495, 500, 501, 502, 503, 504, 505, 506, 508, 509, 510, 511, 515, 516, 518, 519, 520, 521, 522, 523, 524, 526, 528, 530, 531, 532, 534, 535, 536, 538, 539, 540, 541, 544, 545, 546, 549, 551, 552, 553, 554, 555, 556, 558, 559, 560, 561, 562, 563, 567, 568, 569, 571, 573, 575, 576, 578, 579, 580, 581, 584, 586, 588, 590, 591, 592, 593, 594, 595, 596, 597, 600, 602, 606, 607, 608, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 623, 625, 629, 630, 631, 632, 633, 634, 635, 636, 638, 639, 640, 641, 643, 645, 648, 649, 651, 652, 653, 654, 655, 656, 658, 661, 662, 664, 665, 666, 667, 668, 671, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 685, 686, 687, 689, 691, 692, 693, 694, 695, 696, 699, 701, 702, 703, 704, 705, 706, 707, 708, 710, 712, 713, 714, 715, 719, 721, 722, 723]\n",
      "[129 604 258 622 537 172   8 300 151  71 566 287 331 338 461 207 724  40\n",
      " 711 446 146 376 329 137 496  93 646 394 513 529 660 435  97 663 637 609\n",
      " 352 275 106 601 222 408 572 247 644 272 550 368 388 484 377  83 386 186\n",
      " 684   7 107 245 582 170 210  90 690  44  60 359  72 599 621 543  61  68]\n",
      "[570 497 585 475 259 236 464  41  32  15 647 642 123 326 598 356 114 700\n",
      " 483 565 104 364 163 307 603 477 469 626   9 387 533 381 698 269 403 548\n",
      " 613 365 188   2  56 414 345 627 158 442 717 294 512 564 318 525 583 463\n",
      " 357 407 252 230 328 589 688 253 697  28 499 197 557 355 284 670 720 182\n",
      "  76  80  86 317 176 268 440 624 316  51 173 527 650 481 574 410  11  69\n",
      " 458 493 718 517 542 375 479 716 205 672 215 370 264 657 383 353 351 248\n",
      " 267 244  50 256 401 240 171 669 587  38 339  49 547 426 514  19 683 507\n",
      "  77  65 577  53 498 628 437 450 491 605 157 143 119 216 232 311 709 659]\n"
     ]
    }
   ],
   "source": [
    "_ = print(train_subbasins), print(val_subbasins), print(test_subbasins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[683, 688, 697, 698, 700, 709, 716, 717, 718, 720]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(k for k in list(nse_dict.keys()) if k in test_subbasins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190817-165028'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
