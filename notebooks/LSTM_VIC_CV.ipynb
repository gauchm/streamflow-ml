{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM trained on gridded forcings for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src import load_data, evaluate\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA Available')\n",
    "    USE_CUDA = True\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "writer = SummaryWriter(log_dir='../runs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/load_data.py:18: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(os.path.join(dir, f), skiprows=2, skipfooter=1, index_col=False, header=None, names=['runoff'], na_values='-1.2345')\n",
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "station_data_dict = load_data.load_train_test_lstm()\n",
    "data_runoff = load_data.load_discharge_gr4j_vic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegression(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, num_layers, batch_size):\n",
    "            super(LSTMRegression, self).__init__()\n",
    "            self.batch_size = batch_size\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.num_layers = num_layers\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers)\n",
    "            self.linear = nn.Linear(hidden_dim, 1)\n",
    "            self.hidden = self.init_hidden()\n",
    "        def init_hidden(self):\n",
    "            return (torch.randn(self.num_layers, self.batch_size, self.hidden_dim, device=device),\n",
    "                    torch.randn(self.num_layers, self.batch_size, self.hidden_dim, device=device))\n",
    "\n",
    "        def forward(self, input):\n",
    "            lstm_out, self.hidden = self.lstm(input, self.hidden)\n",
    "            return self.linear(lstm_out[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "actuals = {}\n",
    "models = {}\n",
    "seq_len = 7 * 24\n",
    "train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(days=seq_len // 24 + 1)\n",
    "train_ends = ['2012-12-31', '2013-01-31', '2013-02-28', '2013-03-31', '2013-04-30', '2013-05-31', \\\n",
    "              '2013-06-30', '2013-07-31', '2013-08-31', '2013-09-30', '2013-10-31', '2013-11-30']\n",
    "test_ends = train_ends[1:] + ['2013-12-31']\n",
    "\n",
    "\n",
    "plot_list = ['04159492']\n",
    "median_nse_list = []\n",
    "for cv_iter in range(len(train_ends)):\n",
    "    train_end = train_ends[cv_iter]\n",
    "    test_start = datetime.strptime(train_end, '%Y-%m-%d') + timedelta(days=1)\n",
    "    test_end = test_ends[cv_iter]\n",
    "    print('Train: {} - {}, Test: {} - {}'.format(train_start.strftime('%Y-%m-%d'), train_end, test_start.strftime('%Y-%m-%d'), test_end))\n",
    "    \n",
    "    nse_list = []\n",
    "    for station, station_rdrs in station_data_dict.items():\n",
    "        station_runoff = data_runoff[data_runoff['station'] == station].set_index('date')\n",
    "        if any(station_runoff['runoff'].isna()):\n",
    "            print('Station', station, 'had NA runoff values. Skipping.')\n",
    "            continue\n",
    "\n",
    "        station_train = station_rdrs.loc[train_start : train_end]\n",
    "        station_test = station_rdrs.loc[test_start : test_end]\n",
    "        num_train_days = len(pd.date_range(train_start, train_end, freq='D'))\n",
    "\n",
    "        x = np.zeros((seq_len, len(pd.date_range(train_start, test_end, freq='D')), station_rdrs.shape[1]))\n",
    "        for day in range(x.shape[1]):\n",
    "            x[:,day,:] = station_rdrs[train_start - timedelta(hours = seq_len - 1) + timedelta(days=day) : train_start + timedelta(days=day)]\n",
    "\n",
    "        # Scale training data\n",
    "        scalers = []  # save scalers to apply them to test data later\n",
    "        x_train = x[:,:num_train_days,:]\n",
    "        for i in range(x.shape[2]):\n",
    "            scalers.append(preprocessing.StandardScaler())\n",
    "            x_train[:,:,i] = scalers[i].fit_transform(x_train[:,:,i].reshape((-1, 1))).reshape(x_train[:,:,i].shape)\n",
    "        x_train = torch.from_numpy(x_train).float().to(device)\n",
    "        y_train = torch.from_numpy(station_runoff.loc[train_start:train_end, 'runoff'].to_numpy()).float().to(device)\n",
    "\n",
    "        # Train model\n",
    "        learning_rate = 2e-3\n",
    "        patience = 50\n",
    "        min_improvement = 0.05\n",
    "        best_loss_model = (-1, np.inf, None)\n",
    "\n",
    "        # Prepare model\n",
    "        H = 200\n",
    "        batch_size = 3\n",
    "        lstm_layers = 2\n",
    "        model = LSTMRegression(station_rdrs.shape[1], H, lstm_layers, batch_size).to(device)\n",
    "        loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(300):\n",
    "            epoch_losses = []\n",
    "            for i in range(num_train_days // batch_size):\n",
    "                model.hidden = model.init_hidden()\n",
    "                y_pred = model(x_train[:,i*batch_size : (i+1)*batch_size,:])\n",
    "\n",
    "                loss = loss_fn(y_pred, y_train[i*batch_size : (i+1)*batch_size].reshape((batch_size,1))).to(device)\n",
    "                epoch_losses.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            epoch_loss = np.array(epoch_losses).mean()\n",
    "            writer.add_scalar('loss_' + station, epoch_loss, epoch)\n",
    "            if epoch_loss < best_loss_model[1] - min_improvement:\n",
    "                best_loss_model = (epoch, epoch_loss, model.state_dict())  # new best model\n",
    "            elif epoch > best_loss_model[0] + patience:\n",
    "                print('Patience exhausted in epoch {}. Best loss was {}'.format(epoch, best_loss_model[1]))\n",
    "                break\n",
    "\n",
    "        print('Using best model from epoch', str(best_loss_model[0]), 'which had loss', str(best_loss_model[1]))\n",
    "        model.load_state_dict(best_loss_model[2])\n",
    "        model.eval()        \n",
    "\n",
    "        # scale test data\n",
    "        x_test = x[:,num_train_days:,:]\n",
    "        for i in range(x.shape[2]):\n",
    "            x_test[:,:,i] = scalers[i].transform(x_test[:,:,i].reshape((-1, 1))).reshape(x_test[:,:,i].shape)\n",
    "        # if batch size doesn't align with number of samples, add dummies to the last batch\n",
    "        if x_test.shape[1] % batch_size != 0:\n",
    "            x_test = np.concatenate([x_test, np.zeros((x_test.shape[0], batch_size - (x_test.shape[1] % batch_size), x_test.shape[2]))], axis=1)\n",
    "\n",
    "        x_test = torch.from_numpy(x_test).float().to(device)\n",
    "        predict = station_runoff[test_start:test_end].copy()\n",
    "        predict['runoff'] = np.nan\n",
    "        pred_array = np.array([])\n",
    "        for i in range(x_test.shape[1] // batch_size):\n",
    "            pred_array = np.concatenate([pred_array, model(x_test[:,i*batch_size : (i+1)*batch_size,:]).detach().cpu().numpy().reshape(batch_size)])\n",
    "        predict['runoff'] = pred_array[:predict.shape[0]]  # ignore dummies\n",
    "        predictions[station] = predict\n",
    "        actuals[station] = station_runoff['runoff'].loc[test_start:test_end]\n",
    "        models[station] = model\n",
    "        \n",
    "        nse = evaluate.evaluate_daily(station + '_CV_{}-{}'.format(test_start.strftime('%Y-%m-%d'), test_end), predict['runoff'], actuals[station], writer=writer)\n",
    "        nse_list.append(nse)\n",
    "    \n",
    "    print('  NSEs: {}:'.format(nse_list))\n",
    "    median_nse_list.append(np.median(nse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_nse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
