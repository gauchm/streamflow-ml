{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics, svm, neural_network, ensemble\n",
    "from datetime import datetime, timedelta\n",
    "import hydroeval\n",
    "import netCDF4 as nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amnesix\\Miniconda3\\envs\\gwf\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "C:\\Users\\Amnesix\\Miniconda3\\envs\\gwf\\lib\\site-packages\\pandas\\core\\frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "dir = 'ObservedDischarge_GR4J+VIC'  # Read runoff observations\n",
    "data_runoff = pd.DataFrame(columns=['date','runoff', 'station'])\n",
    "for f in os.listdir(dir):\n",
    "    if not f.endswith('.rvt'):\n",
    "        continue\n",
    "    data = pd.read_csv(os.path.join(dir, f), skiprows=2, skipfooter=1, index_col=False, header=None, names=['runoff'], na_values='-1.2345')\n",
    "    data['date'] = pd.date_range('2010-01-01', periods=len(data), freq='D')\n",
    "    data['station'] = f[11:-4]\n",
    "    data_runoff = data_runoff.append(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station\n",
       "02GC018       44\n",
       "02GG013       31\n",
       "04214500    1003\n",
       "Name: date, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_runoff[pd.isna(data_runoff['runoff'])].groupby(['station'])['date'].count()  # Count NAs per station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "forcing_variables = ['RDRS_FB_SFC', 'RDRS_FI_SFC', 'RDRS_HU_40m', 'RDRS_P0_SFC', 'RDRS_PR0_SFC', 'RDRS_TT_40m', 'RDRS_UVC_40m', 'RDRS_WDC_40m']\n",
    "rdrs_nc = nc.Dataset('RDRS_CaPA24hr_forcings_final.nc', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdrs_data = pd.DataFrame(index=pd.date_range('2010-01-01 7:00', '2015-01-01 7:00', freq='H')) # Using 7:00 because forcings are UTC, while runoff is local time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in forcing_variables:\n",
    "    var_data = pd.DataFrame(rdrs_nc[var][:].reshape(43825,34*39))\n",
    "    var_data.dropna(axis=1, how='all', inplace=True)\n",
    "    var_data.columns = [var + '_' + str(c) for c in var_data.columns]\n",
    "    rdrs_data = rdrs_data.reset_index(drop=True).join(var_data.reset_index(drop=True))\n",
    "rdrs_data.index = pd.date_range('2010-01-01 7:00', '2015-01-01 7:00', freq='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = rdrs_data.resample('D')\n",
    "rdrs_daily = resampled.mean().join(resampled.min(), lsuffix='_mean', rsuffix='_min').join(resampled.max().rename(lambda c: c + '_max', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_runoff.join(rdrs_daily, on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdrs_nc.close()\n",
    "del resampled, rdrs_daily, rdrs_nc, var_data, rdrs_data, data_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02GA010\n",
      "   1\n",
      "  Fitting model\n",
      "  Predicting\n",
      "   0\n"
     ]
    }
   ],
   "source": [
    "# Create test and train splits for each station (by time), then create predictions for each subbasin\n",
    "history = 7\n",
    "train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(days=history + 1)\n",
    "use_runoff_history = False\n",
    "\n",
    "predictions = {}\n",
    "actuals = {}\n",
    "independent_vars = list(col for col in data.columns if col not in ['date', 'station', 'runoff'])\n",
    "for station in data['station'].unique():\n",
    "    print(station)\n",
    "    station_data = data[data['station'] == station].set_index('date')\n",
    "\n",
    "    for i in range(1, history + 1):\n",
    "        print('   {}'.format(i))\n",
    "        station_data[['-{}_{}'.format(i, var) for var in independent_vars]] = station_data[independent_vars].shift(i, axis=0)\n",
    "        if use_runoff_history:\n",
    "            station_data['-{}_runoff'.format(i)] = station_data['runoff'].shift(i, axis=0)\n",
    "    \n",
    "    station_train = station_data.loc[train_start : '2013-12-31']\n",
    "    station_test = station_data.loc['2014-01-01' : '2014-12-31']\n",
    "    \n",
    "    print('  Fitting model')\n",
    "    m = linear_model.LinearRegression()\n",
    "    m.fit(station_train.drop(['station', 'runoff'], axis=1), station_train['runoff'])\n",
    "    \n",
    "    print('  Creating prediction dataframe')\n",
    "    station_test = station_test[~pd.isna(station_test['runoff'])]\n",
    "    if len(station_test) == 0:\n",
    "        print('Skipping', station)\n",
    "        continue\n",
    "    predict = pd.DataFrame(columns=[x for x in station_test.columns if x not in ['station']], index=station_test.index)\n",
    "    predict.loc[:,independent_vars] = station_test[independent_vars]\n",
    "    for i in range(history):\n",
    "        print('   {}'.format(i))\n",
    "        predict[['-{}_{}'.format(i + 1, var) for var in independent_vars]] = \\\n",
    "            station_test[['-{}_{}'.format(i + 1, var) for var in independent_vars]]\n",
    "        if use_runoff_history:\n",
    "            for j in range(i + 1, history + 1):\n",
    "                predict.iloc[i]['-{}_runoff'.format(j)] = station_test.iloc[i]['-{}_runoff'.format(j)]\n",
    "    print('  Predicting')\n",
    "    if not use_runoff_history:\n",
    "        predict['runoff'] = m.predict(predict.drop('runoff', axis=1))\n",
    "    else:\n",
    "        for i in range(len(predict)):\n",
    "            print('   day {}'.format(i))\n",
    "            predict.iloc[i]['runoff'] = m.predict([predict.iloc[i].drop('runoff')])[0]\n",
    "            for j in range(1, history + 1):\n",
    "                if (i + j) >= len(predict):\n",
    "                    break\n",
    "                predict.iloc[i + j]['-{}_runoff'.format(j)] = predict.iloc[i]['runoff']\n",
    "    predictions[station] = predict\n",
    "    actuals[station] = station_test['runoff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each subbasin\n",
    "nse_list = []\n",
    "plot_list = ['02GA010']\n",
    "for station, predict in predictions.items():\n",
    "    mse = metrics.mean_squared_error(actuals[station], predict['runoff'])\n",
    "\n",
    "    predict_clipped = predict.copy()\n",
    "    predict_clipped['runoff'] = predict['runoff'].clip(0)\n",
    "    mse_clip = metrics.mean_squared_error(actuals[station], predict_clipped['runoff'])\n",
    "    nse_list.append(hydroeval.evaluator(hydroeval.nse, predict_clipped['runoff'].to_numpy(), actuals[station].to_numpy())[0])\n",
    "    \n",
    "    print(station, '\\n\\tRMSE (clipped to 0):', np.sqrt(mse_clip))\n",
    "    print('\\tNSE: (clipped to 0)', nse_list[-1])\n",
    "    \n",
    "    if station in plot_list:\n",
    "        plt.figure(figsize=(17,4))\n",
    "        plt.title(station)\n",
    "        plt.plot(actuals[station], label='Test')\n",
    "        plt.plot(predict_clipped['runoff'], label='Prediction')\n",
    "        plt.legend()\n",
    "print('Median NSE (clipped to 0)', np.median(nse_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GWF",
   "language": "python",
   "name": "gwf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
