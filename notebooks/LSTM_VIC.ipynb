{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM trained on gridded forcings for each station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src import load_data, evaluate\n",
    "import torch.autograd as autograd\n",
    "import pickle\n",
    "\n",
    "time_stamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA Available')\n",
    "    USE_CUDA = True\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_data_dict = load_data.load_train_test_lstm()\n",
    "data_runoff = load_data.load_discharge_gr4j_vic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegression(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim, num_layers, batch_size, dropout):\n",
    "            super(LSTMRegression, self).__init__()\n",
    "            self.batch_size = batch_size\n",
    "            self.hidden_dim = hidden_dim\n",
    "            self.num_layers = num_layers\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, dropout=dropout)\n",
    "            self.linear = nn.Linear(hidden_dim, 1)\n",
    "            self.hidden = self.init_hidden()\n",
    "        def init_hidden(self):\n",
    "            return (torch.randn(self.num_layers, self.batch_size, self.hidden_dim, device=device),\n",
    "                    torch.randn(self.num_layers, self.batch_size, self.hidden_dim, device=device))\n",
    "\n",
    "        def forward(self, input):\n",
    "            lstm_out, self.hidden = self.lstm(input, self.hidden)\n",
    "            return self.linear(lstm_out[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {}\n",
    "actuals = {}\n",
    "seq_len = 5 * 24\n",
    "train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(hours=seq_len)  # first day for which to make a prediction in train set\n",
    "train_end = '2013-12-31' # last day for which to make a prediction in train set\n",
    "test_start = '2014-01-01'\n",
    "test_end = '2014-12-31'\n",
    "validation_fraction = 0.1\n",
    "\n",
    "for station in station_data_dict.keys():\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    station_rdrs = station_data_dict[station]\n",
    "    station_runoff = data_runoff[data_runoff['station'] == station].set_index('date')\n",
    "    if any(station_runoff['runoff'].isna()):\n",
    "        print('Station', station, 'had NA runoff values. Skipping.')\n",
    "        continue\n",
    "    \n",
    "    num_train_days = len(pd.date_range(train_start, train_end, freq='D'))\n",
    "    num_test_days = len(pd.date_range(test_start, test_end, freq='D'))\n",
    "    num_total_days = len(pd.date_range(train_start, test_end, freq='D'))\n",
    "    \n",
    "    x = np.zeros((seq_len, num_total_days, station_rdrs.shape[1]))\n",
    "    for day in range(x.shape[1]):\n",
    "        # For each day that is to be predicted, cut out a sequence that ends with that day's 23:00:00 and is seq_len long\n",
    "        x[:,day,:] = station_rdrs[train_start + timedelta(days=day, hours=-seq_len + 24) : train_start + timedelta(hours=23, days=day)]\n",
    "    \n",
    "    # Scale training data\n",
    "    scalers = []  # save scalers to apply them to test data later\n",
    "    x_train = x[:,:num_train_days,:].copy()\n",
    "    for i in range(x.shape[2]):\n",
    "        scalers.append(preprocessing.StandardScaler())\n",
    "        x_train[:,:,i] = scalers[i].fit_transform(x_train[:,:,i].reshape((-1, 1))).reshape(x_train[:,:,i].shape)\n",
    "    x_train = torch.from_numpy(x_train).float().to(device)\n",
    "    y_train = torch.from_numpy(station_runoff.loc[train_start:train_end, 'runoff'].to_numpy()).float().to(device)\n",
    "    \n",
    "    # Get validation split\n",
    "    num_validation_samples = int(x_train.shape[1] * validation_fraction)\n",
    "    validation_indices = np.random.choice(range(x_train.shape[1]), size=num_validation_samples)\n",
    "    shuffle_indices = np.arange(x_train.shape[1])\n",
    "    np.random.shuffle(shuffle_indices)\n",
    "    x_train = x_train[:,shuffle_indices,:]\n",
    "    y_train = y_train[shuffle_indices]\n",
    "    x_val, x_train = x_train[:,:num_validation_samples,:], x_train[:,num_validation_samples:,:]\n",
    "    y_val, y_train = y_train[:num_validation_samples], y_train[num_validation_samples:]\n",
    "    print('Shapes: x_train {}, y_train {}, x_val {}, y_val {}'.format(x_train.shape, y_train.shape, x_val.shape, y_val.shape))\n",
    "    \n",
    "    # Train model\n",
    "    learning_rate = 2e-3\n",
    "    patience = 50\n",
    "    min_improvement = 0.05\n",
    "    best_loss_model = (-1, np.inf, None)\n",
    "    \n",
    "    # Prepare model\n",
    "    H = 20\n",
    "    batch_size = 5\n",
    "    lstm_layers = 1\n",
    "    dropout = 0\n",
    "    weight_decay = 2e-5\n",
    "    model = LSTMRegression(station_rdrs.shape[1], H, lstm_layers, batch_size, dropout).to(device)\n",
    "    loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    for epoch in range(300):\n",
    "        epoch_losses = []\n",
    "        \n",
    "        shuffle_indices = np.arange(x_train.shape[1])\n",
    "        np.random.shuffle(shuffle_indices)\n",
    "        x_train = x_train[:,shuffle_indices,:]\n",
    "        y_train = y_train[shuffle_indices]\n",
    "\n",
    "        model.train()\n",
    "        for i in range(x_train.shape[1] // batch_size):\n",
    "            model.hidden = model.init_hidden()\n",
    "            y_pred = model(x_train[:,i*batch_size : (i+1)*batch_size,:])\n",
    "    \n",
    "            loss = loss_fn(y_pred, y_train[i*batch_size : (i+1)*batch_size].reshape((batch_size,1))).to(device)\n",
    "            epoch_losses.append(loss.item())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss = np.array(epoch_losses).mean()\n",
    "        print('Epoch', epoch, 'mean train loss:\\t{}'.format(epoch_loss))\n",
    "        writer.add_scalar('loss_' + station, epoch_loss, epoch)\n",
    "        \n",
    "        # eval on validation split\n",
    "        model.eval()\n",
    "        val_pred = pd.Series()\n",
    "        for i in range(x_val.shape[1] // batch_size):\n",
    "            batch_pred = model(x_val[:,i*batch_size : (i+1)*batch_size,:]).detach().cpu().numpy().reshape(batch_size)\n",
    "            val_pred = val_pred.append(pd.Series(batch_pred))\n",
    "        val_nse, val_mse = evaluate.evaluate_daily(station, val_pred, pd.Series(y_val.cpu().numpy().flatten())[:val_pred.shape[0]])\n",
    "        print('Epoch {} mean val mse:    \\t{},\\tnse: {}'.format(epoch, val_mse, val_nse))\n",
    "        writer.add_scalar('loss_eval_' + station, val_mse, epoch)\n",
    "        \n",
    "        if val_mse < best_loss_model[1] - min_improvement:\n",
    "            best_loss_model = (epoch, val_mse, model.state_dict())  # new best model\n",
    "        elif epoch > best_loss_model[0] + patience:\n",
    "            print('Patience exhausted in epoch {}. Best val-loss was {}'.format(epoch, best_loss_model[1]))\n",
    "            break\n",
    "    \n",
    "    print('Using best model from epoch', str(best_loss_model[0]), 'which had loss', str(best_loss_model[1]))\n",
    "    model.load_state_dict(best_loss_model[2])\n",
    "    load_data.pickle_model('LSTM_VIC', model, station, time_stamp)\n",
    "    model.eval()\n",
    "    \n",
    "    # scale test data\n",
    "    x_test = x[:,num_train_days:num_train_days+num_test_days,:].copy()\n",
    "    for i in range(x.shape[2]):\n",
    "        x_test[:,:,i] = scalers[i].transform(x_test[:,:,i].reshape((-1, 1))).reshape(x_test[:,:,i].shape)\n",
    "    print('x_test shape: {}'.format(x_test.shape))\n",
    "    # if batch size doesn't align with number of samples, add dummies to the last batch\n",
    "    if x_test.shape[1] % batch_size != 0:\n",
    "        x_test = np.concatenate([x_test, np.zeros((x_test.shape[0], batch_size - (x_test.shape[1] % batch_size), x_test.shape[2]))], axis=1)\n",
    "        print('Appended dummy entries to x_test. New shape: {}'.format(x_test.shape))\n",
    "    \n",
    "    # Predict\n",
    "    x_test = torch.from_numpy(x_test).float().to(device)\n",
    "    predict = station_runoff[test_start:test_end].copy()\n",
    "    predict['runoff'] = np.nan\n",
    "    pred_array = np.array([])\n",
    "    print('Predicting')\n",
    "    for i in range(x_test.shape[1] // batch_size):\n",
    "        pred_array = np.concatenate([pred_array, model(x_test[:,i*batch_size : (i+1)*batch_size,:]).detach().cpu().numpy().reshape(batch_size)])\n",
    "    predict['runoff'] = pred_array[:predict.shape[0]]  # ignore dummies\n",
    "    \n",
    "    predictions[station] = predict\n",
    "    actuals[station] = station_runoff['runoff'].loc[test_start:test_end]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nse_list = []\n",
    "mse_list = []\n",
    "for station, predict in predictions.items():\n",
    "    nse, mse = evaluate.evaluate_daily(station, predict['runoff'], actuals[station], writer=writer)\n",
    "    nse_list.append(nse)\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    print(station, '\\tNSE:', nse, '\\tMSE:', mse, '(clipped to 0)')\n",
    "\n",
    "print('Median NSE (clipped to 0)', np.median(nse_list), '/ Min', np.min(nse_list), '/ Max', np.max(nse_list))\n",
    "print('Median MSE (clipped to 0)', np.median(mse_list), '/ Min', np.min(mse_list), '/ Max', np.max(mse_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data.pickle_results('LSTM_VIC', (predictions, actuals), time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
