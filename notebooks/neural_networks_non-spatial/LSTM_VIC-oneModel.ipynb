{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM trained on gridded forcings for each station, one model for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20190905-102708'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src import load_data, evaluate, datasets, utils\n",
    "\n",
    "time_stamp = '20190905-102708'\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda devices: []\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA Available')\n",
    "    USE_CUDA = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "num_devices = torch.cuda.device_count() if USE_CUDA else 0\n",
    "print('cuda devices: {}'.format(list(torch.cuda.get_device_name(i) for i in range(num_devices))))\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdrs_vars = [4, 5]\n",
    "agg = None #['sum', 'minmax']\n",
    "seq_len = 5*24\n",
    "seq_steps = 1\n",
    "validation_fraction = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(hours=seq_len * seq_steps)\n",
    "train_end = '2012-12-31'\n",
    "test_start = '2013-01-01'\n",
    "test_end = '2014-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.RdrsDataset(rdrs_vars, seq_len, seq_steps, train_start, train_end, station=True, aggregate_daily=agg)\n",
    "test_dataset = datasets.RdrsDataset(rdrs_vars, seq_len, seq_steps, test_start, test_end, station=True, aggregate_daily=agg,\n",
    "                                    conv_scalers=train_dataset.conv_scalers, fc_scalers=train_dataset.fc_scalers)\n",
    "\n",
    "val_indices = np.random.choice(len(train_dataset), size=int(validation_fraction * len(train_dataset)), replace=False)\n",
    "train_indices = list(i for i in range(len(train_dataset)) if i not in val_indices)\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, sampler=train_sampler, pin_memory=True, drop_last=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, sampler=val_sampler, pin_memory=True, drop_last=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, batch_size, dropout):\n",
    "        super(LSTMRegression, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.init_hidden(batch_size)\n",
    "    def init_hidden(self, batch_size):\n",
    "        self.hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device, requires_grad=True),\n",
    "                       torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device, requires_grad=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        lstm_out, self.hidden = self.lstm(input.permute(1,0,2), self.hidden)\n",
    "        return self.linear(lstm_out[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask of the grid that contains all grid cells that fall into a station's subwatershed\n",
    "station_cell_mask = torch.zeros(train_dataset.x_conv.shape[-2:]).bool()\n",
    "station_cell_mapping = load_data.get_station_cell_mapping()\n",
    "for station in station_cell_mapping['station'].unique():    \n",
    "    for _, row in station_cell_mapping[station_cell_mapping['station'] == station].iterrows():\n",
    "        station_cell_mask[row['col'] - 1, row['row'] - 1] = True\n",
    "\n",
    "onehot_vars = list(i for i,v in enumerate(train_dataset.fc_var_names) if v.startswith('station') or v.startswith('month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'time_stamp': '20190905-102708', 'H': 128, 'batch_size': 32, 'lstm_layers': 2, 'loss': NSELoss(), 'optimizer': Adam (\\nParameter Group 0\\n    amsgrad: False\\n    betas: (0.9, 0.999)\\n    eps: 1e-08\\n    lr: 0.002\\n    weight_decay: 1e-05\\n), 'lr': 0.002, 'patience': 400, 'min_improvement': 0.01, 'dropout': 0.3, 'num_epochs': 1000, 'seq_len': 120, 'seq_steps': 1, 'train_start': datetime.datetime(2010, 1, 6, 0, 0), 'train_end': '2012-12-31', 'weight_decay': 1e-05, 'validation_fraction': 0.1, 'test_start': '2013-01-01', 'test_end': '2014-12-31', 'input_dim': 784, 'model': 'LSTMRegression((lstm):LSTM(784,128,num_layers=2,dropout=0.3)(linear):Linear(in_features=128,out_features=1,bias=True))', 'train len': 49113, 'test len': 33580, 'rdrs_vars': [4, 5], 'aggregate_daily': None}\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "learning_rate = 2e-3\n",
    "patience = 400\n",
    "min_improvement = 0.01\n",
    "H = 128\n",
    "lstm_layers = 2\n",
    "dropout = 0.3\n",
    "weight_decay = 1e-5\n",
    "best_loss_model = (-1, np.inf, None)\n",
    "input_dim = train_dataset.x_conv.shape[2] * int(station_cell_mask.sum()) + len(onehot_vars)\n",
    "model = LSTMRegression(input_dim, H, lstm_layers, batch_size, dropout).to(device)\n",
    "loss_fn = evaluate.NSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "param_description = {'time_stamp': time_stamp, 'H': H, 'batch_size': batch_size, 'lstm_layers': lstm_layers, 'loss': loss_fn, 'optimizer': optimizer, 'lr': learning_rate, \n",
    "                     'patience': patience, 'min_improvement': min_improvement, 'dropout': dropout, 'num_epochs': num_epochs, 'seq_len': seq_len, 'seq_steps': seq_steps, \n",
    "                     'train_start': train_start, 'train_end': train_end, 'weight_decay': weight_decay, 'validation_fraction': validation_fraction, 'test_start': test_start, \n",
    "                     'test_end': test_end, 'input_dim': input_dim, 'model': str(model).replace('\\n','').replace(' ', ''), 'train len':len(train_dataset), \n",
    "                     'test len': len(test_dataset), 'rdrs_vars': rdrs_vars, 'aggregate_daily': agg}\n",
    "writer = SummaryWriter()\n",
    "writer.add_text('Parameter Description', str(param_description))\n",
    "str(param_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../../pickle/models/LSTM_VIC-oneModel_allStations_20190905-102708.pkl', map_location='cpu')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = torch.tensor(0.0)\n",
    "    for i, train_batch in enumerate(train_dataloader):\n",
    "        x_train = train_batch['x_conv'][...,station_cell_mask].reshape(*train_batch['x_conv'].shape[:2], -1)\n",
    "        x_train = torch.cat([x_train, train_batch['x_fc'][:,onehot_vars].unsqueeze(dim=1).repeat(1,x_train.shape[1],1)], dim=2).to(device)\n",
    "        model.init_hidden(x_train.shape[0])\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        loss = loss_fn(y_pred.reshape(-1), train_batch['y'].to(device), means=train_batch['y_mean'].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses += loss.detach()\n",
    "       \n",
    "    train_loss = (train_losses / len(train_dataloader)).item()\n",
    "    print('Epoch', epoch, 'mean loss:', train_loss)\n",
    "    writer.add_scalar('loss_nse', train_loss, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = torch.tensor(0.0)\n",
    "    for i, val_batch in enumerate(val_dataloader):\n",
    "        x_val = val_batch['x_conv'][...,station_cell_mask].reshape(*val_batch['x_conv'].shape[:2], -1)\n",
    "        x_val = torch.cat([x_val, val_batch['x_fc'][:,onehot_vars].unsqueeze(dim=1).repeat(1,x_val.shape[1],1)], dim=2).to(device)\n",
    "        \n",
    "        model.init_hidden(x_val.shape[0])\n",
    "        y_pred = model(x_val)\n",
    "\n",
    "        loss = loss_fn(y_pred.reshape(-1), val_batch['y'].to(device), means=val_batch['y_mean'].to(device))\n",
    "        val_losses += loss.detach()\n",
    "        \n",
    "    val_loss = (val_losses / len(val_dataloader)).item()\n",
    "    print('Epoch', epoch, 'mean val loss:', val_loss)\n",
    "    writer.add_scalar('loss_nse_val', val_loss, epoch)\n",
    "    if val_loss < best_loss_model[1] - min_improvement:\n",
    "        best_loss_model = (epoch, val_loss, model.state_dict())  # new best model\n",
    "        load_data.pickle_model('LSTM_VIC-oneModel', model, 'allStations', time_stamp)\n",
    "    elif epoch > best_loss_model[0] + patience:\n",
    "        print('Patience exhausted in epoch {}. Best loss was {}'.format(epoch, best_loss_model[1]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Using best model from epoch', str(best_loss_model[0]), 'which had loss', str(best_loss_model[1]))\n",
    "#model.load_state_dict(best_loss_model[2])\n",
    "model.eval()\n",
    "predict = test_dataset.data_runoff.copy()\n",
    "predict['actual'] = predict['runoff']\n",
    "predict['runoff'] = np.nan\n",
    "pred_array = np.array([])\n",
    "for i, test_batch in enumerate(test_dataloader):\n",
    "    x_test = test_batch['x_conv'][...,station_cell_mask].reshape(*test_batch['x_conv'].shape[:2], -1)\n",
    "    x_test = torch.cat([x_test, test_batch['x_fc'][:,onehot_vars].unsqueeze(dim=1).repeat(1,x_test.shape[1],1)], dim=2).to(device)\n",
    "    model.init_hidden(x_test.shape[0])\n",
    "    pred_array = np.concatenate([pred_array, model(x_test).detach().cpu().numpy().reshape(-1)])\n",
    "    \n",
    "predict['runoff'] = pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mgauch/miniconda3/envs/gwf/lib/python3.7/site-packages/pandas/plotting/_converter.py:129: FutureWarning: Using an implicitly registered datetime converter for a matplotlib plotting method. The converter was registered by pandas on import. Future versions of pandas will require you to explicitly register matplotlib converters.\n",
      "\n",
      "To register the converters:\n",
      "\t>>> from pandas.plotting import register_matplotlib_converters\n",
      "\t>>> register_matplotlib_converters()\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02GA010 \tNSE: -0.01487434590386405 \tMSE: 483.86524294371355 (clipped to 0)\n",
      "02GA018 \tNSE: 0.0812810162385933 \tMSE: 230.73919475927738 (clipped to 0)\n",
      "02GA038 \tNSE: 0.11653072595862213 \tMSE: 145.3646710949108 (clipped to 0)\n",
      "02GA047 \tNSE: -0.30057416421048666 \tMSE: 101.95204081067533 (clipped to 0)\n",
      "02GB001 \tNSE: -0.2337025223522986 \tMSE: 9264.951975066868 (clipped to 0)\n",
      "02GB007 \tNSE: 0.31392503455299814 \tMSE: 21.454946287251236 (clipped to 0)\n",
      "02GC002 \tNSE: 0.2170335998568238 \tMSE: 100.61355842428154 (clipped to 0)\n",
      "02GC007 \tNSE: -0.23456837105123518 \tMSE: 37.18685918090604 (clipped to 0)\n",
      "02GC010 \tNSE: 0.3104240262504604 \tMSE: 40.99523633463642 (clipped to 0)\n",
      "02GC018 \tNSE: 0.2723961615127093 \tMSE: 49.278280902924706 (clipped to 0)\n",
      "02GC026 \tNSE: 0.20934581604935942 \tMSE: 127.1630893458375 (clipped to 0)\n",
      "02GD004 \tNSE: 0.2529861029456023 \tMSE: 41.13288105401522 (clipped to 0)\n",
      "02GE007 \tNSE: 0.200096219550977 \tMSE: 28.936566035819332 (clipped to 0)\n",
      "02GG002 \tNSE: 0.2141797289564379 \tMSE: 189.52635403438597 (clipped to 0)\n",
      "02GG003 \tNSE: 0.20103636743895537 \tMSE: 381.4233772681286 (clipped to 0)\n",
      "02GG006 \tNSE: 0.21344073078831693 \tMSE: 42.16527894747181 (clipped to 0)\n",
      "02GG009 \tNSE: 0.2133280501506717 \tMSE: 122.36951751649164 (clipped to 0)\n",
      "02GG013 \tNSE: 0.18780254088633908 \tMSE: 31.011632120586263 (clipped to 0)\n",
      "04159492 \tNSE: 0.11717402453577075 \tMSE: 409.890629313159 (clipped to 0)\n",
      "04159900 \tNSE: 0.15363041641696762 \tMSE: 36.77218937179733 (clipped to 0)\n",
      "04160600 \tNSE: 0.1370448717923114 \tMSE: 24.966081849391475 (clipped to 0)\n",
      "04161820 \tNSE: -0.19046577188380076 \tMSE: 37.59258660967876 (clipped to 0)\n",
      "04164000 \tNSE: -0.1585062490999496 \tMSE: 203.00198885252243 (clipped to 0)\n",
      "04165500 \tNSE: -0.03719022415620499 \tMSE: 464.30745347829946 (clipped to 0)\n",
      "04166100 \tNSE: -0.32182912777066575 \tMSE: 9.693379702421073 (clipped to 0)\n",
      "04166500 \tNSE: 0.10850835946870196 \tMSE: 30.813777697752972 (clipped to 0)\n",
      "04174500 \tNSE: -0.13142170284490828 \tMSE: 107.00334380316545 (clipped to 0)\n",
      "04176500 \tNSE: 0.2529699510333715 \tMSE: 510.2769653050801 (clipped to 0)\n",
      "04177000 \tNSE: 0.18407759946357383 \tMSE: 21.988969833477768 (clipped to 0)\n",
      "04193500 \tNSE: 0.07115023562004341 \tMSE: 65763.25927535482 (clipped to 0)\n",
      "04195820 \tNSE: 0.19602946949844224 \tMSE: 943.6960544248424 (clipped to 0)\n",
      "04196800 \tNSE: 0.19087359207033439 \tMSE: 242.1298533469185 (clipped to 0)\n",
      "04197100 \tNSE: 0.23970025019893704 \tMSE: 77.9796950663634 (clipped to 0)\n",
      "04198000 \tNSE: 0.15572310736004968 \tMSE: 6237.145696058488 (clipped to 0)\n",
      "04199000 \tNSE: 0.13209123597863714 \tMSE: 887.5263660012916 (clipped to 0)\n",
      "04199500 \tNSE: 0.1589668698469927 \tMSE: 340.3224766226584 (clipped to 0)\n",
      "04200500 \tNSE: 0.16668930934594905 \tMSE: 833.8981379484029 (clipped to 0)\n",
      "04207200 \tNSE: 0.2146974153023803 \tMSE: 18.381021051936813 (clipped to 0)\n",
      "04208504 \tNSE: 0.08847135687102747 \tMSE: 890.1338409380818 (clipped to 0)\n",
      "04209000 \tNSE: 0.16075354361272798 \tMSE: 262.39545349530937 (clipped to 0)\n",
      "04212100 \tNSE: 0.2517889102184998 \tMSE: 1098.6170763304492 (clipped to 0)\n",
      "04213000 \tNSE: 0.1805660887674878 \tMSE: 147.06317831533934 (clipped to 0)\n",
      "04213500 \tNSE: 0.22446963015296706 \tMSE: 794.4663734524029 (clipped to 0)\n",
      "04214500 \tNSE: 0.248261265137516 \tMSE: 90.61239732674679 (clipped to 0)\n",
      "04215000 \tNSE: 0.18228400856567506 \tMSE: 78.54392106500774 (clipped to 0)\n",
      "04215500 \tNSE: 0.17962543892085037 \tMSE: 148.14726754768168 (clipped to 0)\n",
      "Median NSE (clipped to 0) 0.1800957638441691 / Min -0.32182912777066575 / Max 0.31392503455299814\n",
      "Median MSE (clipped to 0) 136.26388022037415 / Min 9.693379702421073 / Max 65763.25927535482\n"
     ]
    }
   ],
   "source": [
    "nse_list = []\n",
    "mse_list = []\n",
    "grouped_predict = predict.groupby('station')\n",
    "for station in grouped_predict.groups.keys():\n",
    "    station_predict = grouped_predict.get_group(station).set_index('date')\n",
    "    nse, mse = evaluate.evaluate_daily(station, station_predict[['runoff']], station_predict['actual'], writer=writer)\n",
    "    nse_list.append(nse)\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    print(station, '\\tNSE:', nse, '\\tMSE:', mse, '(clipped to 0)')\n",
    "\n",
    "result_str = 'Median NSE (clipped to 0) {} / Min {} / Max {}'.format(np.median(nse_list), np.min(nse_list), np.max(nse_list))\n",
    "print(result_str)\n",
    "print('Median MSE (clipped to 0)', np.median(mse_list), '/ Min', np.min(mse_list), '/ Max', np.max(mse_list))\n",
    "writer.add_text('Results', result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LSTM_VIC-oneModel_20190905-102708.pkl'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data.pickle_results('LSTM_VIC-oneModel', predict[['date', 'station', 'runoff', 'actual']].rename({'runoff': 'prediction'}, axis=1).reset_index(drop=True), time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20190906-133600'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
