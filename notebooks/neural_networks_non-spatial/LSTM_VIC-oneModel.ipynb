{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM trained on gridded forcings for each station, one model for all stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'20190906-083511'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn import preprocessing\n",
    "import netCDF4 as nc\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from src import load_data, evaluate, datasets, utils\n",
    "\n",
    "time_stamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda devices: []\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = False\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA Available')\n",
    "    USE_CUDA = True\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n",
    "num_devices = torch.cuda.device_count() if USE_CUDA else 0\n",
    "print('cuda devices: {}'.format(list(torch.cuda.get_device_name(i) for i in range(num_devices))))\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdrs_vars = [4, 5]\n",
    "agg = None #['sum', 'minmax']\n",
    "seq_len = 5*24\n",
    "seq_steps = 1\n",
    "validation_fraction = 0.1\n",
    "batch_size = 32\n",
    "\n",
    "train_start = datetime.strptime('2010-01-01', '%Y-%m-%d') + timedelta(hours=seq_len * seq_steps)\n",
    "train_end = '2012-12-31'\n",
    "test_start = '2013-01-01'\n",
    "test_end = '2014-12-31'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.RdrsDataset(rdrs_vars, seq_len, seq_steps, train_start, train_end, station=True, aggregate_daily=agg)\n",
    "test_dataset = datasets.RdrsDataset(rdrs_vars, seq_len, seq_steps, test_start, test_end, station=True, aggregate_daily=agg,\n",
    "                                    conv_scalers=train_dataset.conv_scalers, fc_scalers=train_dataset.fc_scalers)\n",
    "\n",
    "val_indices = np.random.choice(len(train_dataset), size=int(validation_fraction * len(train_dataset)), replace=False)\n",
    "train_indices = list(i for i in range(len(train_dataset)) if i not in val_indices)\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, sampler=train_sampler, pin_memory=True, drop_last=False)\n",
    "val_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size, sampler=val_sampler, pin_memory=True, drop_last=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMRegression(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, batch_size, dropout):\n",
    "        super(LSTMRegression, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.init_hidden(batch_size)\n",
    "    def init_hidden(self, batch_size):\n",
    "        self.hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device, requires_grad=True),\n",
    "                       torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device, requires_grad=True))\n",
    "\n",
    "    def forward(self, input):\n",
    "        lstm_out, self.hidden = self.lstm(input.permute(1,0,2), self.hidden)\n",
    "        return self.linear(lstm_out[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask of the grid that contains all grid cells that fall into a station's subwatershed\n",
    "station_cell_mask = torch.zeros(train_dataset.x_conv.shape[-2:]).bool()\n",
    "station_cell_mapping = load_data.get_station_cell_mapping()\n",
    "for station in station_cell_mapping['station'].unique():    \n",
    "    for _, row in station_cell_mapping[station_cell_mapping['station'] == station].iterrows():\n",
    "        station_cell_mask[row['col'] - 1, row['row'] - 1] = True\n",
    "\n",
    "onehot_vars = list(i for i,v in enumerate(train_dataset.fc_var_names) if v.startswith('station') or v.startswith('month'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "learning_rate = 2e-3\n",
    "patience = 100\n",
    "min_improvement = 0.01\n",
    "H = 256\n",
    "lstm_layers = 2\n",
    "dropout = 0.3\n",
    "weight_decay = 1e-5\n",
    "best_loss_model = (-1, np.inf, None)\n",
    "input_dim = train_dataset.x_conv.shape[2] * int(station_cell_mask.sum()) + len(onehot_vars)\n",
    "model = LSTMRegression(input_dim, H, lstm_layers, batch_size, dropout).to(device)\n",
    "loss_fn = evaluate.NSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "param_description = {'time_stamp': time_stamp, 'H': H, 'batch_size': batch_size, 'lstm_layers': lstm_layers, 'loss': loss_fn, 'optimizer': optimizer, 'lr': learning_rate, \n",
    "                     'patience': patience, 'min_improvement': min_improvement, 'dropout': dropout, 'num_epochs': num_epochs, 'seq_len': seq_len, 'seq_steps': seq_steps, \n",
    "                     'train_start': train_start, 'train_end': train_end, 'weight_decay': weight_decay, 'validation_fraction': validation_fraction, 'test_start': test_start, \n",
    "                     'test_end': test_end, 'input_dim': input_dim, 'model': str(model).replace('\\n','').replace(' ', ''), 'train len':len(train_dataset), \n",
    "                     'test len': len(test_dataset), 'rdrs_vars': rdrs_vars, 'aggregate_daily': agg}\n",
    "writer = SummaryWriter()\n",
    "writer.add_text('Parameter Description', str(param_description))\n",
    "str(param_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = torch.tensor(0.0)\n",
    "    for i, train_batch in enumerate(train_dataloader):\n",
    "        x_train = train_batch['x_conv'][...,station_cell_mask].reshape(*train_batch['x_conv'].shape[:2], -1)\n",
    "        x_train = torch.cat([x_train, train_batch['x_fc'][:,onehot_vars].unsqueeze(dim=1).repeat(1,x_train.shape[1],1)], dim=2).to(device)\n",
    "        model.init_hidden(x_train.shape[0])\n",
    "        y_pred = model(x_train)\n",
    "\n",
    "        loss = loss_fn(y_pred.reshape(-1), train_batch['y'].to(device), means=train_batch['y_mean'].to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses += loss.detach()\n",
    "       \n",
    "    train_loss = (train_losses / len(train_dataloader)).item()\n",
    "    print('Epoch', epoch, 'mean loss:', train_loss)\n",
    "    writer.add_scalar('loss_nse', train_loss, epoch)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = torch.tensor(0.0)\n",
    "    for i, val_batch in enumerate(val_dataloader):\n",
    "        x_val = val_batch['x_conv'][...,station_cell_mask].reshape(*val_batch['x_conv'].shape[:2], -1)\n",
    "        x_val = torch.cat([x_val, val_batch['x_fc'][:,onehot_vars].unsqueeze(dim=1).repeat(1,x_val.shape[1],1)], dim=2).to(device)\n",
    "        \n",
    "        model.init_hidden(x_val.shape[0])\n",
    "        y_pred = model(x_val)\n",
    "\n",
    "        loss = loss_fn(y_pred.reshape(-1), val_batch['y'].to(device), means=val_batch['y_mean'].to(device))\n",
    "        val_losses += loss.detach()\n",
    "        \n",
    "    val_loss = (val_losses / len(val_dataloader)).item()\n",
    "    print('Epoch', epoch, 'mean val loss:', val_loss)\n",
    "    writer.add_scalar('loss_nse_val', val_loss, epoch)\n",
    "    if val_loss < best_loss_model[1] - min_improvement:\n",
    "        best_loss_model = (epoch, val_loss, model.state_dict())  # new best model\n",
    "        load_data.pickle_model('LSTM_VIC-oneModel', model, 'allStations', time_stamp)\n",
    "    elif epoch > best_loss_model[0] + patience:\n",
    "        print('Patience exhausted in epoch {}. Best loss was {}'.format(epoch, best_loss_model[1]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using best model from epoch', str(best_loss_model[0]), 'which had loss', str(best_loss_model[1]))\n",
    "model.load_state_dict(best_loss_model[2])\n",
    "model.eval()\n",
    "predict = test_dataset.data_runoff.copy()\n",
    "predict['actual'] = predict['runoff']\n",
    "predict['runoff'] = np.nan\n",
    "pred_array = np.array([])\n",
    "for i, test_batch in enumerate(test_dataloader):\n",
    "    x_test = test_batch['x_conv'][...,station_cell_mask].reshape(*test_batch['x_conv'].shape[:2], -1)\n",
    "    x_test = torch.cat([x_test, test_batch['x_fc'][:,onehot_vars].unsqueeze(dim=1).repeat(1,x_test.shape[1],1)], dim=2).to(device)\n",
    "    model.init_hidden(x_test.shape[0])\n",
    "    pred_array = np.concatenate([pred_array, model(x_test).detach().cpu().numpy().reshape(-1)])\n",
    "    \n",
    "predict['runoff'] = pred_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nse_list = []\n",
    "mse_list = []\n",
    "grouped_predict = predict.groupby('station')\n",
    "for station in grouped_predict.groups.keys():\n",
    "    station_predict = grouped_predict.get_group(station).set_index('date')\n",
    "    nse, mse = evaluate.evaluate_daily(station, station_predict[['runoff']], station_predict['actual'], writer=writer)\n",
    "    nse_list.append(nse)\n",
    "    mse_list.append(mse)\n",
    "    \n",
    "    print(station, '\\tNSE:', nse, '\\tMSE:', mse, '(clipped to 0)')\n",
    "\n",
    "result_str = 'Median NSE (clipped to 0) {} / Min {} / Max {}'.format(np.median(nse_list), np.min(nse_list), np.max(nse_list))\n",
    "print(result_str)\n",
    "print('Median MSE (clipped to 0)', np.median(mse_list), '/ Min', np.min(mse_list), '/ Max', np.max(mse_list))\n",
    "writer.add_text('Results', result_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data.pickle_results('LSTM_VIC-oneModel', predict[['date', 'station', 'runoff', 'actual']].rename({'runoff': 'prediction'}, axis=1).reset_index(drop=True), time_stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
